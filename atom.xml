<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>红色石头的机器学习之路</title>
  
  <subtitle>公众号ID：redstonewill</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://redstonewill.github.io/"/>
  <updated>2018-03-27T03:03:07.669Z</updated>
  <id>https://redstonewill.github.io/</id>
  
  <author>
    <name>红色石头</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Coursera吴恩达《神经网络与深度学习》课程笔记（4）-- 浅层神经网络</title>
    <link href="https://redstonewill.github.io/2018/03/26/37/"/>
    <id>https://redstonewill.github.io/2018/03/26/37/</id>
    <published>2018-03-26T13:06:31.000Z</published>
    <updated>2018-03-27T03:03:07.669Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170927081305727?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的个人网站：<a href="https://redstonewill.github.io/">红色石头的机器学习之路</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="http://weibo.com/redstonewill" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）</p></blockquote><p>上节课我们主要介绍了向量化、矩阵计算的方法和python编程的相关技巧。并以逻辑回归为例，将其算法流程包括梯度下降转换为向量化的形式，从而大大提高了程序运算速度。本节课我们将从浅层神经网络入手，开始真正的神经网络模型的学习。</p><h3 id="Neural-Networks-Overview"><a href="#Neural-Networks-Overview" class="headerlink" title="Neural Networks Overview"></a>Neural Networks Overview</h3><p>首先，我们从整体结构上来大致看一下神经网络模型。</p><p>前面的课程中，我们已经使用计算图的方式介绍了逻辑回归梯度下降算法的正向传播和反向传播两个过程。如下图所示。神经网络的结构与逻辑回归类似，只是神经网络的层数比逻辑回归多一层，多出来的中间那层称为隐藏层或中间层。这样从计算上来说，神经网络的正向传播和反向传播过程只是比逻辑回归多了一次重复的计算。正向传播过程分成两层，第一层是输入层到隐藏层，用上标[1]来表示：</p><p>$$z^{[1]}=W^{[1]}x+b^{[1]}$$</p><p>$$a^{[1]}=\sigma(z^{[1]})$$</p><p>第二层是隐藏层到输出层，用上标[2]来表示：</p><p>$$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$$</p><p>$$a^{[2]}=\sigma(z^{[2]})$$</p><p>在写法上值得注意的是，方括号上标[i]表示当前所处的层数；圆括号上标(i)表示第i个样本。</p><p>同样，反向传播过程也分成两层。第一层是输出层到隐藏层，第二层是隐藏层到输入层。其细节部分我们之后再来讨论。</p><p><img src="http://img.blog.csdn.net/20170927081053565?" alt="这里写图片描述"></p><h3 id="Neural-Network-Representation"><a href="#Neural-Network-Representation" class="headerlink" title="Neural Network Representation"></a>Neural Network Representation</h3><p>下面我们以图示的方式来介绍单隐藏层的神经网络结构。如下图所示，单隐藏层神经网络就是典型的浅层（shallow）神经网络。</p><p><img src="http://img.blog.csdn.net/20170927081305727?" alt="这里写图片描述"></p><p> 结构上，从左到右，可以分成三层：输入层（Input layer），隐藏层（Hidden layer）和输出层（Output layer）。输入层和输出层，顾名思义，对应着训练样本的输入和输出，很好理解。隐藏层是抽象的非线性的中间层，这也是其被命名为隐藏层的原因。</p><p>在写法上，我们通常把输入矩阵X记为$a^{[0]}$，把隐藏层输出记为$a^{[1]}$，上标从0开始。用下标表示第几个神经元，注意下标从1开始。例如$a_1^{[1]}$表示隐藏层第1个神经元，$a_2^{[1]}$表示隐藏层第2个神经元,，等等。这样，隐藏层有4个神经元就可以将其输出$a^{[1]}$写成矩阵的形式：</p><p>$$<br> \boldsymbol{a^{[1]}}=<br> \left[<br> \begin{matrix}<br>   a_1^{[1]} \<br>   a_2^{[1]}  \<br>   a_3^{[1]} \<br>   a_4^{[1]}<br>  \end{matrix}<br>  \right]<br>$$</p><p>最后，相应的输出层记为$a^{[2]}$，即$\hat y$。这种单隐藏层神经网络也被称为两层神经网络（2 layer NN）。之所以叫两层神经网络是因为，通常我们只会计算隐藏层输出和输出层的输出，输入层是不用计算的。这也是我们把输入层层数上标记为0的原因（$a^{[0]}$）。</p><p>关于隐藏层对应的权重$W^{[1]}$和常数项$b^{[1]}$，$W^{[1]}$的维度是（4,3）。这里的4对应着隐藏层神经元个数，3对应着输入层x特征向量包含元素个数。常数项$b^{[1]}$的维度是（4,1），这里的4同样对应着隐藏层神经元个数。关于输出层对应的权重$W^{[2]}$和常数项$b^{[2]}$，$W^{[2]}$的维度是（1,4），这里的1对应着输出层神经元个数，4对应着输出层神经元个数。常数项$b^{[2]}$的维度是（1,1），因为输出只有一个神经元。总结一下，第i层的权重$W^{[i]}$维度的行等于i层神经元的个数，列等于i-1层神经元的个数；第i层常数项$b^{[i]}$维度的行等于i层神经元的个数，列始终为1。</p><h3 id="Computing-a-Neural-Network’s-Output"><a href="#Computing-a-Neural-Network’s-Output" class="headerlink" title="Computing a Neural Network’s Output"></a>Computing a Neural Network’s Output</h3><p>接下来我们开始详细推导神经网络的计算过程。回顾一下，我们前面讲过两层神经网络可以看成是逻辑回归再重复计算一次。如下图所示，逻辑回归的正向计算可以分解成计算z和a的两部分：</p><p>$$z=w^Tx+b$$</p><p>$$a=\sigma(z)$$</p><p><img src="http://img.blog.csdn.net/20170927081331442?" alt="这里写图片描述"></p><p>对于两层神经网络，从输入层到隐藏层对应一次逻辑回归运算；从隐藏层到输出层对应一次逻辑回归运算。每层计算时，要注意对应的上标和下标，一般我们记上标方括号表示layer，下标表示第几个神经元。例如$a_i^{[l]}$表示第l层的第i个神经元。注意，i从1开始，l从0开始。</p><p>下面，我们将从输入层到输出层的计算公式列出来：</p><p>$$z_1^{[1]}=w_1^{[1]T}x+b_1^{[1]},\ a_1^{[1]}=\sigma(z_1^{[1]})$$</p><p>$$z_2^{[1]}=w_2^{[1]T}x+b_2^{[1]},\ a_2^{[1]}=\sigma(z_2^{[1]})$$</p><p>$$z_3^{[1]}=w_3^{[1]T}x+b_3^{[1]},\ a_3^{[1]}=\sigma(z_3^{[1]})$$</p><p>$$z_4^{[1]}=w_4^{[1]T}x+b_4^{[1]},\ a_4^{[1]}=\sigma(z_4^{[1]})$$</p><p>然后，从隐藏层到输出层的计算公式为：</p><p>$$z_1^{[2]}=w_1^{[2]T}a^{[1]}+b_1^{[2]},\ a_1^{[2]}=\sigma(z_1^{[2]})$$</p><p>其中$a^{[1]}$为：</p><p>$$<br> \boldsymbol{a^{[1]}}=<br> \left[<br> \begin{matrix}<br>   a_1^{[1]} \<br>   a_2^{[1]}  \<br>   a_3^{[1]} \<br>   a_4^{[1]}<br>  \end{matrix}<br>  \right]<br>$$</p><p>上述每个节点的计算都对应着一次逻辑运算的过程，分别由计算z和a两部分组成。</p><p>为了提高程序运算速度，我们引入向量化和矩阵运算的思想，将上述表达式转换成矩阵运算的形式：</p><p>$$z^{[1]}=W^{[1]}x+b^{[1]}$$</p><p>$$a^{[1]}=\sigma(z^{[1]})$$</p><p>$$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$$</p><p>$$a^{[2]}=\sigma(z^{[2]})$$</p><p><img src="http://img.blog.csdn.net/20170927081521144?" alt="这里写图片描述"></p><p>之前也介绍过，这里顺便提一下，$W^{[1]}$的维度是（4,3），$b^{[1]}$的维度是（4,1），$W^{[2]}$的维度是（1,4），$b^{[2]}$的维度是（1,1）。这点需要特别注意。</p><h3 id="Vectorizing-across-multiple-examples"><a href="#Vectorizing-across-multiple-examples" class="headerlink" title="Vectorizing across multiple examples"></a>Vectorizing across multiple examples</h3><p>上一部分我们只是介绍了单个样本的神经网络正向传播矩阵运算过程。而对于m个训练样本，我们也可以使用矩阵相乘的形式来提高计算效率。而且它的形式与上一部分单个样本的矩阵运算十分相似，比较简单。</p><p>之前我们也介绍过，在书写标记上用上标(i)表示第i个样本，例如$x^{(i)}$，$z^{(i)}$，$a^{[2](i)}$。对于每个样本i，可以使用for循环来求解其正向输出：</p><p>for i = 1 to m:<br>$\ \ \ \ z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]}$<br>$\ \ \ \ a^{[1](i)}=\sigma(z^{[1](i)})$<br>$\ \ \ \ z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]}$<br>$\ \ \ \ a^{[2](i)}=\sigma(z^{[2](i)})$</p><p>不使用for循环，利用矩阵运算的思想，输入矩阵X的维度为（$n_x$,m）。这样，我们可以把上面的for循环写成矩阵运算的形式：</p><p>$$Z^{[1]}=W^{[1]}X+b^{[1]}$$</p><p>$$A^{[1]}=\sigma(Z^{[1]})$$</p><p>$$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$$</p><p>$$A^{[2]}=\sigma(Z^{[2]})$$</p><p>其中，$Z^{[1]}$的维度是（4,m），4是隐藏层神经元的个数；$A^{[1]}$的维度与$Z^{[1]}$相同；$Z^{[2]}$和$A^{[2]}$的维度均为（1,m）。对上面这四个矩阵来说，均可以这样来理解：行表示神经元个数，列表示样本数目m。</p><h3 id="Explanation-for-Vectorized-Implementation"><a href="#Explanation-for-Vectorized-Implementation" class="headerlink" title="Explanation for Vectorized Implementation"></a>Explanation for Vectorized Implementation</h3><p>这部分Andrew用图示的方式解释了m个样本的神经网络矩阵运算过程。其实内容比较简单，只要记住上述四个矩阵的行表示神经元个数，列表示样本数目m就行了。</p><p>值得注意的是输入矩阵X也可以写成$A^{[0]}$。</p><h3 id="Activation-functions"><a href="#Activation-functions" class="headerlink" title="Activation functions"></a>Activation functions</h3><p>神经网络隐藏层和输出层都需要激活函数（activation function），在之前的课程中我们都默认使用Sigmoid函数$\sigma(x)$作为激活函数。其实，还有其它激活函数可供使用，不同的激活函数有各自的优点。下面我们就来介绍几个不同的激活函数$g(x)$。</p><ul><li>sigmoid函数</li></ul><p><img src="http://img.blog.csdn.net/20170920120759651?" alt="这里写图片描述"></p><ul><li>tanh函数</li></ul><p><img src="http://img.blog.csdn.net/20170919091551404?" alt="这里写图片描述"></p><ul><li>ReLU函数</li></ul><p><img src="http://img.blog.csdn.net/20170919091933651?" alt="这里写图片描述"></p><ul><li>Leaky ReLU函数</li></ul><p><img src="http://img.blog.csdn.net/20170919092253605?" alt="这里写图片描述"></p><p>如上图所示，不同激活函数形状不同，a的取值范围也有差异。</p><p>如何选择合适的激活函数呢？首先我们来比较sigmoid函数和tanh函数。对于隐藏层的激活函数，一般来说，tanh函数要比sigmoid函数表现更好一些。因为tanh函数的取值范围在[-1,+1]之间，隐藏层的输出被限定在[-1,+1]之间，可以看成是在0值附近分布，均值为0。这样从隐藏层到输出层，数据起到了归一化（均值为0）的效果。因此，隐藏层的激活函数，tanh比sigmoid更好一些。而对于输出层的激活函数，因为二分类问题的输出取值为{0,+1}，所以一般会选择sigmoid作为激活函数。</p><p>观察sigmoid函数和tanh函数，我们发现有这样一个问题，就是当|z|很大的时候，激活函数的斜率（梯度）很小。因此，在这个区域内，梯度下降算法会运行得比较慢。在实际应用中，应尽量避免使z落在这个区域，使|z|尽可能限定在零值附近，从而提高梯度下降算法运算速度。</p><p>为了弥补sigmoid函数和tanh函数的这个缺陷，就出现了ReLU激活函数。ReLU激活函数在z大于零时梯度始终为1；在z小于零时梯度始终为0；z等于零时的梯度可以当成1也可以当成0，实际应用中并不影响。对于隐藏层，选择ReLU作为激活函数能够保证z大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度。但当z小于零时，存在梯度为0的缺点，实际应用中，这个缺点影响不是很大。为了弥补这个缺点，出现了Leaky ReLU激活函数，能够保证z小于零是梯度不为0。</p><p>最后总结一下，如果是分类问题，输出层的激活函数一般会选择sigmoid函数。但是隐藏层的激活函数通常不会选择sigmoid函数，tanh函数的表现会比sigmoid函数好一些。实际应用中，通常会会选择使用ReLU或者Leaky ReLU函数，保证梯度下降速度不会太小。其实，具体选择哪个函数作为激活函数没有一个固定的准确的答案，应该要根据具体实际问题进行验证（validation）。</p><h3 id="Why-do-you-need-non-linear-activation-functions"><a href="#Why-do-you-need-non-linear-activation-functions" class="headerlink" title="Why do you need non-linear activation functions"></a>Why do you need non-linear activation functions</h3><p>我们知道上一部分讲的四种激活函数都是非线性（non-linear）的。那是否可以使用线性激活函数呢？答案是不行！下面我们就来进行简要的解释和说明。</p><p>假设所有的激活函数都是线性的，为了简化计算，我们直接令激活函数$g(z)=z$，即$a=z$。那么，浅层神经网络的各层输出为：</p><p>$$z^{[1]}=W^{[1]}x+b^{[1]}$$</p><p>$$a^{[1]}=z^{[1]}$$</p><p>$$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$$</p><p>$$a^{[2]}=z^{[2]}$$</p><p>我们对上式中$a^{[2]}$进行化简计算：</p><p>$$a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]}=(W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]})=W’x+b’$$</p><p>经过推导我们发现$a^{[2]}$仍是输入变量x的线性组合。这表明，使用神经网络与直接使用线性模型的效果并没有什么两样。即便是包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入x的线性模型。这样的话神经网络就没有任何作用了。因此，隐藏层的激活函数必须要是非线性的。</p><p>另外，如果所有的隐藏层全部使用线性激活函数，只有输出层使用非线性激活函数，那么整个神经网络的结构就类似于一个简单的逻辑回归模型，而失去了神经网络模型本身的优势和价值。</p><p>值得一提的是，如果是预测问题而不是分类问题，输出y是连续的情况下，输出层的激活函数可以使用线性函数。如果输出y恒为正值，则也可以使用ReLU激活函数，具体情况，具体分析。</p><h3 id="Derivatives-of-activation-functions"><a href="#Derivatives-of-activation-functions" class="headerlink" title="Derivatives of activation functions"></a>Derivatives of activation functions</h3><p>在梯度下降反向计算过程中少不了计算激活函数的导数即梯度。</p><p>我们先来看一下sigmoid函数的导数：</p><p>$$g(z)=\frac{1}{1+e^{(-z)}}$$</p><p>$$g’(z)=\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$$</p><p>对于tanh函数的导数：</p><p>$$g(z)=\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}$$</p><p>$$g’(z)=\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$$</p><p>对于ReLU函数的导数：</p><p>$$g(z)=max(0,z)$$</p><p>$$g’(z)=\begin{cases}<br>        0, &amp; z&lt;0\<br>        1, &amp; z\geq0<br>    \end{cases}$$</p><p>对于Leaky ReLU函数：</p><p>$$g(z)=max(0.01z,z)$$</p><p>$$g’(z)=\begin{cases}<br>        0.01, &amp; z&lt;0\<br>        1, &amp; z\geq0<br>    \end{cases}$$</p><h3 id="Gradient-descent-for-neural-networks"><a href="#Gradient-descent-for-neural-networks" class="headerlink" title="Gradient descent for neural networks"></a>Gradient descent for neural networks</h3><p>接下来看一下在神经网络中如何进行梯度计算。</p><p>仍然是浅层神经网络，包含的参数为$W^{[1]}$，$b^{[1]}$，$W^{[2]}$，$b^{[2]}$。令输入层的特征向量个数$n_x=n^{[0]}$，隐藏层神经元个数为$n^{[1]}$，输出层神经元个数为$n^{[2]}=1$。则$W^{[1]}$的维度为（$n^{[1]}$,$n^{[0]}$），$b^{[1]}$的维度为（$n^{[1]}$,1），$W^{[2]}$的维度为（$n^{[2]}$,$n^{[1]}$），$b^{[2]}$的维度为（$n^{[2]}$,1）。</p><p>该神经网络正向传播过程为：</p><p>$$Z^{[1]}=W^{[1]}X+b^{[1]}$$</p><p>$$A^{[1]}=g(Z^{[1]})$$</p><p>$$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$$</p><p>$$A^{[2]}=g(Z^{[2]})$$</p><p>其中，$g(\cdot)$表示激活函数。</p><p>反向传播是计算导数（梯度）的过程，这里先列出来Cost function对各个参数的梯度：</p><p>$$dZ^{[2]}=A^{[2]}-Y$$</p><p>$$dW^{[2]}=\frac1mdZ^{[2]}A^{[1]T}$$</p><p>$$db^{[2]}=\frac1mnp.sum(dZ^{[2]},axis=1,keepdim=True)$$</p><p>$$dZ^{[1]}=W^{[2]T}dZ^{[2]}\ast g’(Z^{[1]})$$</p><p>$$dW^{[1]}=\frac1mdZ^{[1]}X^T$$</p><p>$$db^{[1]}=\frac1mnp.sum(dZ^{[1]},axis=1,keepdim=True)$$</p><p>反向传播的具体推导过程我们下一部分再进行详细说明。</p><h3 id="Backpropagation-intuition-optional"><a href="#Backpropagation-intuition-optional" class="headerlink" title="Backpropagation intuition(optional)"></a>Backpropagation intuition(optional)</h3><p>我们仍然使用计算图的方式来推导神经网络反向传播过程。记得之前介绍逻辑回归时，我们就引入了计算图来推导正向传播和反向传播，其过程如下图所示：</p><p><img src="http://img.blog.csdn.net/20170927082308231?" alt="这里写图片描述"></p><p>由于多了一个隐藏层，神经网络的计算图要比逻辑回归的复杂一些，如下图所示。对于单个训练样本，正向过程很容易，反向过程可以根据梯度计算方法逐一推导。</p><p>$$dz^{[2]}=a^{[2]}-y$$</p><p>$$dW^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial W^{[2]}}=dz^{[2]}a^{[1]T}$$</p><p>$$db^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial b^{[2]}}=dz^{[2]}\cdot 1=dz^{[2]}$$</p><p>$$dz^{[1]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial a^{[1]}}\cdot \frac{\partial a^{[1]}}{\partial z^{[1]}}=W^{[2]T}dz^{[2]}\ast g^{[1]’}(z^{[1]})$$</p><p>$$dW^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial W^{[1]}}=dz^{[1]}x^T$$</p><p>$$db^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial b^{[1]}}=dz^{[1]}\cdot 1=dz^{[1]}$$</p><p><img src="http://img.blog.csdn.net/20170927082510979?" alt="这里写图片描述"></p><p>总结一下，浅层神经网络（包含一个隐藏层），m个训练样本的正向传播过程和反向传播过程分别包含了6个表达式，其向量化矩阵形式如下图所示：</p><p><img src="http://img.blog.csdn.net/20170927082924477?" alt="这里写图片描述"></p><h3 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a>Random Initialization</h3><p>神经网络模型中的参数权重W是不能全部初始化为零的，接下来我们分析一下原因。</p><p>举个简单的例子，一个浅层神经网络包含两个输入，隐藏层包含两个神经元。如果权重$W^{[1]}$和$W^{[2]}$都初始化为零，即：</p><p>$$W^{[1]}=<br> \left[<br> \begin{matrix}<br>   0 &amp; 0 \<br>   0 &amp; 0<br>  \end{matrix}<br>  \right]<br>$$</p><p>$$W^{[2]}=<br> \left[<br> \begin{matrix}<br>   0 &amp; 0<br>  \end{matrix}<br>  \right]<br>$$</p><p>这样使得隐藏层第一个神经元的输出等于第二个神经元的输出，即$a_1^{[1]}=a_2^{[1]}$。经过推导得到$dz_1^{[1]}=dz_2^{[1]}$，以及$dW_1^{[1]}=dW_2^{[1]}$。因此，这样的结果是隐藏层两个神经元对应的权重行向量$W_1^{[1]}$和$W_2^{[1]}$每次迭代更新都会得到完全相同的结果，$W_1^{[1]}$始终等于$W_2^{[1]}$，完全对称。这样隐藏层设置多个神经元就没有任何意义了。值得一提的是，参数b可以全部初始化为零，并不会影响神经网络训练效果。</p><p><img src="http://img.blog.csdn.net/20170927082954620?" alt="这里写图片描述"></p><p>我们把这种权重W全部初始化为零带来的问题称为symmetry breaking problem。解决方法也很简单，就是将W进行随机初始化（b可初始化为零）。python里可以使用如下语句进行W和b的初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W_1 = np.random.randn((<span class="number">2</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_1 = np.zero((<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">W_2 = np.random.randn((<span class="number">1</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_2 = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>这里我们将$W_1^{[1]}$和$W_2^{[1]}$乘以0.01的目的是尽量使得权重W初始化比较小的值。之所以让W比较小，是因为如果使用sigmoid函数或者tanh函数作为激活函数的话，W比较小，得到的|z|也比较小（靠近零点），而零点区域的梯度比较大，这样能大大提高梯度下降算法的更新速度，尽快找到全局最优解。如果W较大，得到的|z|也比较大，附近曲线平缓，梯度较小，训练过程会慢很多。</p><p>当然，如果激活函数是ReLU或者Leaky ReLU函数，则不需要考虑这个问题。但是，如果输出层是sigmoid函数，则对应的权重W最好初始化到比较小的值。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了浅层神经网络。首先，我们简单概述了神经网络的结构：包括输入层，隐藏层和输出层。然后，我们以计算图的方式推导了神经网络的正向输出，并以向量化的形式归纳出来。接着，介绍了不同的激活函数并做了比较，实际应用中根据不同需要选择合适的激活函数。激活函数必须是非线性的，不然神经网络模型起不了任何作用。然后，我们重点介绍了神经网络的反向传播过程以及各个参数的导数推导，并以矩阵形式表示出来。最后，介绍了权重随机初始化的重要性，必须对权重W进行随机初始化操作。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170927081305727?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达神经网络与深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://redstonewill.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Coursera" scheme="https://redstonewill.github.io/tags/Coursera/"/>
    
      <category term="吴恩达" scheme="https://redstonewill.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
  </entry>
  
  <entry>
    <title>Coursera吴恩达《神经网络与深度学习》课程笔记（3）-- 神经网络基础之Python与向量化</title>
    <link href="https://redstonewill.github.io/2018/03/22/36/"/>
    <id>https://redstonewill.github.io/2018/03/22/36/</id>
    <published>2018-03-22T05:36:02.000Z</published>
    <updated>2018-03-22T05:39:25.862Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170926163908656?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了逻辑回归，以输出概率的形式来处理二分类问题。我们介绍了逻辑回归的Cost function表达式，并使用梯度下降算法来计算最小化Cost function时对应的参数w和b。通过计算图的方式来讲述了神经网络的正向传播和反向传播两个过程。本节课我们将来探讨Python和向量化的相关知识。</p><h3 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h3><p>深度学习算法中，数据量很大，在程序中应该尽量减少使用loop循环语句，而可以使用向量运算来提高程序运行速度。</p><p>向量化（Vectorization）就是利用矩阵运算的思想，大大提高运算速度。例如下面所示在Python中使用向量化要比使用循环计算速度快得多。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(<span class="number">1000000</span>)</span><br><span class="line">b = np.random.rand(<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line">tic = time.time()</span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(c)</span><br><span class="line">print(<span class="string">"Vectorized version:"</span> + str(<span class="number">1000</span>*(toc-tic)) + <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line">c = <span class="number">0</span></span><br><span class="line">tic = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">c += a[i]*b[i]</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(c)</span><br><span class="line">print(<span class="string">"for loop:"</span> + str(<span class="number">1000</span>*(toc-tic)) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure><p>输出结果类似于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">250286.989866</span></span><br><span class="line">Vectorized version:<span class="number">1.5027523040771484</span>ms</span><br><span class="line"><span class="number">250286.989866</span></span><br><span class="line">For loop:<span class="number">474.29513931274414</span>ms</span><br></pre></td></tr></table></figure><p>从程序运行结果上来看，该例子使用for循环运行时间是使用向量运算运行时间的约300倍。因此，深度学习算法中，使用向量化矩阵运算的效率要高得多。</p><p>为了加快深度学习神经网络运算速度，可以使用比CPU运算能力更强大的GPU。事实上，GPU和CPU都有并行指令（parallelization instructions），称为Single Instruction Multiple Data（SIMD）。SIMD是单指令多数据流，能够复制多个操作数，并把它们打包在大型寄存器的一组指令集。SIMD能够大大提高程序运行速度，例如python的numpy库中的内建函数（built-in function）就是使用了SIMD指令。相比而言，GPU的SIMD要比CPU更强大一些。</p><h3 id="More-Vectorization-Examples"><a href="#More-Vectorization-Examples" class="headerlink" title="More Vectorization Examples"></a>More Vectorization Examples</h3><p>上一部分我们讲了应该尽量避免使用for循环而使用向量化矩阵运算。在python的numpy库中，我们通常使用np.dot()函数来进行矩阵运算。</p><p>我们将向量化的思想使用在逻辑回归算法上，尽可能减少for循环，而只使用矩阵运算。值得注意的是，算法最顶层的迭代训练的for循环是不能替换的。而每次迭代过程对J，dw，b的计算是可以直接使用矩阵运算。</p><h3 id="Vectorizing-Logistic-Regression"><a href="#Vectorizing-Logistic-Regression" class="headerlink" title="Vectorizing Logistic Regression"></a>Vectorizing Logistic Regression</h3><p>在《神经网络与深度学习》课程笔记（2）中我们介绍过，整个训练样本构成的输入矩阵X的维度是（$n_x$，m），权重矩阵w的维度是（$n_x$，1），b是一个常数值，而整个训练样本构成的输出矩阵Y的维度为（1，m）。利用向量化的思想，所有m个样本的线性输出Z可以用矩阵表示：</p><p>$$Z=w^TX+b$$</p><p>在python的numpy库中可以表示为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z = np.dot(w.T,X) + b</span><br><span class="line">A = sigmoid(Z)</span><br></pre></td></tr></table></figure><p>其中，w.T表示w的转置。</p><p>这样，我们就能够使用向量化矩阵运算代替for循环，对所有m个样本同时运算，大大提高了运算速度。</p><h3 id="Vectorizing-Logistic-Regression’s-Gradient-Output"><a href="#Vectorizing-Logistic-Regression’s-Gradient-Output" class="headerlink" title="Vectorizing Logistic Regression’s Gradient Output"></a>Vectorizing Logistic Regression’s Gradient Output</h3><p>再来看逻辑回归中的梯度下降算法如何转化为向量化的矩阵形式。对于所有m个样本，dZ的维度是（1，m），可表示为：</p><p>$$dZ=A-Y$$</p><p>db可表示为：</p><p>$$db=\frac1m \sum_{i=1}^mdz^{(i)}$$</p><p>对应的程序为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db = <span class="number">1</span>/m*np.sum(dZ)</span><br></pre></td></tr></table></figure><p>dw可表示为：</p><p>$$dw=\frac1m X\cdot dZ^T$$</p><p>对应的程序为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dw = <span class="number">1</span>/m*np.dot(X,dZ.T)</span><br></pre></td></tr></table></figure><p>这样，我们把整个逻辑回归中的for循环尽可能用矩阵运算代替，对于单次迭代，梯度下降算法流程如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Z = np.dot(w.T,X) + b</span><br><span class="line">A = sigmoid(Z)</span><br><span class="line">dZ = A-Y</span><br><span class="line">dw = <span class="number">1</span>/m*np.dot(X,dZ.T)</span><br><span class="line">db = <span class="number">1</span>/m*np.sum(dZ)</span><br><span class="line"></span><br><span class="line">w = w - alpha*dw</span><br><span class="line">b = b - alpha*db</span><br></pre></td></tr></table></figure><p>其中，alpha是学习因子，决定w和b的更新速度。上述代码只是对单次训练更新而言的，外层还需要一个for循环，表示迭代次数。</p><h3 id="Broadcasting-in-Python"><a href="#Broadcasting-in-Python" class="headerlink" title="Broadcasting in Python"></a>Broadcasting in Python</h3><p>下面介绍使用python的另一种技巧：广播（Broadcasting）。python中的广播机制可由下面四条表示：</p><ul><li><p><strong>让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐</strong></p></li><li><p><strong>输出数组的shape是输入数组shape的各个轴上的最大值</strong></p></li><li><p><strong>如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错</strong></p></li><li><p><strong>当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值</strong></p></li></ul><p>简而言之，就是python中可以对不同维度的矩阵进行四则混合运算，但至少保证有一个维度是相同的。下面给出几个广播的例子，具体细节可参阅python的相关手册，这里就不赘述了。</p><p><img src="http://img.blog.csdn.net/20170926163908656?" alt="这里写图片描述"></p><p>值得一提的是，在python程序中为了保证矩阵运算正确，可以使用reshape()函数来对矩阵设定所需的维度。这是一个很好且有用的习惯。</p><h3 id="A-note-on-python-numpy-vectors"><a href="#A-note-on-python-numpy-vectors" class="headerlink" title="A note on python/numpy vectors"></a>A note on python/numpy vectors</h3><p>接下来我们将总结一些python的小技巧，避免不必要的code bug。</p><p>python中，如果我们用下列语句来定义一个向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>这条语句生成的a的维度是（5，）。它既不是行向量也不是列向量，我们把a叫做rank 1 array。这种定义会带来一些问题。例如我们对a进行转置，还是会得到a本身。所以，如果我们要定义（5，1）的列向量或者（1，5）的行向量，最好使用下来标准语句，避免使用rank 1 array。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">b = np.random.randn(<span class="number">1</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>除此之外，我们还可以使用assert语句对向量或数组的维度进行判断，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span>(a.shape == (<span class="number">5</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>assert会对内嵌语句进行判断，即判断a的维度是不是（5，1）的。如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。</p><p>另外，还可以使用reshape函数对数组设定所需的维度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.reshape((<span class="number">5</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="Quick-tour-of-Jupyter-iPython-Notebooks"><a href="#Quick-tour-of-Jupyter-iPython-Notebooks" class="headerlink" title="Quick tour of Jupyter/iPython Notebooks"></a>Quick tour of Jupyter/iPython Notebooks</h3><p>Jupyter notebook（又称IPython notebook）是一个交互式的笔记本，支持运行超过40种编程语言。本课程所有的编程练习题都将在Jupyter notebook上进行，使用的语言是python。</p><p>关于Jupyter notebook的简介和使用方法可以看我的另外两篇博客：</p><p><a href="http://blog.csdn.net/red_stone1/article/details/72858962" target="_blank" rel="noopener">Jupyter notebook入门教程（上）</a></p><p><a href="http://blog.csdn.net/red_stone1/article/details/72863749" target="_blank" rel="noopener">Jupyter notebook入门教程（下）</a></p><h3 id="Explanation-of-logistic-regression-cost-function-optional"><a href="#Explanation-of-logistic-regression-cost-function-optional" class="headerlink" title="Explanation of logistic regression cost function(optional)"></a>Explanation of logistic regression cost function(optional)</h3><p>在上一节课的笔记中，我们介绍过逻辑回归的Cost function。接下来我们将简要解释这个Cost function是怎么来的。</p><p>首先，预测输出$\hat y$的表达式可以写成：</p><p>$$\hat y=\sigma(w^Tx+b)$$</p><p>其中，$\sigma(z)=\frac{1}{1+exp(-z)}$。$\hat y$可以看成是预测输出为正类（+1）的概率：</p><p>$$\hat y=P(y=1|x)$$</p><p>那么，当y=1时：</p><p>$$p(y|x)=\hat y$$</p><p>当y=0时：</p><p>$$p(y|x)=1-\hat y$$</p><p>我们把上面两个式子整合到一个式子中，得到：</p><p>$$P(y|x)=\hat y^y(1-\hat y)^{(1-y)}$$</p><p>由于log函数的单调性，可以对上式P(y|x)进行log处理：</p><p>$$log\ P(y|x)=log\ \hat y^y(1-\hat y)^{(1-y)}=y\ log\ \hat y+(1-y)log(1-\hat y)$$</p><p>我们希望上述概率P(y|x)越大越好，对上式加上负号，则转化成了单个样本的Loss function，越小越好，也就得到了我们之前介绍的逻辑回归的Loss function形式。</p><p>$$L=-(y\ log\ \hat y+(1-y)log(1-\hat y))$$</p><p>如果对于所有m个训练样本，假设样本之间是独立同分布的（iid），我们希望总的概率越大越好：</p><p>$$max\ \prod_{i=1}^m\ P(y^{(i)}|x^{(i)})$$</p><p>同样引入log函数，加上负号，将上式转化为Cost function：</p><p>$$J(w,b)=-\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac 1m\sum_{i=1}^my^{(i)}\ log\ \hat y^{(i)}+(1-y^{(i)})log(1-\hat y^{(i)})$$</p><p>上式中，$\frac1m$表示对所有m个样本的Cost function求平均，是缩放因子。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课我们主要介绍了神经网络基础——python和向量化。在深度学习程序中，使用向量化和矩阵运算的方法能够大大提高运行速度，节省时间。以逻辑回归为例，我们将其算法流程包括梯度下降转换为向量化的形式。同时，我们也介绍了python的相关编程方法和技巧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170926163908656?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达神经网络与深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://redstonewill.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Coursera" scheme="https://redstonewill.github.io/tags/Coursera/"/>
    
      <category term="吴恩达" scheme="https://redstonewill.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
  </entry>
  
  <entry>
    <title>Coursera吴恩达《神经网络与深度学习》课程笔记（2）-- 神经网络基础之逻辑回归</title>
    <link href="https://redstonewill.github.io/2018/03/20/35/"/>
    <id>https://redstonewill.github.io/2018/03/20/35/</id>
    <published>2018-03-20T12:06:57.000Z</published>
    <updated>2018-03-20T12:18:40.344Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170926082756271?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要对深度学习（Deep Learning）的概念做了简要的概述。我们先从房价预测的例子出发，建立了标准的神经网络（Neural Network）模型结构。然后从监督式学习入手，介绍了Standard NN，CNN和RNN三种不同的神经网络模型。接着介绍了两种不同类型的数据集：Structured Data和Unstructured Data。最后，我们解释了近些年来深度学习性能优于传统机器学习的原因，归结为三个因素：Data，Computation和Algorithms。本节课，我们将开始介绍神经网络的基础：逻辑回归（Logistic Regression）。通过对逻辑回归模型结构的分析，为我们后面学习神经网络模型打下基础。</p><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><p>我们知道逻辑回归模型一般用来解决二分类（Binary Classification）问题。二分类就是输出y只有{0,1}两个离散值（也有{-1,1}的情况）。我们以一个图像识别问题为例，判断图片中是否有猫存在，0代表noncat，1代表cat。主要是通过这个例子简要介绍神经网络模型中一些标准化的、有效率的处理方法和notations。</p><p><img src="http://img.blog.csdn.net/20170926082756271?" alt="这里写图片描述"></p><p>如上图所示，这是一个典型的二分类问题。一般来说，彩色图片包含RGB三个通道。例如该cat图片的尺寸为（64，64，3）。在神经网络模型中，我们首先要将图片输入x（维度是（64，64，3））转化为一维的特征向量（feature vector）。方法是每个通道一行一行取，再连接起来。由于64x64x3=12288，则转化后的输入特征向量维度为（12288，1）。此特征向量x是列向量，维度一般记为$n_x$。</p><p>如果训练样本共有m张图片，那么整个训练样本X组成了矩阵，维度是（$n_x$，m）。注意，这里矩阵X的行$n_x$代表了每个样本$x^{(i)}$特征个数，列m代表了样本个数。这里，Andrew解释了X的维度之所以是（$n_x$，m）而不是（m，$n_x$）的原因是为了之后矩阵运算的方便。算是Andrew给我们的一个小小的经验吧。而所有训练样本的输出Y也组成了一维的行向量，写成矩阵的形式后，它的维度就是（1，m）。</p><h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><p>接下来我们就来介绍如何使用逻辑回归来解决二分类问题。逻辑回归中，预测值$\hat h=P(y=1\ |\ x)$表示为1的概率，取值范围在[0,1]之间。这是其与二分类模型不同的地方。使用线性模型，引入参数w和b。权重w的维度是（$n_x$，1），b是一个常数项。这样，逻辑回归的线性预测输出可以写成：</p><p>$$\hat y = w^Tx+b$$</p><p>值得注意的是，很多其它机器学习资料中，可能把常数b当做$w_0$处理，并引入$x_0=1$。这样从维度上来看，x和w都会增加一维。但在本课程中，为了简化计算和便于理解，Andrew建议还是使用上式这种形式将w和b分开比较好。</p><p>上式的线性输出区间为整个实数范围，而逻辑回归要求输出范围在[0,1]之间，所以还需要对上式的线性函数输出进行处理。方法是引入Sigmoid函数，让输出限定在[0,1]之间。这样，逻辑回归的预测输出就可以完整写成：</p><p>$$\hat y = Sigmoid(w^Tx+b)=\sigma(w^Tx+b)$$</p><p>Sigmoid函数是一种非线性的S型函数，输出被限定在[0,1]之间，通常被用在神经网络中当作激活函数（Activation function）使用。Sigmoid函数的表达式和曲线如下所示：</p><p>$$Sigmoid(z)=\frac{1}{1+e^{-z}}$$</p><p><img src="http://img.blog.csdn.net/20170906231842576?" alt="这里写图片描述"></p><p>从Sigmoid函数曲线可以看出，当z值很大时，函数值趋向于1；当z值很小时，函数值趋向于0。且当z=0时，函数值为0.5。还有一点值得注意的是，Sigmoid函数的一阶导数可以用其自身表示：</p><p>$$\sigma’(z)=\sigma(z)(1-\sigma(z))$$</p><p>这样，通过Sigmoid函数，就能够将逻辑回归的输出限定在[0,1]之间了。</p><h3 id="Logistic-Regression-Cost-Function"><a href="#Logistic-Regression-Cost-Function" class="headerlink" title="Logistic Regression Cost Function"></a>Logistic Regression Cost Function</h3><p>逻辑回归中，w和b都是未知参数，需要反复训练优化得到。因此，我们需要定义一个cost function，包含了参数w和b。通过优化cost function，当cost function取值最小时，得到对应的w和b。</p><p>提一下，对于m个训练样本，我们通常使用上标来表示对应的样本。例如$(x^{(i)},y^{(i)})$表示第i个样本。</p><p>如何定义所有m个样本的cost function呢？先从单个样本出发，我们希望该样本的预测值$\hat y$与真实值越相似越好。我们把单个样本的cost function用Loss function来表示，根据以往经验，如果使用平方错误（squared error）来衡量，如下所示：</p><p>$$L(\hat y,y)=\frac12(\hat y-y)^2$$</p><p>但是，对于逻辑回归，我们一般不使用平方错误来作为Loss function。原因是这种Loss function一般是non-convex的。non-convex函数在使用梯度下降算法时，容易得到局部最小值（local minumum），即局部最优化。而我们最优化的目标是计算得到全局最优化（Global optimization）。因此，我们一般选择的Loss function应该是convex的。</p><p>Loss function的原则和目的就是要衡量预测输出$\hat y$与真实样本输出y的接近程度。平方错误其实也可以，只是它是non-convex的，不利于使用梯度下降算法来进行全局优化。因此，我们可以构建另外一种Loss function，且是convex的，如下所示：</p><p>$$L(\hat y,y)=-(ylog\ \hat y+(1-y)log\ (1-\hat y))$$</p><p>我们来分析一下这个Loss function，它是衡量错误大小的，Loss function越小越好。</p><p>当y=1时，$L(\hat y,y)=-log\ \hat y$。如果$\hat y$越接近1，$L(\hat y,y)\approx 0$，表示预测效果越好；如果$\hat y$越接近0，$L(\hat y,y)\approx +\infty$，表示预测效果越差。这正是我们希望Loss function所实现的功能。</p><p>当y=0时，$L(\hat y,y)=-log\ (1-\hat y)$。如果$\hat y$越接近0，$L(\hat y,y)\approx 0$，表示预测效果越好；如果$\hat y$越接近1，$L(\hat y,y)\approx +\infty$，表示预测效果越差。这也正是我们希望Loss function所实现的功能。</p><p>因此，这个Loss function能够很好地反映预测输出$\hat y$与真实样本输出y的接近程度，越接近的话，其Loss function值越小。而且这个函数是convex的。上面我们只是简要地分析为什么要使用这个Loss function，后面的课程中，我们将详细推导该Loss function是如何得到的。并不是凭空捏造的哦。。。</p><p>还要提一点的是，上面介绍的Loss function是针对单个样本的。那对于m个样本，我们定义Cost function，Cost function是m个样本的Loss function的平均值，反映了m个样本的预测输出$\hat y$与真实样本输出y的平均接近程度。Cost function可表示为：</p><p>$$J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]$$</p><p>Cost function已经推导出来了，Cost function是关于待求系数w和b的函数。我们的目标就是迭代计算出最佳的w和b值，最小化Cost function，让Cost function尽可能地接近于零。</p><p>其实逻辑回归问题可以看成是一个简单的神经网络，只包含一个神经元。这也是我们这里先介绍逻辑回归的原因。</p><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><p>我们已经掌握了Cost function的表达式，接下来将使用梯度下降（Gradient Descent）算法来计算出合适的w和b值，从而最小化m个训练样本的Cost function，即J(w,b)。</p><p>由于J(w,b)是convex function，梯度下降算法是先随机选择一组参数w和b值，然后每次迭代的过程中分别沿着w和b的梯度（偏导数）的反方向前进一小步，不断修正w和b。每次迭代更新w和b后，都能让J(w,b)更接近全局最小值。梯度下降的过程如下图所示。</p><p><img src="http://img.blog.csdn.net/20170926083044469?" alt="这里写图片描述"></p><p>梯度下降算法每次迭代更新，w和b的修正表达式为：</p><p>$$w:=w-\alpha\frac{\partial J(w,b)}{\partial w}$$</p><p>$$b:=b-\alpha\frac{\partial J(w,b)}{\partial b}$$</p><p>上式中，$\alpha$是学习因子（learning rate），表示梯度下降的步进长度。$\alpha$越大，w和b每次更新的“步伐”更大一些；$\alpha$越小，w和b每次更新的“步伐”更小一些。在程序代码中，我们通常使用dw来表示$\frac{\partial J(w,b)}{\partial w}$，用db来表示$\frac{\partial J(w,b)}{\partial b}$。微积分里，$\frac{df}{dx}$表示对单一变量求导数，$\frac{\partial f}{\partial x}$表示对多个变量中某个变量求偏导数。</p><p>梯度下降算法能够保证每次迭代w和b都能向着J(w,b)全局最小化的方向进行。其数学原理主要是运用泰勒一阶展开来证明的，可以参考我的另一篇博客中的Gradient Descent有提到如何推导：<a href="http://blog.csdn.net/red_stone1/article/details/72229903" target="_blank" rel="noopener">台湾大学林轩田机器学习基石课程学习笔记10 – Logistic Regression</a></p><h3 id="Derivatives"><a href="#Derivatives" class="headerlink" title="Derivatives"></a>Derivatives</h3><p>这一部分的内容非常简单，Andrew主要是给对微积分、求导数不太清楚的同学介绍的。梯度或者导数一定程度上可以看成是斜率。关于求导数的方法这里就不再赘述了。</p><h3 id="More-Derivative-Examples"><a href="#More-Derivative-Examples" class="headerlink" title="More Derivative Examples"></a>More Derivative Examples</h3><p>Andrew给出了更加复杂的求导数的例子，略。</p><h3 id="Computation-graph"><a href="#Computation-graph" class="headerlink" title="Computation graph"></a>Computation graph</h3><p>整个神经网络的训练过程实际上包含了两个过程：正向传播（Forward Propagation）和反向传播（Back Propagation）。正向传播是从输入到输出，由神经网络计算得到预测输出的过程；反向传播是从输出到输入，对参数w和b计算梯度的过程。下面，我们用计算图（Computation graph）的形式来理解这两个过程。</p><p>举个简单的例子，假如Cost function为J(a,b,c)=3(a+bc)，包含a，b，c三个变量。我们用u表示bc，v表示a+u，则J=3v。它的计算图可以写成如下图所示：</p><p><img src="http://img.blog.csdn.net/20170926083150863?" alt="这里写图片描述"></p><p>令a=5，b=3，c=2，则u=bc=6，v=a+u=11，J=3v=33。计算图中，这种从左到右，从输入到输出的过程就对应着神经网络或者逻辑回归中输入与权重经过运算计算得到Cost function的正向过程。</p><h3 id="Derivatives-with-a-Computation-Graph"><a href="#Derivatives-with-a-Computation-Graph" class="headerlink" title="Derivatives with a Computation Graph"></a>Derivatives with a Computation Graph</h3><p>上一部分介绍的是计算图的正向传播（Forward Propagation），下面我们来介绍其反向传播（Back Propagation），即计算输出对输入的偏导数。</p><p>还是上个计算图的例子，输入参数有3个，分别是a，b，c。</p><p>首先计算J对参数a的偏导数。从计算图上来看，从右到左，J是v的函数，v是a的函数。则利用求导技巧，可以得到：</p><p>$$\frac{\partial J}{\partial a}=\frac{\partial J}{\partial v}\cdot \frac{\partial v}{\partial a}=3\cdot 1=3$$</p><p>根据这种思想，然后计算J对参数b的偏导数。从计算图上来看，从右到左，J是v的函数，v是u的函数，u是b的函数。可以推导：</p><p>$$\frac{\partial J}{\partial b}=\frac{\partial J}{\partial v}\cdot \frac{\partial v}{\partial u}\cdot \frac{\partial u}{\partial b}=3\cdot 1\cdot c=3\cdot 1\cdot 2=6$$</p><p>最后计算J对参数c的偏导数。仍从计算图上来看，从右到左，J是v的函数，v是u的函数，u是c的函数。可以推导：</p><p>$$\frac{\partial J}{\partial c}=\frac{\partial J}{\partial v}\cdot \frac{\partial v}{\partial u}\cdot \frac{\partial u}{\partial c}=3\cdot 1\cdot b=3\cdot 1\cdot 3=9$$</p><p>为了统一格式，在程序代码中，我们使用da，db，dc来表示J对参数a，b，c的偏导数。</p><p><img src="http://img.blog.csdn.net/20170926083227668?" alt="这里写图片描述"></p><h3 id="Logistic-Regression-Gradient-Descent"><a href="#Logistic-Regression-Gradient-Descent" class="headerlink" title="Logistic Regression Gradient Descent"></a>Logistic Regression Gradient Descent</h3><p>现在，我们将对逻辑回归进行梯度计算。对单个样本而言，逻辑回归Loss function表达式如下：</p><p>$$z=w^Tx+b$$</p><p>$$\hat y=a=\sigma(z)$$</p><p>$$L(a,y)=-(ylog(a)+(1-y)log(1-a))$$</p><p>首先，该逻辑回归的正向传播过程非常简单。根据上述公式，例如输入样本x有两个特征$(x_1,x_2)$，相应的权重w维度也是2，即$(w_1,w_2)$。则$z=w_1x_1+w_2x_2+b$，最后的Loss function如下所示：</p><p><img src="http://img.blog.csdn.net/20170926083257736?" alt="这里写图片描述"></p><p>然后，计算该逻辑回归的反向传播过程，即由Loss function计算参数w和b的偏导数。推导过程如下：</p><p>$$da=\frac{\partial L}{\partial a}=-\frac ya+\frac{1-y}{1-a}$$</p><p>$$dz=\frac{\partial L}{\partial z}=\frac{\partial L}{\partial a}\cdot \frac{\partial a}{\partial z}=(-\frac ya+\frac{1-y}{1-a})\cdot a(1-a)=a-y$$</p><p>知道了dz之后，就可以直接对$w_1$，$w_2$和b进行求导了。</p><p>$$dw_1=\frac{\partial L}{\partial w_1}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_1}=x_1\cdot dz=x_1(a-y)$$</p><p>$$dw_2=\frac{\partial L}{\partial w_2}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_2}=x_2\cdot dz=x_2(a-y)$$</p><p>$$db=\frac{\partial L}{\partial b}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial b}=1\cdot dz=a-y$$</p><p>则梯度下降算法可表示为：</p><p>$$w_1:=w_1-\alpha\ dw_1$$</p><p>$$w_2:=w_2-\alpha\ dw_2$$</p><p>$$b:=b-\alpha\ db$$</p><p><img src="http://img.blog.csdn.net/20170926083336211?" alt="这里写图片描述"></p><h3 id="Gradient-descent-on-m-examples"><a href="#Gradient-descent-on-m-examples" class="headerlink" title="Gradient descent on m examples"></a>Gradient descent on m examples</h3><p>上一部分讲的是对单个样本求偏导和梯度下降。如果有m个样本，其Cost function表达式如下：</p><p>$$z^{(i)}=w^Tx^{(i)}+b$$</p><p>$$\hat y^{(i)}=a^{(i)}=\sigma(z^{(i)})$$</p><p>$$J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]$$</p><p>Cost function关于w和b的偏导数可以写成和平均的形式：</p><p>$$dw_1=\frac1m\sum_{i=1}^mx_1^{(i)}(a^{(i)}-y^{(i)})$$</p><p>$$dw_2=\frac1m\sum_{i=1}^mx_2^{(i)}(a^{(i)}-y^{(i)})$$</p><p>$$db=\frac1m\sum_{i=1}^m(a^{(i)}-y^{(i)})$$</p><p>这样，每次迭代中w和b的梯度有m个训练样本计算平均值得到。其算法流程图如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">J=0; dw1=0; dw2=0; db=0;</span><br><span class="line">for i = 1 to m</span><br><span class="line">z(i) = wx(i)+b;</span><br><span class="line">a(i) = sigmoid(z(i));</span><br><span class="line">J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i));</span><br><span class="line">dz(i) = a(i)-y(i);</span><br><span class="line">dw1 += x1(i)dz(i);</span><br><span class="line">dw2 += x2(i)dz(i);</span><br><span class="line">db += dz(i);</span><br><span class="line">J /= m;</span><br><span class="line">dw1 /= m;</span><br><span class="line">dw2 /= m;</span><br><span class="line">db /= m;</span><br></pre></td></tr></table></figure><p>经过每次迭代后，根据梯度下降算法，w和b都进行更新：</p><p>$$w_1:=w_1-\alpha\ dw_1$$</p><p>$$w_2:=w_2-\alpha\ dw_2$$</p><p>$$b:=b-\alpha\ db$$</p><p>这样经过n次迭代后，整个梯度下降算法就完成了。</p><p>值得一提的是，在上述的梯度下降算法中，我们是利用for循环对每个样本进行dw1，dw2和db的累加计算最后再求平均数的。在深度学习中，样本数量m通常很大，使用for循环会让神经网络程序运行得很慢。所以，我们应该尽量避免使用for循环操作，而使用矩阵运算，能够大大提高程序运行速度。关于vectorization的内容我们放在下次笔记中再说。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课的内容比较简单，主要介绍了神经网络的基础——逻辑回归。首先，我们介绍了二分类问题，以图片为例，将多维输入x转化为feature vector，输出y只有{0,1}两个离散值。接着，我们介绍了逻辑回归及其对应的Cost function形式。然后，我们介绍了梯度下降算法，并使用计算图的方式来讲述神经网络的正向传播和反向传播两个过程。最后，我们在逻辑回归中使用梯度下降算法，总结出最优化参数w和b的算法流程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170926082756271?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达神经网络与深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://redstonewill.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Coursera" scheme="https://redstonewill.github.io/tags/Coursera/"/>
    
      <category term="吴恩达" scheme="https://redstonewill.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
  </entry>
  
  <entry>
    <title>Coursera吴恩达《神经网络与深度学习》课程笔记（1）-- 深度学习概述</title>
    <link href="https://redstonewill.github.io/2018/03/19/34/"/>
    <id>https://redstonewill.github.io/2018/03/19/34/</id>
    <published>2018-03-19T13:32:32.000Z</published>
    <updated>2018-03-19T13:36:37.919Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170925093517265?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>吴恩达（Andrew Ng）相信大家都不陌生了。8 月 8 日，吴恩达在他自己创办的在线教育平台 Coursera 上线了他的人工智能专项课程（Deep Learning Specialization）。此课程广受好评，通过视频讲解、作业与测验等让更多的人对人工智能有了了解与启蒙，国外媒体报道称：吴恩达这次深度学习课程是迄今为止，最全面、系统和容易获取的深度学习课程，堪称普通人的人工智能第一课。</p><p>该专项课程的Coursera地址：<a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">https://www.coursera.org/specializations/deep-learning</a></p><p>另外，网易云课堂前段时间宣布跟吴恩达合作，拿到了独家版权，开设了深度学习微专业课，并且提供中文字幕翻译，降低了学习门槛。但是只有视频和课件材料，没有Coursera 上的作业、考试等环节，也不会提供证书，需要证书的还得去 Coursera 上学习。这里附上网易云课堂该专项课程的地址：<a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank" rel="noopener">http://mooc.study.163.com/smartSpec/detail/1001319001.htm</a></p><p>好了，在接下来的一段时间里，我将同步开始学习Coursera上深度学习专项课程，并将笔记以博客的形式记录下来。专项课程的第一门课是《神经网络与深度学习》。今天介绍第一讲：深度学习概述。</p><h3 id="What-is-a-neural-network"><a href="#What-is-a-neural-network" class="headerlink" title="What is a neural network?"></a>What is a neural network?</h3><p>简单来说，深度学习（Deep Learning）就是更复杂的神经网络（Neural Network）。那么，什么是神经网络呢？下面我们将通过一个简单的例子来引入神经网络模型的概念。</p><p>假如我们要建立房价的预测模型，一共有六个房子。我们已知输入x即每个房子的面积（多少尺或者多少平方米），还知道其对应的输出y即每个房子的价格。根据这些输入输出，我们要建立一个函数模型，来预测房价：y=f(x)。首先，我们将已知的六间房子的价格和面积的关系绘制在二维平面上，如下图所示：</p><p><img src="http://img.blog.csdn.net/20170925093517265?" alt="这里写图片描述"></p><p>一般地，我们会一条直线来拟合图中这些离散点，即建立房价与面积的线性模型。但是从实际考虑，我们知道价格永远不会是负数。所以，我们对该直线做一点点修正，让它变成折线的形状，当面积小于某个值时，价格始终为零。如下图蓝色折线所示，就是我们建立的房价预测模型。</p><p><img src="http://img.blog.csdn.net/20170925093612288?" alt="这里写图片描述"></p><p>其实这个简单的模型（蓝色折线）就可以看成是一个神经网络，而且几乎是一个最简单的神经网络。我们把该房价预测用一个最简单的神经网络模型来表示，如下图所示：</p><p><img src="http://img.blog.csdn.net/20170925093652899?" alt="这里写图片描述"></p><p>该神经网络的输入x是房屋面积，输出y是房屋价格，中间包含了一个神经元（neuron），即房价预测函数（蓝色折线）。该神经元的功能就是实现函数f(x)的功能。</p><p>值得一提的是，上图神经元的预测函数（蓝色折线）在神经网络应用中比较常见。我们把这个函数称为ReLU函数，即线性整流函数（Rectified Linear Unit），形如下图所示：</p><p><img src="http://img.blog.csdn.net/20170902133054327?" alt="这里写图片描述"></p><p>上面讲的只是由单个神经元（输入x仅仅是房屋面积一个因素）组成的神经网络，而通常一个大型的神经网络往往由许多神经元组成，就像通过乐高积木搭建复杂物体（例如火车）一样。</p><p>现在，我们把上面举的房价预测的例子变得复杂一些，而不是仅仅使用房屋面积一个判断因素。例如，除了考虑房屋面积（size）之外，我们还考虑卧室数目（#bedrooms）。这两点实际上与家庭成员的个数（family size）有关。还有，房屋的邮政编码（zip code/postal code），代表了该房屋位置的交通便利性，是否需要步行还是开车？即决定了可步行性（walkability）。另外，还有可能邮政编码和地区财富水平（wealth）共同影响了房屋所在地区的学校质量（school quality）。如下图所示，该神经网络共有三个神经元，分别代表了family size，walkability和school quality。每一个神经元都包含了一个ReLU函数（或者其它非线性函数）。那么，根据这个模型，我们可以根据房屋的面积和卧室个数来估计family size，根据邮政编码来估计walkability，根据邮政编码和财富水平来估计school quality。最后，由family size，walkability和school quality等这些人们比较关心的因素来预测最终的房屋价格。</p><p><img src="http://img.blog.csdn.net/20170925093733914?" alt="这里写图片描述"></p><p>所以，在这个例子中，x是size，#bedrooms，zip code/postal code和wealth这四个输入；y是房屋的预测价格。这个神经网络模型包含的神经元个数更多一些，相对之前的单个神经元的模型要更加复杂。那么，在建立一个表现良好的神经网络模型之后，在给定输入x时，就能得到比较好的输出y，即房屋的预测价格。</p><p>实际上，上面这个例子真正的神经网络模型结构如下所示。它有四个输入，分别是size，#bedrooms，zip code和wealth。在给定这四个输入后，神经网络所做的就是输出房屋的预测价格y。图中，三个神经元所在的位置称之为中间层或者隐藏层（x所在的称之为输入层，y所在的称之为输出层），每个神经元与所有的输入x都有关联（直线相连）。</p><p><img src="http://img.blog.csdn.net/20170925094655458?" alt="这里写图片描述"></p><p>这就是基本的神经网络模型结构。在训练的过程中，只要有足够的输入x和输出y，就能训练出较好的神经网络模型，该模型在此类房价预测问题中，能够得到比较准确的结果。</p><h3 id="Supervised-Learning-with-Neural-Networks"><a href="#Supervised-Learning-with-Neural-Networks" class="headerlink" title="Supervised Learning with Neural Networks"></a>Supervised Learning with Neural Networks</h3><p>目前为止，由神经网络模型创造的价值基本上都是基于监督式学习（Supervised Learning）的。监督式学习与非监督式学习本质区别就是是否已知训练样本的输出y。在实际应用中，机器学习解决的大部分问题都属于监督式学习，神经网络模型也大都属于监督式学习。下面我们来看几个监督式学习在神经网络中应用的例子。</p><p>首先，第一个例子还是房屋价格预测。根据训练样本的输入x和输出y，训练神经网络模型，预测房价。第二个例子是线上广告，这是深度学习最广泛、最赚钱的应用之一。其中，输入x是广告和用户个人信息，输出y是用户是否对广告进行点击。神经网络模型经过训练，能够根据广告类型和用户信息对用户的点击行为进行预测，从而向用户提供用户自己可能感兴趣的广告。第三个例子是电脑视觉（computer vision）。电脑视觉是近些年来越来越火的课题，而电脑视觉发展迅速的原因很大程度上是得益于深度学习。其中，输入x是图片像素值，输出是图片所属的不同类别。第四个例子是语音识别（speech recognition）。深度学习可以将一段语音信号辨识为相应的文字信息。第五个例子是智能翻译，例如通过神经网络输入英文，然后直接输出中文。除此之外，第六个例子是自动驾驶。通过输入一张图片或者汽车雷达信息，神经网络通过训练来告诉你相应的路况信息并作出相应的决策。至此，神经网络配合监督式学习，其应用是非常广泛的。</p><p><img src="http://img.blog.csdn.net/20170925094723928?" alt="这里写图片描述"></p><p>我们应该知道，根据不同的问题和应用场合，应该使用不同类型的神经网络模型。例如上面介绍的几个例子中，对于一般的监督式学习（房价预测和线上广告问题），我们只要使用标准的神经网络模型就可以了。而对于图像识别处理问题，我们则要使用卷积神经网络（Convolution Neural Network），即CNN。而对于处理类似语音这样的序列信号时，则要使用循环神经网络（Recurrent Neural Network），即RNN。还有其它的例如自动驾驶这样的复杂问题则需要更加复杂的混合神经网络模型。</p><p>CNN和RNN是比较常用的神经网络模型。下图给出了Standard NN，Convolutional NN和Recurrent NN的神经网络结构图。</p><p><img src="http://img.blog.csdn.net/20170925095229513?" alt="这里写图片描述"></p><p>CNN一般处理图像问题，RNN一般处理语音信号。他们的结构是什么意思？如何实现CNN和RNN的结构？这些问题我们将在以后的课程中来深入分析并解决。</p><p>另外，数据类型一般分为两种：Structured Data和Unstructured Data。</p><p><img src="http://img.blog.csdn.net/20170925095423087?" alt="这里写图片描述"></p><p>简单地说，Structured Data通常指的是有实际意义的数据。例如房价预测中的size，#bedrooms，price等；例如在线广告中的User Age，Ad ID等。这些数据都具有实际的物理意义，比较容易理解。而Unstructured Data通常指的是比较抽象的数据，例如Audio，Image或者Text。以前，计算机对于Unstructured Data比较难以处理，而人类对Unstructured Data却能够处理的比较好，例如我们第一眼很容易就识别出一张图片里是否有猫，但对于计算机来说并不那么简单。现在，值得庆幸的是，由于深度学习和神经网络的发展，计算机在处理Unstructured Data方面效果越来越好，甚至在某些方面优于人类。总的来说，神经网络与深度学习无论对Structured Data还是Unstructured Data都能处理得越来越好，并逐渐创造出巨大的实用价值。我们在之后的学习和实际应用中也将会碰到许多Structured Data和Unstructured Data。</p><h3 id="Why-is-Deep-Learning-taking-off？"><a href="#Why-is-Deep-Learning-taking-off？" class="headerlink" title="Why is Deep Learning taking off？"></a>Why is Deep Learning taking off？</h3><p>如果说深度学习和神经网络背后的技术思想已经出现数十年了，那么为什么直到现在才开始发挥作用呢？接下来，我们来看一下深度学习背后的主要动力是什么，方便我们更好地理解并使用深度学习来解决更多问题。</p><p>深度学习为什么这么强大？下面我们用一张图来说明。如下图所示，横坐标x表示数据量（Amount of data），纵坐标y表示机器学习模型的性能表现（Performance）。</p><p><img src="http://img.blog.csdn.net/20170925095445485?" alt="这里写图片描述"></p><p>上图共有4条曲线。其中，最底下的那条红色曲线代表了传统机器学习算法的表现，例如是SVM，logistic regression，decision tree等。当数据量比较小的时候，传统学习模型的表现是比较好的。但是当数据量很大的时候，其表现很一般，性能基本趋于水平。红色曲线上面的那条黄色曲线代表了规模较小的神经网络模型（Small NN）。它在数据量较大时候的性能优于传统的机器学习算法。黄色曲线上面的蓝色曲线代表了规模中等的神经网络模型（Media NN），它在在数据量更大的时候的表现比Small NN更好。最上面的那条绿色曲线代表更大规模的神经网络（Large NN），即深度学习模型。从图中可以看到，在数据量很大的时候，它的表现仍然是最好的，而且基本上保持了较快上升的趋势。值得一提的是，近些年来，由于数字计算机的普及，人类进入了大数据时代，每时每分，互联网上的数据是海量的、庞大的。如何对大数据建立稳健准确的学习模型变得尤为重要。传统机器学习算法在数据量较大的时候，性能一般，很难再有提升。然而，深度学习模型由于网络复杂，对大数据的处理和分析非常有效。所以，近些年来，在处理海量数据和建立复杂准确的学习模型方面，深度学习有着非常不错的表现。然而，在数据量不大的时候，例如上图中左边区域，深度学习模型不一定优于传统机器学习算法，性能差异可能并不大。</p><p>所以说，现在深度学习如此强大的原因归结为三个因素：</p><ul><li><p><strong>Data</strong></p></li><li><p><strong>Computation</strong></p></li><li><p><strong>Algorithms</strong></p></li></ul><p>其中，数据量的几何级数增加，加上GPU出现、计算机运算能力的大大提升，使得深度学习能够应用得更加广泛。另外，算法上的创新和改进让深度学习的性能和速度也大大提升。举个算法改进的例子，之前神经网络神经元的激活函数是Sigmoid函数，后来改成了ReLU函数。之所以这样更改的原因是对于Sigmoid函数，在远离零点的位置，函数曲线非常平缓，其梯度趋于0，所以造成神经网络模型学习速度变得很慢。然而，ReLU函数在x大于零的区域，其梯度始终为1，尽管在x小于零的区域梯度为0，但是在实际应用中采用ReLU函数确实要比Sigmoid函数快很多。</p><p>构建一个深度学习的流程是首先产生Idea，然后将Idea转化为Code，最后进行Experiment。接着根据结果修改Idea，继续这种Idea-&gt;Code-&gt;Experiment的循环，直到最终训练得到表现不错的深度学习网络模型。如果计算速度越快，每一步骤耗时越少，那么上述循环越能高效进行。</p><h3 id="About-this-Course"><a href="#About-this-Course" class="headerlink" title="About this Course"></a>About this Course</h3><p>这里简单列一下本系列深度学习专项课程有哪些：</p><ul><li><p><strong>Neural Networks and Deep Learning</strong></p></li><li><p><strong>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</strong></p></li><li><p><strong>Structuring your Machine Learning project</strong></p></li><li><p><strong>Convolutional Neural Networks</strong></p></li><li><p><strong>Natural Language Processing: Building sequence models</strong></p></li></ul><p>目前我们正在学习的是第一门课《Neural Networks and Deep Learning》。Coursera上关于这门课的教学日程安排如下：</p><ul><li><p><strong>Week 1: Introduction</strong></p></li><li><p><strong>Week 2: Basics of Neural Network programming</strong></p></li><li><p><strong>Week 3: One hidden layer Neural Networks</strong></p></li><li><p><strong>Week 4: Deep Neural Networks</strong></p></li></ul><p>这门课我打算用5次笔记进行总结。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课的内容比较简单，主要对深度学习进行了简要概述。首先，我们使用房价预测的例子来建立最简单的但个神经元组成的神经网络模型。然后，我们将例子复杂化，建立标准的神经网络模型结构。接着，我们从监督式学习入手，介绍了不同的神经网络类型，包括Standard NN，CNN和RNN。不同的神经网络模型适合处理不同类型的问题。对数据集本身来说，分为Structured Data和Unstructured Data。近些年来，深度学习对Unstructured Data的处理能力大大提高，例如图像处理、语音识别和语言翻译等。最后，我们用一张对比图片解释了深度学习现在飞速发展、功能强大的原因。归纳其原因包含三点：Data，Computation和Algorithms。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170925093517265?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达神经网络与深度学习" scheme="https://redstonewill.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="深度学习" scheme="https://redstonewill.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://redstonewill.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Coursera" scheme="https://redstonewill.github.io/tags/Coursera/"/>
    
      <category term="吴恩达" scheme="https://redstonewill.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记16（完结） -- Finale</title>
    <link href="https://redstonewill.github.io/2018/03/18/33/"/>
    <id>https://redstonewill.github.io/2018/03/18/33/</id>
    <published>2018-03-18T06:42:22.000Z</published>
    <updated>2018-03-18T06:44:06.907Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170820202309144?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Matrix Factorization。通过电影推荐系统的例子，介绍Matrix Factorization其实是一个提取用户特征，关于电影的线性模型。反过来也可以看出是关于用户的线性模型。然后，我们使用SGD对模型进行最佳化。本节课我们将对机器学习技法课程介绍过的所有内容做个总结，分成三个部分：Feature Exploitation Techniques，Error Optimization Techniques和Overfitting Elimination Techniques。</p><h3 id="Feature-Exploitation-Techniques"><a href="#Feature-Exploitation-Techniques" class="headerlink" title="Feature Exploitation Techniques"></a>Feature Exploitation Techniques</h3><p>我们在本系列课程中介绍的第一个特征提取的方法就是kernel。Kernel运算将特征转换和计算内积这两个步骤合二为一，提高了计算效率。我们介绍过的kernel有：Polynormial Kernel、Gaussian Kernel、Stump Kernel等。另外，我们可以将不同的kernels相加（transform union）或者相乘（transform combination），得到不同的kernels的结合形式，让模型更加复杂。值得一提的是，要成为kernel，必须满足Mercer Condition。不同的kernel可以搭配不同的kernel模型，比如：SVM、SVR和probabilistic SVM等，还包括一些不太常用的模型：kernel ridge regression、kernel logistic regression。使用这些kernel模型就可以将线性模型扩展到非线性模型，kernel就是实现一种特征转换，从而能够处理非常复杂的非线性模型。顺便提一下，因为PCA、k-Means等算法都包含了内积运算，所以它们都对应有相应的kernel版本。</p><p><img src="http://img.blog.csdn.net/20170820202309144?" alt="这里写图片描述"></p><p>Kernel是我们利用特征转换的第一种方法，那利用特征转换的第二种方法就是Aggregation。我们之前介绍的所有的hypothesis都可以看成是一种特征转换，然后再由这些g组合成G。我们介绍过的分类模型（hypothesis）包括：Decision Stump、Decision Tree和Gaussian RBF等。如果所有的g是已知的，就可以进行blending，例如Uniform、Non-Uniform和Conditional等方式进行aggregation。如果所有的g是未知的，可以使用例如Bagging、AdaBoost和Decision Tree的方法来建立模型。除此之外，还有probabilistic SVM模型。值得一提的是，机器学习中很多模型都是类似的，我们在设计一个机器学习模型时，应该融会贯通。</p><p><img src="http://img.blog.csdn.net/20170820205533778?" alt="这里写图片描述"></p><p>除此之外，我们还介绍了利用提取的方式，找出潜藏的特征（Hidden Features）。一般通过unsupervised learning的方法，从原始数据中提取出隐藏特征，使用权重表征。相应的模型包括：Neural Network、RBF Network、Matrix Factorization等。这些模型使用的unsupervised learning方法包括：AdaBoost、k-Means和Autoencoder、PCA等。</p><p><img src="http://img.blog.csdn.net/20170820211733400?" alt="这里写图片描述"></p><p>另外，还有一种非常有用的特征转换方法是维度压缩，即将高维度的数据降低（投影）到低维度的数据。我们介绍过的维度压缩模型包括：Decision Stump、Random Forest Tree Branching、Autoencoder、PCA和Matrix Factorization等。这些从高纬度到低纬度的特征转换在实际应用中作用很大。</p><p><img src="http://img.blog.csdn.net/20170820212320303?" alt="这里写图片描述"></p><h3 id="Error-Optimization-Techniques"><a href="#Error-Optimization-Techniques" class="headerlink" title="Error Optimization Techniques"></a>Error Optimization Techniques</h3><p>接下来我们将总结一下本系列课程中介绍过哪些优化技巧。首先，第一个数值优化技巧就是梯度下降（Gradient Descent），即让变量沿着其梯度反方向变化，不断接近最优解。例如我们介绍过的SGD、Steepest Descent和Functional GD都是利用了梯度下降的技巧。</p><p><img src="http://img.blog.csdn.net/20170821075109200?" alt="这里写图片描述"></p><p>而对于一些更复杂的最佳化问题，无法直接利用梯度下降方法来做，往往需要一些数学上的推导来得到最优解。最典型的例子是Dual SVM，还包括Kernel LogReg、Kernel RidgeReg和PCA等等。这些模型本身包含了很多数学上的一些知识，例如线性代数等等。除此之外，还有一些boosting和kernel模型，虽然本课程中没有提到，但是都会用到类似的数学推导和转换技巧。</p><p><img src="http://img.blog.csdn.net/20170821080108333?" alt="这里写图片描述"></p><p>如果原始问题比较复杂，求解比较困难，我们可以将原始问题拆分为子问题以简化计算。也就是将问题划分为多个步骤进行求解，即Multi-Stage。例如probabilistic SVM、linear blending、RBF Network等。还可以使用交叉迭代优化的方法，即Alternating Optim。例如k-Means、alternating LeastSqr等。除此之外，还可以采样分而治之的方法，即Divide &amp; Conquer。例如decision tree。</p><p><img src="http://img.blog.csdn.net/20170821081019760?" alt="这里写图片描述"></p><h3 id="Overfitting-Elimination-Techniques"><a href="#Overfitting-Elimination-Techniques" class="headerlink" title="Overfitting Elimination Techniques"></a>Overfitting Elimination Techniques</h3><p>Feature Exploitation Techniques和Error Optimization Techniques都是为了优化复杂模型，减小$E_{in}$。但是$E_{in}$太小有很可能会造成过拟合overfitting。因此，机器学习中，Overfitting Elimination尤为重要。</p><p>首先，可以使用Regularization来避免过拟合现象发生。我们介绍过的方法包括：large-margin、L2、voting/averaging等等。</p><p><img src="http://img.blog.csdn.net/20170821082118629?" alt="这里写图片描述"></p><p>除了Regularization之外，还可以使用Validation来消除Overfitting。我们介绍过的Validation包括：SV、OOB和Internal Validation等。</p><p><img src="http://img.blog.csdn.net/20170821082504296?" alt="这里写图片描述"></p><h3 id="Machine-Learning-in-Action"><a href="#Machine-Learning-in-Action" class="headerlink" title="Machine Learning in Action"></a>Machine Learning in Action</h3><p>本小节介绍了林轩田老师所在的台大团队在近几年的KDDCup国际竞赛上的表现和使用的各种机器算法。融合了我们在本系列课程中所介绍的很多机器学习技法和模型。这里不再一一赘述，将相应的图片贴出来，读者自己看看吧。</p><p><img src="http://img.blog.csdn.net/20170821082919157?" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20170821083004329?" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20170821083042817?" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20170821083128269?" alt="这里写图片描述"></p><p>ICDM在2006年的时候发布了排名前十的数据挖掘算法，如下图所示。其中大部分的算法我们在本系列的课程中都有过介绍。值得一提的是Naive Bayes算法本课程中没有涉及，贝叶斯模型在实际中应用还是挺广泛的，后续可能还需要深入学习一下。</p><p><img src="http://img.blog.csdn.net/20170821083957182?" alt="这里写图片描述"></p><p>最后，我们将所有介绍过的机器学习算法和模型列举出来：</p><p><img src="http://img.blog.csdn.net/20170821084154106?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要从三个方面来对机器学习技法课程做个总结：Feature Exploitation Techniques，Error Optimization Techniques和Overfitting Elimination Techniques。最后介绍了林轩田老师带领的台大团队是如何在历届KDDCup中将很多机器学习算法模型融合起来，并获得了良好的成绩。</p><p><img src="http://img.blog.csdn.net/20170821084916401?" alt="这里写图片描述"></p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p><p>###<strong>写在最后的话</strong></p><p>历时近4个月，终于将台湾大学林轩田老师的《机器学习基石》和《机器学习技法》这两门课程学完了。突然的想法，开始写博客记录下学习历程，通过笔记的形式加深巩固了自己的理解。如果能对读者有些许帮助的话，那便是一大快事。笔者资历尚浅，博客中难免有疏漏和错误，欢迎各位批评指正。另外，鄙人不才，建立了一个QQ群，以便讨论与该课程相关或者其它的机器学习和深度学习问题。有兴趣的朋友可以加一下，QQ群号码是223490966（红色石头机器学习小站）。后续，笔者根据学习情况，可能还会推出一些课程笔记的博客。</p><p>积跬步以致千里，积小流以成江海！</p><p>最后，特别感谢林轩田老师！您的教学风格我很喜欢，深入浅出、寓教于乐。非常有幸能够学到您的课程！再次感谢！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170820202309144?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记15 -- Matrix Factorization</title>
    <link href="https://redstonewill.github.io/2018/03/18/32/"/>
    <id>https://redstonewill.github.io/2018/03/18/32/</id>
    <published>2018-03-18T06:40:21.000Z</published>
    <updated>2018-03-18T06:41:49.172Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170817082634527?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Radial Basis Function Network。它的原理就是基于距离相似性（distance-based similarities）的线性组合（linear aggregation）。我们使用k-Means clustering算法找出具有代表性的k个中心点，然后再计算与这些中心点的distance similarity，最后应用到RBF Network中去。</p><h3 id="LinearNetwork-Hypothesis"><a href="#LinearNetwork-Hypothesis" class="headerlink" title="LinearNetwork Hypothesis"></a>LinearNetwork Hypothesis</h3><p>回顾一下，我们在机器学习基石课程的第一节课就提到过，机器学习的目的就是让机器从数据data中学习到某种能力skill。我们之前举过一个典型的推荐系统的例子。就是说，假如我们手上有许多不同用户对不同电影的排名rank，通过机器学习，训练一个模型，能够对用户没有看过的某部电影进行排名预测。</p><p><img src="http://img.blog.csdn.net/20170817082634527?" alt="这里写图片描述"></p><p>一个典型的电影推荐系统的例子是2006年Netflix举办的一次比赛。数据包含了480189个用户和17770部电影，总共1亿多个排名信息。该推荐系统模型中，我们用$\breve x_n=(n)$表示第n个用户，这是一个抽象的特征，常常使用数字编号来代替具体哪个用户。输出方面，我们使用$y_m=r_{nm}$表示第n个用户对第m部电影的排名数值。</p><p><img src="http://img.blog.csdn.net/20170817083608703?" alt="这里写图片描述"></p><p>下面我们来进一步看看这些抽象的特征，$\breve x_n=(n)$是用户的ID，通常用数字表示。例如1126,5566,6211等。这些编号并没有数值大小上的意义，只是一种ID标识而已。这类特征被称为类别特征（categorical features）。常见的categorical features包括：IDs，blood type，programming languages等等。而许多机器学习模型中使用的大部分都是数值特征（numerical features）。例如linear models，NNet模型等。但决策树（decision tree）是个例外，它可以使用categorical features。所以说，如果要建立一个类似推荐系统的机器学习模型，就要把用户ID这种categorical features转换为numerical features。这种特征转换其实就是训练模型之前一个编码（encoding）的过程。</p><p><img src="http://img.blog.csdn.net/20170817085426956?" alt="这里写图片描述"></p><p>一种最简单的encoding方式就是binary vector encoding。也就是说，如果输入样本有N个，就构造一个维度为N的向量。第n个样本对应向量上第n个元素为1，其它元素都是0。下图就是一个binary vector encoding的例子。</p><p><img src="http://img.blog.csdn.net/20170817090157014?" alt="这里写图片描述"></p><p>经过encoding之后，输入$x_n$是N维的binary vector，表示第n个用户。输出$y_n$是M维的向量，表示该用户对M部电影的排名数值大小。注意，用户不一定对所有M部电影都作过评价，未评价的恰恰是我们要预测的（下图中问号？表示未评价的电影）。</p><p><img src="http://img.blog.csdn.net/20170817091836052?" alt="这里写图片描述"></p><p>总共有N个用户，M部电影。对于这样的数据，我们需要掌握每个用户对不同电影的喜爱程度及排名。这其实就是一个特征提取（feature extraction）的过程，提取出每个用户喜爱的电影风格及每部电影属于哪种风格，从而建立这样的推荐系统模型。可供选择使用的方法和模型很多，这里，我们使用的是NNet模型。NNet模型中的网络结构是$N-\breve d-M$型，其中N是输入层样本个数，$\breve d$是隐藏层神经元个数，M是输出层电影个数。该NNet为了简化计算，忽略了常数项。当然可以选择加上常数项，得到较复杂一些的模型。顺便提一下，这个结构跟我们之前介绍的autoencoder非常类似，都是只有一个隐藏层。</p><p><img src="http://img.blog.csdn.net/20170817104012267?" alt="这里写图片描述"></p><p>说到这里，有一个问题，就是上图NNet中隐藏层的tanh函数是否一定需要呢？答案是不需要。因为输入向量x是经过encoding得到的，其中大部分元素为0，只有一个元素为1。那么，只有一个元素$x_n$与相应权重的乘积进入到隐藏层。由于$x_n=1$，则相当于只有一个权重值进入到tanh函数进行运算。从效果上来说，tanh(x)与x是无差别的，只是单纯经过一个函数的计算，并不影响最终的结果，修改权重值即可得到同样的效果。因此，我们把隐藏层的tanh函数替换成一个线性函数y=x，得到下图所示的结构。</p><p><img src="http://img.blog.csdn.net/20170817105908092?" alt="这里写图片描述"></p><p>由于中间隐藏层的转换函数是线性的，我们把这种结构称为Linear Network（与linear autoencoder比较相似）。看一下上图这个网络结构，输入层到隐藏层的权重$W_{ni}^{(1)}$维度是Nx$\breve d$，用向量$V^T$表示。隐藏层到输出层的权重$W_{im}^{(2)}$维度是$\breve d$xM，用矩阵W表示。把权重由矩阵表示之后，Linear Network的hypothesis 可表示为：</p><p>$$h(x)=W^TVx$$</p><p>如果是单个用户$x_n$，由于X向量中只有元素$x_n$为1，其它均为0，则对应矩阵V只有第n列向量是有效的，其输出hypothesis为：</p><p>$$h(x_n)=W^Tv_n$$</p><p><img src="http://img.blog.csdn.net/20170817111901831?" alt="这里写图片描述"></p><h3 id="Basic-Matrix-Factorization"><a href="#Basic-Matrix-Factorization" class="headerlink" title="Basic Matrix Factorization"></a>Basic Matrix Factorization</h3><p>刚刚我们已经介绍了linear network的模型和hypothesis。其中Vx可以看作是对用户x的一种特征转换$\Phi(x)$。对于单部电影，其预测的排名可表示为：</p><p>$$h_m(x)=w_m^T\Phi(x)$$</p><p><img src="http://img.blog.csdn.net/20170817134258375?" alt="这里写图片描述"></p><p>推导完linear network模型之后，对于每组样本数据（即第n个用户第m部电影），我们希望预测的排名$w_m^Tv_n$与实际样本排名$y_n$尽可能接近。所有样本综合起来，我们使用squared error measure的方式来定义$E_{in}$，$E_{in}$的表达式如下所示：</p><p><img src="http://img.blog.csdn.net/20170817134856500?" alt="这里写图片描述"></p><p>上式中，灰色的部分是常数，并不影响最小化求解，所以可以忽略。接下来，我们就要求出$E_{in}$最小化时对应的V和W解。</p><p>我们的目标是让真实排名与预测排名尽可能一致，即$r_{nm}\approx w_m^Tv_n=v_n^Tw_m$。把这种近似关系写成矩阵的形式：$R\approx V^TW$。矩阵R表示所有不同用户不同电影的排名情况，维度是NxM。这种用矩阵的方式进行处理的方法叫做Matrix Factorization。</p><p><img src="http://img.blog.csdn.net/20170817140653558?" alt="这里写图片描述"></p><p>上面的表格说明了我们希望将实际排名情况R分解成两个矩阵（V和W）的乘积形式。V的维度是$\breve d$xN的，N是用户个数，$\breve d$可以是影片类型，例如（喜剧片，爱情片，悬疑片，动作片，…）。根据用户喜欢的类型不同，赋予不同的权重。W的维度是$\breve d$xM，M是电影数目，$\breve d$同样是影片类型，该部电影属于哪一类型就在那个类型上占比较大的权重。当然，$\breve d$维特征不一定就是影片类型，还可以是其它特征，例如明显阵容、年代等等。</p><p><img src="http://img.blog.csdn.net/20170817145203692?" alt="这里写图片描述"></p><p>那么，Matrix Factorization的目标就是最小化$E_{in}$函数。$E_{in}$表达式如下所示：</p><p><img src="http://img.blog.csdn.net/20170817145558938?" alt="这里写图片描述"></p><p>$E_{in}$中包含了两组待优化的参数，分别是$v_n$和$w_m$。我们可以借鉴上节课中k-Means的做法，将其中第一个参数固定，优化第二个参数，然后再固定第二个参数，优化第一个参数，一步一步进行优化。</p><p>当$v_n$固定的时候，只需要对每部电影做linear regression即可，优化得到每部电影的$\breve d$维特征值$w_m$。</p><p>当$w_m$固定的时候，因为V和W结构上是对称的，同样只需要对每个用户做linear regression即可，优化得到每个用户对$\breve d$维电影特征的喜爱程度$v_n$。</p><p><img src="http://img.blog.csdn.net/20170817151128423?" alt="这里写图片描述"></p><p>这种算法叫做alternating least squares algorithm。它的处理思想与k-Means算法相同，其算法流程图如下所示：</p><p><img src="http://img.blog.csdn.net/20170817151443027?" alt="这里写图片描述"></p><p>alternating least squares algorithm有两点需要注意。第一是initialize问题，通常会随机选取$v_n$和$w_m$。第二是converge问题，由于每次迭代更新都能减小$E_{in}$，$E_{in}$会趋向于0，则保证了算法的收敛性。</p><p><img src="http://img.blog.csdn.net/20170817151830032?" alt="这里写图片描述"></p><p>在上面的分析中，我们提过Matrix Factorization与Linear Autoencoder的相似性，下图列出了二者之间的比较。</p><p><img src="http://img.blog.csdn.net/20170817152251324?" alt="这里写图片描述"></p><p>Matrix Factorization与Linear Autoencoder有很强的相似性，都可以从原始资料汇总提取有用的特征。其实，linear autoencoder可以看成是matrix factorization的一种特殊形式。</p><h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><p>我们刚刚介绍了alternating least squares algorithm来解决Matrix Factorization的问题。这部分我们将讨论使用Stochastic Gradient Descent方法来进行求解。之前的alternating least squares algorithm中，我们考虑了所有用户、所有电影。现在使用SGD，随机选取一笔资料，然后只在与这笔资料有关的error function上使用梯度下降算法。使用SGD的好处是每次迭代只要处理一笔资料，效率很高；而且程序简单，容易实现；最后，很容易扩展到其它的error function来实现。</p><p><img src="http://img.blog.csdn.net/20170817163304014?" alt="这里写图片描述"></p><p>对于每笔资料，它的error function可表示为：</p><p><img src="http://img.blog.csdn.net/20170817163646644?" alt="这里写图片描述"></p><p>上式中的err是squared error function，仅与第n个用户$v_n$，第m部电影$w_m$有关。其对$v_n$和$w_m$的偏微分结果为：</p><p>$$\nabla v_n=-2(r_{nm}-w_m^Tv_n)w_m$$</p><p>$$\nabla w_m=-2(r_{nm}-w_m^Tv_n)v_n$$</p><p><img src="http://img.blog.csdn.net/20170817164230994?" alt="这里写图片描述"></p><p>很明显，$\nabla v_n$和$\nabla w_m$都由两项乘积构成。（忽略常数因子2）。第一项都是$r_{nm}-w_m^Tv_n$，即余数residual。我们在之前介绍的GBDT算法中也介绍过余数这个概念。$\nabla v_n$的第二项是$w_m$，而$\nabla w_m$的第二项是$v_n$。二者在结构上是对称的。</p><p>计算完任意一个样本点的SGD后，就可以构建Matrix Factorization的算法流程。SGD for Matrix Factorization的算法流程如下所示：</p><p><img src="http://img.blog.csdn.net/20170817170815240?" alt="这里写图片描述"></p><p>在实际应用中，由于SGD算法简单高效，Matrix Factorization大多采用这种算法。</p><p>介绍完SGD for Matrix Factorization之后，我们来看一个实际的应用例子。问题大致是这样的：根据现在有的样本资料，预测未来的趋势和结果。显然，这是一个与时间先后有关的预测模型。比如说一个用户三年前喜欢的电影可能现在就不喜欢了。所以在使用SGD选取样本点的时候有一个技巧，就是最后T次迭代，尽量选择时间上靠后的样本放入到SGD算法中。这样最后的模型受这些时间上靠后的样本点影响比较大，也相对来说比较准确，对未来的预测会比较准。</p><p><img src="http://img.blog.csdn.net/20170817173549256?" alt="这里写图片描述"></p><p>所以，在实际应用中，我们除了使用常规的机器学习算法外，还需要根据样本数据和问题的实际情况来修改我们的算法，让模型更加切合实际，更加准确。我们要学会灵活运用各种机器学习算法，而不能只是照搬。</p><h3 id="Summary-of-Extraction-Models"><a href="#Summary-of-Extraction-Models" class="headerlink" title="Summary of Extraction Models"></a>Summary of Extraction Models</h3><p>从第12节课开始到现在，我们总共用了四节课的时间来介绍Extraction Models。虽然我们没有给出Extraction Models明确的定义，但是它主要的功能就是特征提取和特征转换，将原始数据更好地用隐藏层的一些节点表征出来，最后使用线性模型将所有节点aggregation。这种方法使我们能够更清晰地抓住数据的本质，从而建立最佳的机器学习模型。</p><p>下图所示的就是我们介绍过的所有Extraction Models，除了这四节课讲的内容之外，还包括之前介绍的Adaptive/Gradient Boosting模型。因为之前笔记中都详细介绍过，这里就不再一一总结了。</p><p><img src="http://img.blog.csdn.net/20170817212312885?" alt="这里写图片描述"></p><p>除了各种Extraction Models之外，我们这四节课还介绍了不同的Extraction Techniques。下图所示的是对应于不同的Extraction Models的Extraction Techniques。</p><p><img src="http://img.blog.csdn.net/20170817212840069?" alt="这里写图片描述"></p><p>最后，总结一下这些Extraction Models有什么样的优点和缺点。从优点上来说：</p><ul><li><p><strong>easy：机器自己完成特征提取，减少人类工作量</strong></p></li><li><p><strong>powerful：能够处理非常复杂的问题和特征提取</strong></p></li></ul><p>另一方面，从缺点上来说：</p><ul><li><p><strong>hard：通常遇到non-convex的优化问题，求解较困难，容易得到局部最优解而非全局最优解</strong></p></li><li><p><strong>overfitting：模型复杂，容易造成过拟合，需要进行正则化处理</strong></p></li></ul><p>所以说，Extraction Models是一个非常强大的机器学习工具，但是使用的时候也要小心处理各种可能存在的问题。</p><p><img src="http://img.blog.csdn.net/20170817213747309?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Matrix Factorization。从电影推荐系统模型出发，首先，我们介绍了Linear Network。它从用户ID编码后的向量中提取出有用的特征，这是典型的feature extraction。然后，我们介绍了基本的Matrix Factorization算法，即alternating least squares，不断地在用户和电影之间交互地做linear regression进行优化。为了简化计算，提高运算速度，也可以使用SGD来实现。事实证明，SGD更加高效和简单。同时，我们可以根据具体的问题和需求，对固有算法进行一些简单的调整，来获得更好的效果。最后，我们对已经介绍的所有Extraction Models做个简单的总结。Extraction Models在实际应用中是个非常强大的工具，但是也要避免出现过拟合等问题。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170817082634527?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记14 -- Radial Basis Function Network</title>
    <link href="https://redstonewill.github.io/2018/03/18/31/"/>
    <id>https://redstonewill.github.io/2018/03/18/31/</id>
    <published>2018-03-18T06:38:01.000Z</published>
    <updated>2018-03-18T06:39:30.623Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170814084714413?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Deep Learning的概念。Deep Learing其实是Neural Networ的延伸，神经元更多，网络结构更加复杂。深度学习网络在训练的过程中最核心的问题就是pre-training和regularization。pre-training中，我们使用denoising autoencoder来对初始化权重进行选择。denoising autoencoder与统计学中经常用来进行数据处理的PCA算法具有很大的关联性。这节课我们将介绍Radial Basis Function Network，把之前介绍的adial Basis Function和Neural Network联系起来。</p><h3 id="RBF-Network-Hypothesis"><a href="#RBF-Network-Hypothesis" class="headerlink" title="RBF Network Hypothesis"></a>RBF Network Hypothesis</h3><p>之前我们介绍过，在SVM中引入Gaussian Kernel就能在无限多维的特征转换中得到一条“粗壮”的分界线（或者高维分界平面、分界超平面）。从结果来看，Gaussian SVM其实就是将一些Gaussian函数进行线性组合，而Gaussian函数的中心就位于Support Vectors上，最终得到预测模型$g_{svm}(x)$。</p><p><img src="http://img.blog.csdn.net/20170814084714413?" alt="这里写图片描述"></p><p>Gaussian kernel的另一种叫法是Radial Basis Function(RBF) kernel，即径向基函数。这个名字从何而来？首先，radial表示Gaussian函数计算结果只跟新的点x与中心点$x_n$的距离有关，与其它无关。basis function就是指Gaussian函数，最终的矩$g_{svm}(x)$就是由这些basis function线性组合而成。</p><p>从另外一个角度来看Gaussian SVM。首先，构造一个函数$g_n(x)$：</p><p>$$g_n(x)=y_ne^{-\gamma||x-x_n||^2}$$</p><p>上式中，指数项表示新的点x与$x_n$之间的距离大小。距离越近，即权重越大，相当于对$y_n$投的票数更多；而距离越远，权重越小，相当于对$y_n$投的票数更少。其物理意义是新的点与$x_n$的距离远近决定了$g_n(x)$与$y_n$的接近程度。如果距离越近，则$y_n$对$g_n(x)$的权重影响越大；如果距离越远，则$y_n$对$g_n(x)$的权重影响越小。那么整体来说，$g_{svm}(x)$就由所有的SV组成的$g_n(x)$线性组合而成，不同$g_n(x)$对应的系数是$\alpha_n$，最后由sign函数做最后的选择。这个过程很类型我们之前介绍的aggregation中将所有较好的hypothesis线性组合，不同的$g_n(x)$有不同的权重$\alpha_n$。我们把$g_n(x)$叫做radial hypotheses，Gaussian SVM就是将所有SV对应的radial hypotheses进行线性组合（linear aggregation）。</p><p><img src="http://img.blog.csdn.net/20170814092622529?" alt="这里写图片描述"></p><p>那么，Radial Basis Function(RBF) Network其实就是上面Gaussian SVM概念的延伸，目的就是找到所有radial hypotheses的linear aggregation，得到更好的网络模型。</p><p>之所以叫作RBF Network是因为它的模型结构类似于我们之前介绍的Neural Network。</p><p><img src="http://img.blog.csdn.net/20170814133904920?" alt="这里写图片描述"></p><p>Neural Network与RBF Network在输出层基本是类似的，都是上一层hypotheses的线性组合（linear aggregation）。但是对于隐藏层的各个神经元来说，Neural Network是使用内积（inner-product）加上tanh()函数的方法，而RBF Network是使用距离（distance）加上Gaussian函数的方法。总的来说，RBF Network是Neural Network的一个分支。</p><p><img src="http://img.blog.csdn.net/20170814135229130?" alt="这里写图片描述"></p><p>至此，RBF Network Hypothesis以及网络结构可以写成如下形式：</p><p><img src="http://img.blog.csdn.net/20170814135931865?" alt="这里写图片描述"></p><p>上式中，$\mu_m$表示每个中心点的位置，隐藏层每个神经元对应一个中心点；$\beta_m$表示每个RBF的权重，即投票所占比重。 </p><p>对应到Gaussian SVM上，上式中的RBF就是Gaussian函数。由于是分类问题，上式中的Output就是sign函数。其中，RBF的个数M就等于支持向量的个数SV，$\mu_m$就代表每个SV的坐标$x_m$，而$\beta_m$就是在Dual SVM中推导得到的$\alpha_ny_m$值。那我们学习的目标就是根据已知的RBF和Output，来决定最好的中心点位置$\mu_m$和权重系数$\beta_m$。</p><p><img src="http://img.blog.csdn.net/20170814141742989?" alt="这里写图片描述"></p><p>在之前介绍SVM的时候，我们就讲过Mercer定理：一个矩阵是Kernel的充分必要条件是它是对称的且是半正定的，条件比较苛刻。除了Gaussian kernel还有Polynomial kernel等等。Kernel实际上描述了两个向量之间的相似性，通过转换到z空间计算内积的方式，来表征二者之间的相似性。而RBF实际上是直接使用x空间的距离来描述了一种相似性，距离越近，相似性越高。因此，kernel和RBF可以看成是两种衡量相似性（similarity）的方式。本文介绍的Gaussian RBF即为二者的交集。</p><p><img src="http://img.blog.csdn.net/20170814145418972?" alt="这里写图片描述"></p><p>除了kernel和RBF之外，还有其它衡量相似性的函数。例如神经网络中的神经元就是衡量输入和权重之间的相似性。</p><p>经过以上分析，我们知道了RBF Network中distance similarity是一个很好的定义特征转换的方法。除此之外，我们还可以使用其它相似性函数来表征特征转换，从而得到更好的机器学习模型。</p><h3 id="RBF-Network-Learning"><a href="#RBF-Network-Learning" class="headerlink" title="RBF Network Learning"></a>RBF Network Learning</h3><p>我们已经介绍了RBF Network的Hypothesis可表示为：</p><p><img src="http://img.blog.csdn.net/20170814161854002?" alt="这里写图片描述"></p><p>其中$\mu_m$表示中心点的位置。$\mu_m$的个数M是人为决定的，如果将每个样本点$x_m$都作为一个中心点，即M=N，则我们把这种结构称为full RBF Network。也就是说，对于full RBF Network，每个样本点都对最终的预测都有影响（uniform influence），影响的程度由距离函数和权重$\beta_m$决定。如果每个样本点的影响力都是相同的，设为1，$\beta_m=1\cdot y_m$，那么相当于只根据距离的远近进行投票。最终将x与所有样本点的RBF距离线性组合，经过sign函数后，得到最终的预测分类结果。这实际上就是aggregation的过程，考虑并计入所有样本点的影响力，最后将x与所有样本点的distance similarity进行线性组合。</p><p><img src="http://img.blog.csdn.net/20170814164639278?" alt="这里写图片描述"></p><p>full RBF Network的矩可以表示为：</p><p><img src="http://img.blog.csdn.net/20170814224716379?" alt="这里写图片描述"></p><p>我们来看上式中的Gaussian函数项，当x与样本点$x_m$越接近的时候，其高斯函数值越大。由于Gaussian函数曲线性质，越靠近中心点，值越大；偏离中心点，其值会下降得很快。也就是说，在所有N个中心样本点中，往往只有距离x最近的那个样本点起到关键作用，而其它距离x较远的样本点其值很小，基本可以忽略。因此，为了简化运算，我们可以找到距离x最近的中心样本点，只用这一个点来代替所有N个点，最后得到的矩$g_{nbor}(x)$也只由该最近的中心点决定。这种模型叫做nearest neighbor model，只考虑距离x最近的那一个“邻居”。</p><p>当然可以对nearest neighbor model进行扩展，如果不是只选择一个“邻居”，而是选择距离x最近的k个“邻居”，进行uniformly aggregation，得到最终的矩$g_{nbor}(x)$。这种方法通常叫做k近邻算法（k nearest neighbor）。</p><p><img src="http://img.blog.csdn.net/20170814231531021?" alt="这里写图片描述"></p><p>k nearest neighbor通常比nearest neighbor model效果更好，计算量上也比full RBF Network要简单一些。值得一提的是，k nearest neighbor与full RBF Network都是比较“偷懒”的方法。因为它们在训练模型的时候比较简单，没有太多的运算，但是在测试的时候却要花费更多的力气，找出最相近的中心点，计算相对复杂一些。</p><p>接下来，我们来看一下Full RBF Network有什么样的优点和好处。考虑一个squared error regression问题，且每个RBF的权重为$\beta_m$而不是前面简化的$y_m$。目的是计算最优化模型对应的$\beta_m$值。该hypothesis可表示为：</p><p><img src="http://img.blog.csdn.net/20170815075312519?" alt="这里写图片描述"></p><p>很明显，这是一个简单的线性回归问题，每个RBF都可以看成是特征转换。特征转换后的向量$z_n$可表示为：</p><p>$$z_n=[RBF(x_n,x_1),\  RBF(x_n,x_2),\  \cdots,\  RBF(x_n,x_N)]$$</p><p>那么，根据之前线性回归介绍过的最优化解公式，就能快速地得到$\beta$的最优解为：</p><p>$$\beta=(Z^TZ)^{-1}Z^Ty$$</p><p>上述解的条件是矩阵$Z^TZ$是可逆的。</p><p>矩阵Z的大小是NxN，是一个方阵。而且，由于Z中每个向量$z_n$表示该点与其它所有点的RBF distance，所以从形式上来说，Z也是对称矩阵。如果所有的样本点$x_n$都不一样，则Z一定是可逆的。</p><p><img src="http://img.blog.csdn.net/20170815082805680?" alt="这里写图片描述"></p><p>根据Z矩阵的这些性质，我们可以对$\beta$的解进行化简，得到：</p><p>$$\beta=Z^{-1}y$$</p><p>将$\beta$的解代入矩的计算中，以$x_1$为例，得到：</p><p>$$g_{RBF}(x_1)=\beta^Tz_1=y^TZ^{-1}z_1=y^T\ [1\  0\  \cdots\  0]^T=y_1$$</p><p>结果非常有趣，模型的输出与原样本$y_1$完全相同。同样，对任意的$x_n$，都能得到$g_{RBF}(x_n)=y_n$。因此，$E_{in}(g_{RBF})=0$。看起来，这个模型非常完美了，没有error。但是，我们之前就说过，机器学习中，$E_{in}=0$并非好事，很可能造成模型复杂度增加及过拟合。</p><p><img src="http://img.blog.csdn.net/20170815084315626?" alt="这里写图片描述"></p><p>当然，这种方法在某些领域还是很有用的。比如在函数拟合（function approximation）中，目标就是让$E_{in}=0$，使得原所有样本都尽可能地落在拟合的函数曲线上。</p><p>为了避免发生过拟合，我们可以引入正则项$\lambda$，得到$\beta$的最优解为：</p><p>$$\beta=(Z^TZ+\lambda I)^{-1}Z^Ty$$</p><p><img src="http://img.blog.csdn.net/20170815091954727?" alt="这里写图片描述"></p><p>我们再来看一下Z矩阵，Z矩阵是由一系列Gaussian函数组成，每个Gaussian函数计算的是两个样本之间的distance similarity。这里的Z与之前我们介绍的Gaussian SVM中的kernel K是一致的。当时我们得到kernel ridgeregression中线性系数$\beta$的解为：</p><p>$$\beta=(K+\lambda I)^{-1}y$$</p><p>比较一下kernel ridgeregression与regularized full RBF Network的$\beta$解，形式上相似但不完全相同。这是因为regularization不一样，在kernel ridgeregression中，是对无限多维的特征转换做regularization，而在regularized full RBF Network中，是对有限维（N维度）的特征转换做regularization。因此，两者的公式解有细微差别。</p><p><img src="http://img.blog.csdn.net/20170815092618603?" alt="这里写图片描述"></p><p>除此之外，还有另外一种regularization的方法，就是不把所有N个样本点都拿来作中心点，而是只选择其中的M个样本点作为中心点。类似于SVM中的SV一样，只选择具有代表性的M个中心点。这样减少中心点数量的同时也就减少了权重的数量，能够起到regularization的效果，避免发生过拟合。</p><p><img src="http://img.blog.csdn.net/20170815093443497?" alt="这里写图片描述"></p><p>下一部分，我们将讨论如何选取M个中心点作为好的代表。</p><h3 id="k-Means-Algorithm"><a href="#k-Means-Algorithm" class="headerlink" title="k-Means Algorithm"></a>k-Means Algorithm</h3><p>之所以要选择代表，是因为如果某些样本点很接近，那么就可以用一个中心点来代表它们。这就是聚类（cluster）的思想，从所有N个样本点中选择少数几个代表作为中心点。</p><p><img src="http://img.blog.csdn.net/20170815163423702?" alt="这里写图片描述"></p><p>聚类（clustering）问题是一种典型的非监督式学习（unsupervised learning）。它的优化问题有两个变量需要确定：一个是分类的分群值$S_m$，每一类可表示为$S_1,S_2,\cdots,S_M$；另外一个是每一类对应的中心点$\mu_1,\mu_2,\cdots,\mu_M$。那么对于该聚类问题的优化，其error function可使用squared error measure来衡量。</p><p><img src="http://img.blog.csdn.net/20170815165700953?" alt="这里写图片描述"></p><p>那么，我们的目标就是通过选择最合适的$S_1,S_2,\cdots,S_M$和$\mu_1,\mu_2,\cdots,\mu_M$，使得$E_{in}$最小化。对应的公式可表示为：</p><p><img src="http://img.blog.csdn.net/20170815170616266?" alt="这里写图片描述"></p><p>从这个最小化公式，我们能够发现这是一个组合最佳化的问题，既要优化分群值$S_m$，又要求解每一类的中心点$u_m$。所以，这个最小化问题是比较复杂、难优化的。通常的办法是对S和$\mu$分别进行最优化求解。</p><p>首先，如果$\mu_1,\mu_2,\cdots,\mu_M$是固定的，目标就是只要对所有的$x_n$进行分群归类。这个求解过程很简单，因为每个样本点只能属于一个群S，不能同时属于两个或多个群。所以，只要根据距离公式，计算选择离$x_n$最近的中心点$\mu$即可。</p><p><img src="http://img.blog.csdn.net/20170823170743970?" alt="这里写图片描述"></p><p>然后，如果$S_1,S_2,\cdots,S_M$是固定的，目标就是只要找出每个类的中心点$\mu$。显然，根据上式中的error function，所有的$x_n$分群是已知的，那么该最小化问题就是一个典型的数值最优化问题。对于每个类群$S_m$，利用梯度下降算法，即可得到$\mu_m$的解。</p><p><img src="http://img.blog.csdn.net/20170815192317319?" alt="这里写图片描述"></p><p>如上图所示，中心点$\mu_m$就等于所有属于类群$S_m$的平均位置处。</p><p>经过以上的推导，我们得到了一个非常有名的一种unsupervised learning算法，叫做k-Means Algorithm。这里的k就是代表上面的M，表示类群的个数。</p><p>k-Means Algorithm的流程是这样的：首先，随机选择k个中心点$\mu_1,\mu_2,\cdots,\mu_k$；然后，再由确定的中心点得到不同的类群$S_1,S_2,\cdots,S_k$；接着，再由确定的类群计算出新的不同的k个中心点；继续循环迭代计算，交互地对$\mu$和S值进行最优化计算，不断更新$\mu$和S值，直到程序收敛，实现$E_{in}$最小化。具体算法流程图如下所示：</p><p><img src="http://img.blog.csdn.net/20170815193601984?" alt="这里写图片描述"></p><p>有一个问题是，k-Means Algorithm的循环迭代一定会停止吗？或者说一定能得到最优解吗？答案是肯定的。因为每次迭代更新，$\mu$和S值都会比上一次的值更接近最优解，也就是说$E_{in}$是不断减小的。而$E_{in}$的下界是0，所以，$E_{in}$最终会等于0，$\mu$和S最终能得到最优解。</p><p>k-Means Algorithm已经介绍完毕。接下来，我们把k-Means Algorithm应用到RBF Network中去。首先，使用k-Means，得到原始样本的k个中心点。原始样本到k个中心点组成了RBF特征转换$\Phi(x)$。然后，根据上面介绍过的线性模型，由最优化公式解计算得到权重$\beta$值。最后，将所有的$\Phi(x)$用$\beta$线性组合，即得到矩$g_{RBFNET}(x)$的表达式。具体的算法流程如下所示：</p><p><img src="http://img.blog.csdn.net/20170815204928962?" alt="这里写图片描述"></p><p>值得一提的是，这里我们使用了unsupervised learning（k-Means）与我们上节课介绍的autoencoder类似，同样都是特征转换（feature transform）的方法。</p><p>在最优化求解过程中，参数有k-Means类群个数M、Gaussian函数参数$\lambda$等。我们可以采用validation的方法来选取最佳的参数值。</p><p><img src="http://img.blog.csdn.net/20170815205719760?" alt="这里写图片描述"></p><h3 id="k-means-and-RBF-Network-in-Action"><a href="#k-means-and-RBF-Network-in-Action" class="headerlink" title="k-means and RBF Network in Action"></a>k-means and RBF Network in Action</h3><p>下面这部分，我们将举几个例子，看一下k-Means Algorithm是如何处理分类问题的。</p><p>第一个例子，平面上有4个类群，k=4。首先，我们随机选择4个中心点，如下图中四种颜色的方块所示：</p><p><img src="http://img.blog.csdn.net/20170815210706556?" alt="这里写图片描述"></p><p>第一次迭代，由初始中心点，得到4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815210718226?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815210947603?" alt="这里写图片描述"></p><p>第二次迭代，由上面得到的4个中心点，再计算4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815211219673?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815211325330?" alt="这里写图片描述"></p><p>第三次迭代，由上面得到的4个中心点，再计算4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815211541395?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815211558354?" alt="这里写图片描述"></p><p>第四次迭代，由上面得到的4个中心点，再计算4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815211706419?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815211724216?" alt="这里写图片描述"></p><p>第五次迭代，由上面得到的4个中心点，再计算4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815211826045?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815211841648?" alt="这里写图片描述"></p><p>第六次迭代，由上面得到的4个中心点，再计算4个类群点的分布：</p><p><img src="http://img.blog.csdn.net/20170815211943356?" alt="这里写图片描述"></p><p>4个类群点确定后，再更新4个中心点的位置：</p><p><img src="http://img.blog.csdn.net/20170815212000373?" alt="这里写图片描述"></p><p>从上图我们可以看到，经过六次迭代计算后，聚类的效果已经相当不错了。从另外一个角度来说，k值的选择很重要，下面我们来看看不同的k值对应什么样的分类效果。</p><p><img src="http://img.blog.csdn.net/20170815212602972?" alt="这里写图片描述"></p><p>如上图所示，初始时，我们分别设定k为2，4，7，随机选择中心点位置。在经过多次迭代后，得到的聚类结果如下：</p><p><img src="http://img.blog.csdn.net/20170815212818702?" alt="这里写图片描述"></p><p>通过上面这个例子可以得出，不同的k值会得到不同的聚类效果。还有一点值得注意的是，初始中心点位置也可能会影响最终的聚类。例如上图中k=7的例子，初始值选取的右边三个中心点比较靠近，最后得到的右边三个聚类中心点位置也跟初始位置比较相近。所以，k值大小和初始中心点位置都会影响聚类效果。</p><p>接下来，我们把k-Means应用到RBF Network中，同样分别设定k为2，4，7，不同模型得到的分类效果如下：</p><p><img src="http://img.blog.csdn.net/20170815214012047?" alt="这里写图片描述"></p><p>很明显，k=2时，分类效果不是太好；k=4时，分类效果好一些；而k=7时，分类效果更好，能够更细致地将样本准确分类。这说明了k-Means中k值设置得是否合理，对RBF Network的分类效果起到重要的作用。</p><p>再来看一个例子，如果使用full RBF Network进行分类，即k=N，如下图左边所示，设置正则化因子$\lambda=0.001$。下图右边表示只考虑full RBF Network中的nearest neighbor。下图中间表示的是k=4的RBF Network的分类效果。</p><p><img src="http://img.blog.csdn.net/20170816075335699?" alt="这里写图片描述"></p><p>从上图的比较中，我们可以发现full RBF Network得到的分类线比较弯曲复杂。由于full RBF Network的计算量比较大，所以一般情况下，实际应用得不太多。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Radial Basis Function Network。RBF Network Hypothesis就是计算样本之间distance similarity的Gaussian函数，这类原型替代了神经网络中的神经元。RBF Network的训练学习过程，其实就是对所有的原型Hypotheses进行linear aggregation。然后，我们介绍了一个确定k个中心点的unsupervised learning算法，叫做k-Means Algorithm。这是一种典型的聚类算法，实现对原始样本数据的聚类分群。接着，将k-Means Algorithm应用到RBF Network中，选择合适数量的中心点，得到更好的分类模型。最后，我们列举了几个在实际中使用k-Means和RBF Network的例子，结果显示不同的类群k值对分类的效果影响很大。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170814084714413?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记13 -- Deep Learning</title>
    <link href="https://redstonewill.github.io/2018/03/18/30/"/>
    <id>https://redstonewill.github.io/2018/03/18/30/</id>
    <published>2018-03-18T06:32:42.000Z</published>
    <updated>2018-03-18T06:37:11.100Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170807082811236?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了神经网络Neural Network。神经网络是由一层一层的神经元构成，其作用就是帮助提取原始数据中的模式即特征，简称为pattern feature extraction。神经网络模型的关键是计算出每个神经元的权重，方法就是使用Backpropagation算法，利用GD/SGD，得到每个权重的最优解。本节课我们将继续对神经网络进行深入研究，并介绍层数更多、神经元个数更多、模型更复杂的神经网络模型，即深度学习模型。</p><h3 id="Deep-Neural-Network"><a href="#Deep-Neural-Network" class="headerlink" title="Deep Neural Network"></a>Deep Neural Network</h3><p>总的来说，根据神经网络模型的层数、神经元个数、模型复杂度不同，大致可分为两类：Shallow Neural Networks和Deep Neural Networks。上节课介绍的神经网络模型层数较少，属于Shallow Neural Networks，而本节课将着重介绍Deep Neural Networks。首先，比较一下二者之间的优缺点有哪些：</p><p><img src="http://img.blog.csdn.net/20170807082811236?" alt="这里写图片描述"></p><p>值得一提的是，近些年来，deep learning越来越火，尤其在电脑视觉和语音识别等领域都有非常广泛的应用。原因在于一层一层的神经网络有助于提取图像或者语音的一些物理特征，即pattern feature extraction，从而帮助人们掌握这些问题的本质，建立准确的模型。</p><p>下面举个例子，来看一下深度学习是如何提取出问题潜在的特征从而建立准确的模型的。如下图所示，这是一个手写识别的问题，简单地识别数字1和数字5。</p><p><img src="http://img.blog.csdn.net/20170807084328199?" alt="这里写图片描述"></p><p>如何进行准确的手写识别呢？我们可以将写上数字的图片分解提取出一块一块不同部位的特征。例如左边三幅图每张图代表了数字1的某个部位的特征，三幅图片组合起来就是完整的数字1。右边四幅图也是一样，每张图代表了数字5的某个部位的特征，五幅图组合起来就是完整的数字5。对计算机来说，图片由许多像素点组成。要达到识别的目的，每层神经网络从原始像素中提取出更复杂的特征，再由这些特征对图片内容进行匹配和识别。层数越多，提取特征的个数和深度就越大，同时解决复杂问题的能量就越强，其中每一层都具有相应的物理意义。以上就是深度学习的作用和意义。</p><p>深度学习很强大，同时它也面临很多挑战和困难：</p><ul><li><p><strong>difficult structural decisions</strong></p></li><li><p><strong>high model complexity</strong></p></li><li><p><strong>hard optimization problem</strong></p></li><li><p><strong>huge computational complexity</strong></p></li></ul><p>面对以上深度学习的4个困难，有相应的技术和解决的办法：</p><p><img src="http://img.blog.csdn.net/20170807092913952?" alt="这里写图片描述"></p><p>其中，最关键的技术就是regularization和initialization。</p><p>深度学习中，权重的初始化选择很重要，好的初始值能够帮助避免出现局部最优解的出现。常用的方法就是pre-train，即先权重进行初始值的选择，选择之后再使用backprop算法训练模型，得到最佳的权重值。在接下来的部分，我们将重点研究pre-training的方法。</p><p><img src="http://img.blog.csdn.net/20170807101911830?" alt="这里写图片描述"></p><h3 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h3><p>我们已经介绍了深度学习的架构，那么从算法模型上来说，如何进行pre-training，得到较好的权重初始值呢？首先，我们来看看，权重是什么？神经网络模型中，权重代表了特征转换（feature transform）。从另一个方面也可以说，权重表示一种编码（encoding），就是把数据编码成另外一些数据来表示。因为神经网络是一层一层进行的，有先后顺序，所以就单一层来看，好的权重初始值应该是尽可能地包含了该层输入数据的所有特征，即类似于information-preserving encoding。也就是说，能够把第i层的输入数据的特征传输到第i+1层，再把第i+1层的输入数据的特征传输到第i+2层，一层一层进行下去。这样，每层的权重初始值起到了对该层输入数据的编码作用，能够最大限度地保持其特征。</p><p>举个例子，上一小节我们讲了简单的手写识别的例子。从原始的一张像素图片转换到分解的不同笔画特征，那么反过来，这几个笔画特征也可以组合成原来的数字。这种可逆的转换被称为information-preserving，即转换后的特征保留了原输入的特征，而且转换是可逆的。这正是pre-train希望做到的，通过encoding将输入转换为一些特征，而这些特征又可以复原原输入x，实现information-preserving。所以，pre-training得到的权重初始值就应该满足这样的information-preserving特性。</p><p><img src="http://img.blog.csdn.net/20170807175831186?" alt="这里写图片描述"></p><p>如何在pre-training中得到这样的权重初始值（即转换特征）呢？方法是建立一个简单的三层神经网络（一个输入层、一个隐藏层、一个输出层），如下图所示。</p><p><img src="http://img.blog.csdn.net/20170807224639626?" alt="这里写图片描述"></p><p>该神经网络中，输入层是原始数据（即待pre-training的数据），经过权重$W_{ij}^{(1)}$得到隐藏层的输出为原始数据新的表达方式（即转换特征）。这些转换特征再经过权重$W_{ji}^{(2)}$得到输出层，输出层的结果要求跟原始数据类似，即输入层和输出层是近似相等的。整个网络是$d-\breve{d}-d$ NNet结构。其核心在于“重构性”，从输入层到隐藏层实现特征转换，从隐藏层到输出层实现重构，满足上文所说的information-preserving的特性。这种结构的神经网络我们称之为autoencoder，输入层到隐藏层对应编码，而隐藏层到输出层对应解码。其中，$W_{ij}^{(1)}$表示编码权重，而$W_{ji}^{(2)}$表示解码权重。整个过程类似于在学习如何近似逼近identity function。</p><p><img src="http://img.blog.csdn.net/20170808074316857?" alt="这里写图片描述"></p><p>那么为什么要使用这样的结构来逼近identity function，有什么好处呢？首先对于监督式学习（supervised learning），这种$d-\breve{d}-d$的NNet结构中含有隐藏层。隐藏层的输出实际上就是对原始数据合理的特征转换$\phi(x)$，例如手写识别中隐藏层分解的各个笔画，包含了有用的信息。这样就可以从数据中学习得到一些有用的具有代表性的信息。然后，对于非监督式学习（unsupervised learning），autoencoder也可以用来做density estimation。如果网络最终的输出$g(x)\approx x$，则表示密度较大；如果g(x)与x相差甚远，则表示密度较小。也就是说可以根据g(x)与x的接近程度来估计测试数据是落在密度较大的地方还是密度较小的地方。这种方法同样适用于outlier detection，异常检测。这样就可以从数据中学习得到一些典型的具有代表性的信息，找出哪些是典型资料，哪些不是典型资料。所以说，通过autoencoder不断逼近identity function，对监督式学习和非监督式学习都具有深刻的物理意义和非常广泛的应用。</p><p><img src="http://img.blog.csdn.net/20170808081826212?" alt="这里写图片描述"></p><p>其实，对于autoencoder来说，我们更关心的是网络中间隐藏层，即原始数据的特征转换以及特征转换的编码权重$W_{ij}^{(1)}$。</p><p>Basic Autoencoder一般采用$d-\breve{d}-d$的NNet结构，对应的error function是squared error，即$\sum_{i=1}^d(g_i(x)-x_i)^2$。</p><p><img src="http://img.blog.csdn.net/20170808082741616?" alt="这里写图片描述"></p><p>basic autoencoder在结构上比较简单，只有三层网络，容易训练和优化。各层之间的神经元数量上，通常限定$\breve d&lt;d$，便于数据编码。数据集可表示为：${(x_1,y_1=x_1),(x_2,y_2=x_2),\cdots,(x_N,y_N=x_N)}$，即输入输出都是x，可以看成是非监督式学习。一个重要的限制条件是$W_{ij}^{(1)}=W_{ji}^{(2)}$，即编码权重与解码权重相同。这起到了regularization的作用，但是会让计算复杂一些。</p><p><img src="http://img.blog.csdn.net/20170808083737393?" alt="这里写图片描述"></p><p>以上就是basic autoencoder的结构和一些限定条件。深度学习中，basic autoencoder的过程也就对应着pre-training的过程，使用这种方法，对无label的原始数据进行编码和解码，得到的编码权重$W_{ij}^{(1)}$就可以作为pre-trained的比较不错的初始化权重，也就是作为深度学习中层与层之间的初始化权重。</p><p><img src="http://img.blog.csdn.net/20170808084602404?" alt="这里写图片描述"></p><p>我们在本节课第一部分就说了深度学习中非常重要的一步就是pre-training，即权重初始化，而autoencoder可以作为pre-training的一个合理方法。Pre-training的整个过程是：首先，autoencoder会对深度学习网络第一层（即原始输入）进行编码和解码，得到编码权重$W_{ij}^{(1)}$，作为网络第一层到第二层的的初始化权重；然后再对网络第二层进行编码和解码，得到编码权重$W_{ij}^{(1)}$，作为网络第二层到第三层的初始化权重，以此类推，直到深度学习网络中所有层与层之间都得到初始化权重。值得注意的是，对于l-1层的网络${x_n^{(l-1)}}$，autoencoder中的$\breve d$应与下一层（即l层）的神经元个数相同。</p><p><img src="http://img.blog.csdn.net/20170808090507228?" alt="这里写图片描述"></p><p>当然，除了basic autoencoder之外还有许多其它表现不错的pre-training方法。这些方法大都采用不同的结构和正则化技巧来得到不同的’fancier’ autoencoders，这里不再赘述。</p><h3 id="Denoising-Autoencoder"><a href="#Denoising-Autoencoder" class="headerlink" title="Denoising Autoencoder"></a>Denoising Autoencoder</h3><p>上一部分，我们使用autoencoder解决了deep learning中pre-training的问题。接下来，我们将讨论deep learning中有什么样的regularization方式来控制模型的复杂度。</p><p><img src="http://img.blog.csdn.net/20170809075826822?" alt="这里写图片描述"></p><p>由于深度学习网络中神经元和权重的个数非常多，相应的模型复杂度就会很大，因此，regularization非常必要。之前我门也介绍过一些regularization的方法，包括：</p><ul><li><p><strong>structural decisions/constraints</strong></p></li><li><p><strong>weight decay or weight elimination regularizers</strong></p></li><li><p><strong>early stopping</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170809080411186?" alt="这里写图片描述"></p><p>下面我们将介绍另外一种regularization的方式，它在deep learning和autoencoder中都有很好的效果。</p><p>首先我们来复习一下之前介绍的overfitting产生的原因有哪些。如下图所示，我们知道overfitting与样本数量、噪声大小都有关系，数据量减少或者noise增大都会造成overfitting。如果数据量是固定的，那么noise的影响就非常大，此时，实现regularization的一个方法就是消除noise的影响。</p><p><img src="http://img.blog.csdn.net/20170809081534072?" alt="这里写图片描述"></p><p>去除noise的一个简单方法就是对数据进行cleaning/pruning的操作。但是，这种方法通常比较麻烦，费时费力。此处，有一种比较“疯狂”的方法，就是往数据中添加一些noise。注意是添加noise！下面我们来解释这样做到底有什么作用。</p><p><img src="http://img.blog.csdn.net/20170809082321042?" alt="这里写图片描述"></p><p>这种做法的idea来自于如何建立一个健壮（robust）的autoencoder。在autoencoder中，编码解码后的输出g(x)会非常接近真实样本值x。此时，如果对原始输入加入一些noise，对于健壮的autoencoder，编码解码后的输出g(x)同样会与真实样本值x很接近。举个例子，手写识别中，通常情况下，写的很规范的数字1经过autoencoder后能够复原为数字1。如果原始图片数字1歪斜或加入噪声，经过autoencoder后应该仍然能够解码为数字1。这表明该autoencoder是robust的，一定程度上起到了抗噪声和regularization的作用，这正是我们希望看到的。</p><p>所以，这就引出了denoising autoencoder的概念。denoising autoencoder不仅能实现编码和解码的功能，还能起到去噪声、抗干扰的效果，即输入一些混入noise的数据，经过autoencoder之后能够得到较纯净的数据。这样，autoencoder的样本集为：</p><p>$${(\breve{x}_1,y_1=x_1),(\breve{x}_2,y_2=x_2),\cdots,(\breve{x}_N,y_N=x_N)}$$</p><p>其中$\breve{x}_n=x_n+noise$，为混入噪声的样本，而$x_n$为纯净样本。</p><p>autoencoder训练的目的就是让$\breve{x}_n$经过编码解码后能够复原为纯净的样本$x_n$。那么，在deep learning的pre-training中，如果使用这种denoising autoencoder，不仅能从纯净的样本中编解码得到纯净的样本，还能从混入noise的样本中编解码得到纯净的样本。这样得到的权重初始值更好，因为它具有更好的抗噪声能力，即健壮性好。实际应用中，denoising autoencoder非常有用，在训练过程中，输入混入人工noise，输出纯净信号，让模型本身具有抗噪声的效果，让模型健壮性更强，最关键的是起到了regularization的作用。</p><p><img src="http://img.blog.csdn.net/20170809085825116?" alt="这里写图片描述"></p><h3 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a>Principal Component Analysis</h3><p>刚刚我们介绍的autoencoder是非线性的，因为其神经网络模型中包含了tanh()函数。这部分我们将介绍linear autoencoder。nonlinear autoencoder通常比较复杂，多应用于深度学习中；而linear autoencoder通常比较简单，我们熟知的主成分分析（Principal Component Analysis，PCA），其实跟linear autoencoder有很大的关系。</p><p>对于一个linear autoencoder，它的第k层输出不包含tanh()函数，可表示为：</p><p>$$h_k(x)=\sum_{j=0}^{\breve{d}}w_{jk}^{(2)}(\sum_{i=0}^dw_{ij}^{(1)}x_i)$$</p><p>其中，$w_{ij}^{(1)}$和$w_{jk}^{(2)}$分别是编码权重和解码权重。而且，有三个限制条件，分别是：</p><ul><li><p><strong>移除常数项$x_0$，让输入输出维度一致</strong></p></li><li><p><strong>编码权重与解码权重一致：$w_{ij}^{(1)}=w_{jk}^{(2)}=w_{ij}</strong></p></li><li><p><strong>$\breve{d}&lt;d$</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170809143637045?" alt="这里写图片描述"></p><p>这样，编码权重用W表示，维度是d x $\breve{d}$，解码权重用$W^T$表示。x的维度为d x 1。则linear autoencoder hypothesis可经过下式计算得到：</p><p>$$h(x)=WW^Tx$$</p><p>其实，linear autoencoder hypothesis就应该近似于原始输入x的值，即h(x)=x。根据这个，我们可以写出它的error function：</p><p><img src="http://img.blog.csdn.net/20170809145218227?" alt="这里写图片描述"></p><p>我们的目的是计算出$E_{in}(h)$最小化时对应的W。根据线性代数知识，首先进行特征值分解：</p><p>$$WW^T=V\Gamma V^T$$</p><p>其中$WW^T$是半正定矩阵。V矩阵满足$VV^T=V^TV=I_d$。$\Gamma$是对角矩阵，对角线上有不超过$\breve{d}$个非零值（即为1），即对角线零值个数大于等于$d-\breve(d)$。根据特征值分解的思想，我们可以把$x_n$进行类似分解：</p><p>$$x_n=VIV^Tx_n$$</p><p>其中，I是单位矩阵，维度为dxd。这样，通过特征值分解我们就把对W的优化问题转换成对$\Gamma$和V的优化问题。</p><p><img src="http://img.blog.csdn.net/20170809155615900?" alt="这里写图片描述"></p><p>首先，我们来优化$\Gamma$值，表达式如下：</p><p><img src="http://img.blog.csdn.net/20170809155740158?" alt="这里写图片描述"></p><p>要求上式的最小化，可以转化为$(I-\Gamma)$越小越好，其结果对角线上零值越多越好，即I与$\Gamma$越接近越好。因为$\Gamma$的秩是小于等于$\breve{d}$的，$\Gamma$最多有$\breve{d}$个1。所以，$\Gamma$的最优解是其对角线上有$\breve{d}$个1。</p><p><img src="http://img.blog.csdn.net/20170809160725018?" alt="这里写图片描述"></p><p>那么，$\Gamma$的最优解已经得出，表达式变成：</p><p><img src="http://img.blog.csdn.net/20170809160853847?" alt="这里写图片描述"></p><p>这里的最小化问题似乎有点复杂，我们可以做一些转换，把它变成最大化问题求解，转换后的表达式为：</p><p><img src="http://img.blog.csdn.net/20170809161356367?" alt="这里写图片描述"></p><p>当$\breve{d}=1$时，$V^T$中只有第一行$v^T$有用，最大化问题转化为：</p><p>$$max_v\sum_{n=1}^Nv^Tx_nx_n^Tv\ \ \ \ \ subject\ to\ v^Tv=1$$</p><p>引入拉格朗日因子$\lambda$，表达式的微分与条件微分应该是平行的，且由$\lambda$联系起来，即：</p><p>$$\sum_{n=1}^Nx_nx_n^Tv=\lambda v$$</p><p>根据线性代数的知识，很明显能够看出，v就是矩阵$X^TX$的特征向量，而$\lambda$就是相对应的特征值。我们要求的是最大值，所以最优解v就是矩阵$X^TX$最大特征值对应的特征向量。</p><p>当$\breve{d}&gt;1$时，求解方法是类似的，最优解${v_j}_{j=1}^{\breve d}$就是矩阵$X^TX$前$\breve{d}$大的特征值对应的$\breve{d}$个特征向量。</p><p>经过以上分析，我们得到了$\Gamma$和V的最优解。这就是linear autoencoder的编解码推导过程。</p><p><img src="http://img.blog.csdn.net/20170809163958200?" alt="这里写图片描述"></p><p>值得一提的是，linear autoencoder与PCA推导过程十分相似。但有一点不同的是，一般情况下，PCA会对原始数据x进行处理，即减去其平均值。这是为了在推导过程中的便利。这两种算法的计算流程大致如下：</p><p><img src="http://img.blog.csdn.net/20170809164756333?" alt="这里写图片描述"></p><p>linear autoencoder与PCA也有差别，PCA是基于统计学分析得到的。一般我们认为，将高维数据投影（降维）到低维空间中，应该保证数据本身的方差越大越好，而噪声方差越小越好，而PCA正是基于此原理推导的。linear autoencoder与PCA都可以用来进行数据压缩，但是PCA应用更加广泛一些。</p><p><img src="http://img.blog.csdn.net/20170809165309964?" alt="这里写图片描述"></p><p>以上关于PCA的推导基本上是从几何的角度，而没有从代数角度进行详细的数学推导。网上关于PCA的资料很多，这里附上一篇个人觉得讲解得通俗易懂的PCA原理介绍：<a href="http://blog.codinglabs.org/articles/pca-tutorial.html" target="_blank" rel="noopener">PCA的数学原理</a>。有兴趣的朋友可以看一看。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了深度学习（deep learning）的数学模型，也是上节课讲的神经网络的延伸。由于深度学习网络的复杂性，其建模优化是比较困难的。通常，我们可以从pre-training和regularization的角度来解决这些困难。首先，autoencoder可以得到比较不错的初始化权重，起到pre-training的效果。然后，denoising autoencoder通过引入人工噪声，训练得到初始化权重，从而使模型本身抗噪声能力更强，更具有健壮性，起到了regularization的效果。最后，我们介绍了linear autoencoder并从几何角度详述了其推导过程。linear autoencoder与PCA十分类似，都可以用来进行数据压缩和数据降维处理。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170807082811236?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记12 -- Neural Network</title>
    <link href="https://redstonewill.github.io/2018/03/18/29/"/>
    <id>https://redstonewill.github.io/2018/03/18/29/</id>
    <published>2018-03-18T06:20:46.000Z</published>
    <updated>2018-03-18T06:22:18.565Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170731201555148?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Gradient Boosted Decision Tree。GBDT通过使用functional gradient的方法得到一棵一棵不同的树，然后再使用steepest descent的方式给予每棵树不同的权重，最后可以用来处理任何而定error measure。上节课介绍的GBDT是以regression为例进行介绍的，使用的是squared error measure。本节课讲介绍一种出现时间较早，但当下又非常火的一种机器算法模型，就是神经网络（Neural Network）。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>在之前的机器学习基石课程中，我们就接触过Perceptron模型了，例如PLA算法。Perceptron就是在矩$g_t(x)$外面加上一个sign函数，取值为{-1,+1}。现在，如果把许多perceptrons线性组合起来，得到的模型G就如下图所示：</p><p><img src="http://img.blog.csdn.net/20170731201555148?" alt="这里写图片描述"></p><p>将左边的输入$(x_0,x_1,x_2,\cdots,x_d)$与T个不同的权重$(w_1,w_2,\cdots,w_T)$相乘（每个$w_i$是d+1维的），得到T个不同的perceptrons为$(g_1,g_2,\cdots,g_T)$。最后，每个$g_t$给予不同的权重$(\alpha_1,\alpha_2,\cdots,\alpha_T)$，线性组合得到G。G也是一个perceptron模型。</p><p>从结构上来说，上面这个模型包含了两层的权重，分别是$w_t$和$\alpha$。同时也包含了两层的sign函数，分别是$g_t$和G。那么这样一个由许多感知机linear aggregation的模型能实现什么样的boundary呢？</p><p>举个简单的例子，如下图所示，$g_1$和$g_2$分别是平面上两个perceptrons。其中，红色表示-1，蓝色表示+1。这两个perceptrons线性组合可能得到下图右侧的模型，这表示的是$g_1$和$g_2$进行与（AND）的操作，蓝色区域表示+1。</p><p><img src="http://img.blog.csdn.net/20170731205216172?" alt="这里写图片描述"></p><p>如何通过感知机模型来实现上述的$AND(g_1,g_2)$逻辑操作呢？一种方法是令第二层中的$\alpha_0=-1,\alpha_1=+1,\alpha_2=+1$。这样，G(x)就可表示为：</p><p>$$G(x)=sign(-1+g_1(x)+g_2(x))$$</p><p>$g_1$和$g_2$的取值是{-1,+1}，当$g_1=-1，g_2=-1$时，G(x)=0；当$g_1=-1，g_2=+1$时，G(x)=0；当$g_1=+1，g_2=-1$时，G(x)=0；当$g_1=+1，g_2=+1$时，G(x)=1。感知机模型如下所示：</p><p><img src="http://img.blog.csdn.net/20170731210353253?" alt="这里写图片描述"></p><p>这个例子说明了一些简单的线性边界，如上面的$g_1$和$g_2$，在经过一层感知机模型，经线性组合后，可以得到一些非线性的复杂边界（AND运算）G(x)。</p><p>除此之外，或（OR）运算和非（NOT）运算都可以由感知机建立相应的模型，非常简单。</p><p>所以说，linear aggregation of perceptrons实际上是非常powerful的模型同时也是非常complicated模型。再看下面一个例子，如果二维平面上有个圆形区域，圆内表示+1，圆外表示-1。这样复杂的圆形边界是没有办法使用单一perceptron来解决的。如果使用8个perceptrons，用刚才的方法线性组合起来，能够得到一个很接近圆形的边界（八边形）。如果使用16个perceptrons，那么得到的边界更接近圆形（十六边形）。因此，使用的perceptrons越多，就能得到各种任意的convex set，即凸多边形边界。之前我们在机器学习基石中介绍过，convex set的VC Dimension趋向于无穷大（$2^N$）。这表示只要perceptrons够多，我们能得到任意可能的情况，可能的模型。但是，这样的坏处是模型复杂度可能会变得很大，从而造成过拟合（overfitting）。</p><p><img src="http://img.blog.csdn.net/20170731212555912?" alt="这里写图片描述"></p><p>总的来说，足够数目的perceptrons线性组合能够得到比较平滑的边界和稳定的模型，这也是aggregation的特点之一。</p><p>但是，也有单层perceptrons线性组合做不到的事情。例如刚才我们将的AND、OR、NOT三种逻辑运算都可以由单层perceptrons做到，而如果是异或（XOR）操作，就没有办法只用单层perceptrons实现。这是因为XOR得到的是非线性可分的区域，如下图所示，没有办法由$g_1$和$g_2$线性组合实现。所以说linear aggregation of perceptrons模型的复杂度还是有限制的。</p><p><img src="http://img.blog.csdn.net/20170731213544161?" alt="这里写图片描述"></p><p>那么，为了实现XOR操作，可以使用多层perceptrons，也就是说一次transform不行，我们就用多层的transform，这其实就是Basic Neural Network的基本原型。下面我们就尝试使用两层perceptrons来实现XOR的操作。</p><p>首先，根据布尔运算，异或XOR操作可以拆分成：</p><p>$$XOR(g_1,g_2)=OR(AND(-g_1,g_2),AND(g_1,-g_2))$$</p><p>这种拆分实际上就包含了两层transform。第一层仅有AND操作，第二层是OR操作。这种两层的感知机模型如下所示：</p><p><img src="http://img.blog.csdn.net/20170731230146579?" alt="这里写图片描述"></p><p>这样，从AND操作到XOR操作，从简单的aggregation of perceptrons到multi-layer perceptrons，感知机层数在增加，模型的复杂度也在增加，使最后得到的G能更容易解决一些非线性的复杂问题。这就是基本神经网络的基本模型。</p><p><img src="http://img.blog.csdn.net/20170731230552144?" alt="这里写图片描述"></p><p>顺便提一下，这里所说的感知机模型实际上就是在模仿人类的神经元模型（这就是Neural Network名称的由来）。感知机模型每个节点的输入就对应神经元的树突dendrite，感知机每个节点的输出就对应神经元的轴突axon。</p><h3 id="Neural-Network-Hypothesis"><a href="#Neural-Network-Hypothesis" class="headerlink" title="Neural Network Hypothesis"></a>Neural Network Hypothesis</h3><p>上一部分我们介绍的这种感知机模型其实就是Neural Network。输入部分经过一层一层的运算，相当于一层一层的transform，最后通过最后一层的权重，得到一个分数score。即在OUTPUT层，输出的就是一个线性模型。得到s后，下一步再进行处理。</p><p><img src="http://img.blog.csdn.net/20170801074857278?" alt="这里写图片描述"></p><p>我们之前已经介绍过三种线性模型：linear classification，linear regression，logistic regression。那么，对于OUTPUT层的分数s，根据具体问题，可以选择最合适的线性模型。如果是binary classification问题，可以选择linear classification模型；如果是linear regression问题，可以选择linear regression模型；如果是soft classification问题，则可以选择logistic regression模型。本节课接下来将以linear regression为例，选择squared error来进行衡量。</p><p><img src="http://img.blog.csdn.net/20170801081220770?" alt="这里写图片描述"></p><p>上面讲的是OUTPUT层，对于中间层，每个节点对应一个perceptron，都有一个transform运算。上文我们已经介绍过的transformation function是阶梯函数sign()。那除了sign()函数外，有没有其他的transformation function呢？</p><p>如果每个节点的transformation function都是线性运算（跟OUTPUT端一样），那么由每个节点的线性模型组合成的神经网络模型也必然是线性的。这跟直接使用一个线性模型在效果上并没有什么差异，模型能力不强，反而花费了更多不必要的力气。所以一般来说，中间节点不会选择线性模型。</p><p>如果每个节点的transformation function都是阶梯函数（即sign()函数）。这是一个非线性模型，但是由于阶梯函数是离散的，并不是处处可导，所以在优化计算时比较难处理。所以，一般也不选择阶梯函数作为transformation function。</p><p>既然线性函数和阶梯函数都不太适合作为transformation function，那么最常用的一种transformation function就是tanh(s)，其表达式如下：</p><p>$$tanh(s)=\frac{exp(s)-exp(-s)}{exp(s)+exp(-s)}$$</p><p>tanh(s)函数是一个平滑函数，类似“s”型。当|s|比较大的时候，tanh(s)与阶梯函数相近；当|s|比较小的时候，tanh(s)与线性函数比较接近。从数学上来说，由于处处连续可导，便于最优化计算。而且形状上类似阶梯函数，具有非线性的性质，可以得到比较复杂强大的模型。</p><p>顺便提一下，tanh(x)函数与sigmoid函数存在下列关系：</p><p>$$tanh(s)=2\theta(2s)-1$$</p><p>其中，</p><p>$$\theta(s)=\frac{1}{1+exp(-s)}$$</p><p><img src="http://img.blog.csdn.net/20170801084655875?" alt="这里写图片描述"></p><p>那么，接下来我们就使用tanh函数作为神经网络中间层的transformation function，所有的数学推导也基于此。实际应用中，可以选择其它的transformation function，不同的transformation function，则有不同的推导过程。</p><p>下面我们将仔细来看看Neural Network Hypothesis的结构。如下图所示，该神经网络左边是输入层，中间两层是隐藏层，右边是输出层。整体上来说，我们设定输入层为第0层，然后往右分别是第一层、第二层，输出层即为第3层。</p><p><img src="http://img.blog.csdn.net/20170801085603255?" alt="这里写图片描述"></p><p>Neural Network Hypothesis中，$d^{(0)},d^{(1)},\cdots,d^{(L)}$分别表示神经网络的第几层，其中L为总层数。例如上图所示的是3层神经网络，L=3。我们先来看看每一层的权重$w_{ij}^{(l)}$，上标l满足$1\leq l\leq L$，表示是位于哪一层。下标i满足$0\leq i\leq d^{(l-1)}$，表示前一层输出的个数加上bias项（常数项）。下标j满足$1\leq j\leq d^{(l)}$，表示该层节点的个数（不包括bias项）。</p><p>对于每层的分数score，它的表达式为：</p><p>$$s_j^{(l)}=\sum_{i=0}^{d^{(l-1)}}w_{ij}^{(l)}x_i^{(l-1)}$$</p><p>对于每层的transformation function，它的表达式为：</p><p>$$x_j^{(l)}=\begin{cases}<br>        tanh(s_j^{(l)}), &amp; if\ l&lt;L\<br>        s_j^{(l)}, &amp; if\ l=L<br>    \end{cases}$$</p><p>因为是regression模型，所以在输出层（l=L）直接得到$x_j^{(l)}=s_j^{(l)}$。</p><p><img src="http://img.blog.csdn.net/20170801102651009?" alt="这里写图片描述"></p><p>介绍完Neural Network Hypothesis的结构之后，我们来研究下这种算法结构到底有什么实际的物理意义。还是看上面的神经网络结构图，每一层输入到输出的运算过程，实际上都是一种transformation，而转换的关键在于每个权重值$w_{ij}^{(l)}$。每层网络利用输入x和权重w的乘积，在经过tanh函数，得到该层的输出，从左到右，一层一层地进行。其中，很明显，x和w的乘积$\sum_{i=0}^{d^{(l-1)}}w_{ij}^{(l)}x_i^{(l-1)}$越大，那么tanh(wx)就会越接近1，表明这种transformation效果越好。再想一下，w和x是两个向量，乘积越大，表明两个向量内积越大，越接近平行，则表明w和x有模式上的相似性。从而，更进一步说明了如果每一层的输入向量x和权重向量w具有模式上的相似性，比较接近平行，那么transformation的效果就比较好，就能得到表现良好的神经网络模型。也就是说，神经网络训练的核心就是pattern extraction，即从数据中找到数据本身蕴含的模式和规律。通过一层一层找到这些模式，找到与输入向量x最契合的权重向量w，最后再由G输出结果。</p><p><img src="http://img.blog.csdn.net/20170801105658700?" alt="这里写图片描述"></p><h3 id="Neural-Network-Learning"><a href="#Neural-Network-Learning" class="headerlink" title="Neural Network Learning"></a>Neural Network Learning</h3><p>我们已经介绍了Neural Network Hypothesis的结构和算法流程。确定网络结构其实就是确定各层的权重值$w_{ij}^{(l)}$。那如何根据已有的样本数据，找到最佳的权重$w_{ij}^{(l)}$使error最小化呢？下面我们将详细推导。</p><p><img src="http://img.blog.csdn.net/20170801134927174?" alt="这里写图片描述"></p><p>首先，我们的目标是找到最佳的$w_{ij}^{(l)}$让$E_{in}({w_{ij}^{(l)}})$最小化。如果只有一层隐藏层，就相当于是aggregation of perceptrons。可以使用我们上节课介绍的gradient boosting算法来一个一个确定隐藏层每个神经元的权重，输入层到隐藏层的权重可以通过C&amp;RT算法计算的到。这不是神经网络常用的算法。如果隐藏层个数有两个或者更多，那么aggregation of perceptrons的方法就行不通了。就要考虑使用其它方法。</p><p>根据error function的思想，从输出层来看，我们可以得到每个样本神经网络预测值与实际值之间的squared error：$e_n=(y_n-NNet(x_n))^2$，这是单个样本点的error。那么，我们只要能建立$e_n$与每个权重$w_{ij}^{(l)}$的函数关系，就可以利用GD或SGD算法对$w_{ij}^{(l)}$求偏微分，不断迭代优化$w_{ij}^{(l)}$值，最终得到使$e_n$最小时对应的$w_{ij}^{(l)}$。</p><p><img src="http://img.blog.csdn.net/20170801140710642?" alt="这里写图片描述"></p><p>为了建立$e_n$与各层权重$w_{ij}^{(l)}$的函数关系，求出$e_n$对$w_{ij}^{(l)}$的偏导数$\frac{\partial e_n}{w_{ij}^{(l)}}$，我们先来看输出层如何计算$\frac{\partial e_n}{w_{i1}^{(L)}}$。$e_n$与$w_{i1}^{(L)}$的函数关系为：</p><p><img src="http://img.blog.csdn.net/20170801142747629?" alt="这里写图片描述"></p><p>计算$e_n$对$w_{i1}^{(L)}$的偏导数，得到：</p><p><img src="http://img.blog.csdn.net/20170801143202613?" alt="这里写图片描述"></p><p>以上是输出层求偏导的结果。如果是其它层，即$l\neq L$，偏导计算可以写成如下形式：</p><p><img src="http://img.blog.csdn.net/20170801143443495?" alt="这里写图片描述"></p><p>上述推导中，令$e_n$与第l层第j个神经元的分数$s_j^{(l)}$的偏导数记为$\delta_j^{(l)}$。即：</p><p>$$\frac{\partial e_n}{\partial s_j^{(l)}}=\delta_j^{(l)}$$</p><p>当$l=L$时，$\delta_1^{(L)}=-2(y_n-s_1^{(L)})$；当$l\neq L$时，$\delta_j^{(l)}$是未知的，下面我们将进行运算推导，看看不同层之间的$\delta_j^{(l)}$是否有递推关系。</p><p><img src="http://img.blog.csdn.net/20170801144815735?" alt="这里写图片描述"></p><p>如上图所示，第l层第j个神经元的分数$s_j^{(l)}$经过tanh函数，得到该层输出$x_j^{(l)}$，再与下一层权重$w_{jk}^{(l+1)}$相乘，得到第l+1层的分数$s_j^{(l+1)}$，直到最后的输出层$e_n$。</p><p>那么，利用上面$s_j^{(l)}$到$s_j^{(l+1)}$这样的递推关系，我们可以对偏导数$\delta_j^{(l)}$做一些中间变量替换处理，得到如下表达式：</p><p><img src="http://img.blog.csdn.net/20170801150154804?" alt="这里写图片描述"></p><p>值得一提的是，上式中有个求和项，其中k表示下一层即l+1层神经元的个数。表明l层的$s_j^{(l)}$与l+1层的所有$s_k^{(l+1)}$都有关系。因为$s_j^{(l)}$参与到每个$s_k^{(l+1)}$的运算中了。</p><p>这样，我们得到了$\delta_j^{(l)}$与$\delta_k^{(l)}$的递推关系。也就是说如果知道了$\delta_k^{(l)}$的值，就能推导出$\delta_j^{(l)}$的值。而最后一层，即输出层的$\delta_1^{(L)}=-2(y_n-s_1^{(L)})$，那么就能一层一层往前推导，得到每一层的$\delta_j^{(l)}$，从而可以计算出$e_n$对各个$w_{ij}^{(l)}$的偏导数$\frac{\partial e_n}{w_{ij}^{(l)}}$。计算完偏微分之后，就可以使用GD或SGD算法进行权重的迭代优化，最终得到最优解。</p><p>神经网络中，这种从后往前的推导方法称为Backpropagation Algorithm，即我们常常听到的BP神经网络算法。它的算法流程如下所示：</p><p><img src="http://img.blog.csdn.net/20170801151811019?" alt="这里写图片描述"></p><p>上面采用的是SGD的方法，即每次迭代更新时只取一个点，这种做法一般不够稳定。所以通常会采用mini-batch的方法，即每次选取一些数据，例如$\frac{N}{10}$，来进行训练，最后求平均值更新权重w。这种做法的实际效果会比较好一些。</p><h3 id="Optimization-and-Regularization"><a href="#Optimization-and-Regularization" class="headerlink" title="Optimization and Regularization"></a>Optimization and Regularization</h3><p>经过以上的分析和推导，我们知道神经网络优化的目标就是让$E_{in}(w)$最小化。本节课我们采用error measure是squared error，当然也可以采用其它的错误衡量方式，只要在推导上做稍稍修改就可以了，此处不再赘述。</p><p><img src="http://img.blog.csdn.net/20170801193835369?" alt="这里写图片描述"></p><p>下面我们将主要分析神经网络的优化问题。由于神经网络由输入层、多个隐藏层、输出层构成，结构是比较复杂的非线性模型，因此$E_{in}(w)$可能有许多局部最小值，是non-convex的，找到全局最小值（globalminimum）就会困难许多。而我们使用GD或SGD算法得到的很可能就是局部最小值（local minimum）。</p><p>基于这个问题，不同的初始值权重$w_{ij}^{(l)}$通常会得到不同的local minimum。也就是说最终的输出G与初始权重$w_{ij}^{(l)}$有很大的关系。在选取$w_{ij}^{(l)}$上有个技巧，就是通常选择比较小的值，而且最好是随机random选择。这是因为，如果权重$w_{ij}^{(l)}$很大，那么根据tanh函数，得到的值会分布在两侧比较平缓的位置（类似于饱和saturation），这时候梯度很小，每次迭代权重可能只有微弱的变化，很难在全局上快速得到最优解。而随机选择的原因是通常对权重$w_{ij}^{(l)}$如何选择没有先验经验，只能通过random，从普遍概率上选择初始值，随机性避免了人为因素的干预，可以说更有可能经过迭代优化得到全局最优解。</p><p><img src="http://img.blog.csdn.net/20170801203424117?" alt="这里写图片描述"></p><p>下面从理论上看一下神经网络模型的VC Dimension。对于tanh这样的transfer function，其对应的整个模型的复杂度$d_{vc}=O(VD)$。其中V是神经网络中神经元的个数（不包括bias点）,D表示所有权值的数量。所以，如果V足够大的时候，VC Dimension也会非常大，这样神经网络可以训练出非常复杂的模型。但同时也可能会造成过拟合overfitting。所以，神经网络中神经元的数量V不能太大。</p><p>为了防止神经网络过拟合，一个常用的方法就是使用regularization。之前我们就介绍过可以在error function中加入一个regularizer，例如熟悉的L2 regularizer $\Omega(w)$：</p><p>$$\Omega(w)=\sum(w_{ij}^{(l)})^2$$</p><p>但是，使用L2 regularizer 有一个缺点，就是它使每个权重进行等比例缩小（shrink）。也就是说大的权重缩小程度较大，小的权重缩小程度较小。这会带来一个问题，就是等比例缩小很难得到值为零的权重。而我们恰恰希望某些权重$w_{ij}^{(l)}=0$，即权重的解是松散（sparse）的。因为这样能有效减少VC Dimension，从而减小模型复杂度，防止过拟合发生。</p><p>那么为了得到sparse解，有什么方法呢？我们之前就介绍过可以使用L1 regularizer：$\sum|w{ij}^{(l)}|$，但是这种做法存在一个缺点，就是包含绝对值不容易微分。除此之外，另外一种比较常用的方法就是使用weight-elimination regularizer。weight-elimination regularizer类似于L2 regularizer，只不过是在L2 regularizer上做了尺度的缩小，这样能使large weight和small weight都能得到同等程度的缩小，从而让更多权重最终为零。weight-elimination regularizer的表达式如下：</p><p>$$\sum\frac{(w_{ij}^{(l)})^2}{1+(w_{ij}^{(l)})^2}$$</p><p><img src="http://img.blog.csdn.net/20170801215651811?" alt="这里写图片描述"></p><p>除了weight-elimination regularizer之外，还有另外一个很有效的regularization的方法，就是Early Stopping。简而言之，就是神经网络训练的次数t不能太多。因为，t太大的时候，相当于给模型寻找最优值更多的可能性，模型更复杂，VC Dimension增大，可能会overfitting。而t不太大时，能有效减少VC Dimension，降低模型复杂度，从而起到regularization的效果。$E_{in}$和$E_{test}$随训练次数t的关系如下图右下角所示：</p><p><img src="http://img.blog.csdn.net/20170801220409481?" alt="这里写图片描述"></p><p>那么，如何选择最佳的训练次数t呢？可以使用validation进行验证选择。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Neural Network模型。首先，我们通过使用一层甚至多层的perceptrons来获得更复杂的非线性模型。神经网络的每个神经元都相当于一个Neural Network Hypothesis，训练的本质就是在每一层网络上进行pattern extraction，找到最合适的权重$w_{ij}^{(l)}$，最终得到最佳的G。本课程以regression模型为例，最终的G是线性模型，而中间各层均采用tanh函数作为transform function。计算权重$w_{ij}^{(l)}$的方法就是采用GD或者SGD，通过Backpropagation算法，不断更新优化权重值，最终使得$E_{in}(w)$最小化，即完成了整个神经网络的训练过程。最后，我们提到了神经网络的可以使用一些regularization来防止模型过拟合。这些方法包括随机选择较小的权重初始值，使用weight-elimination regularizer或者early stopping等。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170731201555148?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记11 -- Gradient Boosted Decision Tree</title>
    <link href="https://redstonewill.github.io/2018/03/18/28/"/>
    <id>https://redstonewill.github.io/2018/03/18/28/</id>
    <published>2018-03-18T06:13:28.000Z</published>
    <updated>2018-03-18T06:20:07.897Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170727224137764?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Random Forest算法模型。Random Forest就是通过bagging的方式将许多不同的decision tree组合起来。除此之外，在decision tree中加入了各种随机性和多样性，比如不同特征的线性组合等。RF还可以使用OOB样本进行self-validation，而且可以通过permutation test进行feature selection。本节课将使用Adaptive Boosting的方法来研究decision tree的一些算法和模型。</p><h3 id="Adaptive-Boosted-Decision-Tree"><a href="#Adaptive-Boosted-Decision-Tree" class="headerlink" title="Adaptive Boosted Decision Tree"></a>Adaptive Boosted Decision Tree</h3><p>Random Forest的算法流程我们上节课也详细介绍过，就是先通过bootstrapping“复制”原样本集D，得到新的样本集D’；然后对每个D’进行训练得到不同的decision tree和对应的$g_t$；最后再将所有的$g_t$通过uniform的形式组合起来，即以投票的方式得到G。这里采用的Bagging的方式，也就是把每个$g_t$的预测值直接相加。现在，如果将Bagging替换成AdaBoost，处理方式有些不同。首先每轮bootstrap得到的D’中每个样本会赋予不同的权重$u^{(t)}$；然后在每个decision tree中，利用这些权重训练得到最好的$g_t$；最后得出每个$g_t$所占的权重，线性组合得到G。这种模型称为AdaBoost-D Tree。</p><p><img src="http://img.blog.csdn.net/20170727224137764?" alt="这里写图片描述"></p><p>但是在AdaBoost-DTree中需要注意的一点是每个样本的权重$u^{(t)}$。我们知道，在Adaptive Boosting中进行了bootstrap操作，$u^{(t)}$表示D中每个样本在D’中出现的次数。但是在决策树模型中，例如C&amp;RT算法中并没有引入$u^{(t)}$。那么，如何在决策树中引入这些权重$u^{(t)}$来得到不同的$g_t$而又不改变原来的决策树算法呢？</p><p>在Adaptive Boosting中，我们使用了weighted algorithm，形如：</p><p>$$E_{in}^u(h)=\frac1N\sum_{n=1}^Nu_n\cdot err(y_n,h(x_n))$$</p><p>每个犯错误的样本点乘以相应的权重，求和再平均，最终得到了$E_{in}^u(h)$。如果在决策树中使用这种方法，将当前分支下犯错误的点赋予权重，每层分支都这样做，会比较复杂，不易求解。为了简化运算，保持决策树算法本身的稳定性和封闭性，我们可以把决策树算法当成一个黑盒子，即不改变其结构，不对算法本身进行修改，而从数据来源D’上做一些处理。按照这种思想，我们来看权重u实际上表示该样本在bootstrap中出现的次数，反映了它出现的概率。那么可以根据u值，对原样本集D进行一次重新的随机sampling，也就是带权重的随机抽样。sampling之后，会得到一个新的D’，D’中每个样本出现的几率与它权重u所占的比例应该是差不多接近的。因此，使用带权重的sampling操作，得到了新的样本数据集D’，可以直接代入决策树进行训练，从而无需改变决策树算法结构。sampling可看成是bootstrap的反操作，这种对数据本身进行修改而不更改算法结构的方法非常重要！</p><p><img src="http://img.blog.csdn.net/20170728082507735?" alt="这里写图片描述"></p><p>所以，AdaBoost-DTree结合了AdaBoost和DTree，但是做了一点小小的改变，就是使用sampling替代权重$u^{(t)}$，效果是相同的。</p><p><img src="http://img.blog.csdn.net/20170728083007219?" alt="这里写图片描述"></p><p>上面我们通过使用sampling，将不同的样本集代入决策树中，得到不同的$g_t$。除此之外，我们还要确定每个$g_t$所占的权重$\alpha_t$。之前我们在AdaBoost中已经介绍过，首先算出每个$g_t$的错误率$\epsilon_t$，然后计算权重：</p><p>$$\alpha_t=ln\ \diamond_t=ln \sqrt{\frac{1-\epsilon_t}{\epsilon_t}}$$</p><p>如果现在有一棵完全长成的树（fully grown tree），由所有的样本$x_n$训练得到。若每个样本都不相同的话，一刀刀切割分支，直到所有的$x_n$都被完全分开。这时候，$E_{in}(g_t)=0$，加权的$E_{in}^u(g_t)=0$而且$\epsilon_t$也为0，从而得到权重$\alpha_t=\infty$。$\alpha_t=\infty$表示该$g_t$所占的权重无限大，相当于它一个就决定了G结构，是一种autocracy，而其它的$g_t$对G没有影响。</p><p><img src="http://img.blog.csdn.net/20170728091659613?" alt="这里写图片描述"></p><p>显然$\alpha_t=\infty$不是我们想看到的，因为autocracy总是不好的，我们希望使用aggregation将不同的$g_t$结合起来，发挥集体智慧来得到最好的模型G。首先，我们来看一下什么原因造成了$\alpha_t=\infty$。有两个原因：一个是使用了所有的样本$x_n$进行训练；一个是树的分支过多，fully grown。针对这两个原因，我们可以对树做一些修剪（pruned），比如只使用一部分样本，这在sampling的操作中已经起到这类作用，因为必然有些样本没有被采样到。除此之外，我们还可以限制树的高度，让分支不要那么多，从而避免树fully grown。</p><p><img src="http://img.blog.csdn.net/20170728092206113?" alt="这里写图片描述"></p><p>因此，AdaBoost-DTree使用的是pruned DTree，也就是说将这些预测效果较弱的树结合起来，得到最好的G，避免出现autocracy。</p><p><img src="http://img.blog.csdn.net/20170728100826215?" alt="这里写图片描述"></p><p>刚才我们说了可以限制树的高度，那索性将树的高度限制到最低，即只有1层高的时候，有什么特性呢？当树高为1的时候，整棵树只有两个分支，切割一次即可。如果impurity是binary classification error的话，那么此时的AdaBoost-DTree就跟AdaBoost-Stump没什么两样。也就是说AdaBoost-Stump是AdaBoost-DTree的一种特殊情况。</p><p><img src="http://img.blog.csdn.net/20170728101843620?" alt="这里写图片描述"></p><p>值得一提是，如果树高为1时，通常较难遇到$\epsilon_t=0$的情况，且一般不采用sampling的操作，而是直接将权重u代入到算法中。这是因为此时的AdaBoost-DTree就相当于是AdaBoost-Stump，而AdaBoost-Stump就是直接使用u来优化模型的。</p><h3 id="Optimization-View-of-AdaBoost"><a href="#Optimization-View-of-AdaBoost" class="headerlink" title="Optimization View of AdaBoost"></a>Optimization View of AdaBoost</h3><p>接下来，我们继续将继续探讨AdaBoost算法的一些奥妙之处。我们知道AdaBoost中的权重的迭代计算如下所示：</p><p><img src="http://img.blog.csdn.net/20170728112800984?" alt="这里写图片描述"></p><p>之前对于incorrect样本和correct样本，$u_n^{(t+1)}$的表达式不同。现在，把两种情况结合起来，将$u_n^{(t+1)}$写成一种简化的形式：</p><p>$$u_n^{(t+1)}=u_n^{(t)}\cdot \diamond_t^{-y_ng_t(x_n)}=u_n^{(t)}\cdot exp(-y_n\alpha_tg_t(x_n))$$</p><p>其中，对于incorrect样本，$y_ng_t(x_n)&lt;0$，对于correct样本，$y_ng_t(x_n)&gt;0$。从上式可以看出，$u_n^{(t+1)}$由$u_n^{(t)}$与某个常数相乘得到。所以，最后一轮更新的$u_n^{(T+1)}$可以写成$u_n^{(1)}$的级联形式，我们之前令$u_n^{(1)}=\frac1N$，则有如下推导：</p><p>$$u_n^{(T+1)}=u_n^{(1)}\cdot \prod_{t=1}^Texp(-y_n\alpha_tg_t(x_n))=\frac1N\cdot exp(-y_n\sum_{t=1}^T\alpha_tg_t(x_n))$$</p><p>上式中$\sum_{t=1}^T\alpha_tg_t(x_n)$被称为voting score，最终的模型$G=sign(\sum_{t=1}^T\alpha_tg_t(x_n))$。可以看出，在AdaBoost中，$u_n^{(T+1)}$与$exp(-y_n(voting\ score\ on\ x_n))$成正比。</p><p><img src="http://img.blog.csdn.net/20170728152407683?" alt="这里写图片描述"></p><p>接下来我们继续看一下voting score中蕴含了哪些内容。如下图所示，voting score由许多$g_t(x_n)$乘以各自的系数$\alpha_t$线性组合而成。从另外一个角度来看，我们可以把$g_t(x_n)$看成是对$x_n$的特征转换$\phi_i(x_n)$，$\alpha_t$就是线性模型中的权重$w_i$。看到这里，我们回忆起之前SVM中，w与$\phi (x_n)$的乘积再除以w的长度就是margin，即点到边界的距离。另外，乘积项再与$y_n$相乘，表示点的位置是在正确的那一侧还是错误的那一侧。所以，回过头来，这里的voting score实际上可以看成是没有正规化（没有除以w的长度）的距离，即可以看成是该点到分类边界距离的一种衡量。从效果上说，距离越大越好，也就是说voting score要尽可能大一些。</p><p><img src="http://img.blog.csdn.net/20170728152804003?" alt="这里写图片描述"></p><p>我们再来看，若voting score与$y_n$相乘，则表示一个有对错之分的距离。也就是说，如果二者相乘是负数，则表示该点在错误的一边，分类错误；如果二者相乘是正数，则表示该点在正确的一边，分类正确。所以，我们算法的目的就是让$y_n$与voting score的乘积是正的，而且越大越好。那么在刚刚推导的$u_n^{(T+1)}$中，得到$exp(-y_n(voting\ score))$越小越好，从而得到$u_n^{(T+1)}$越小越好。也就是说，如果voting score表现不错，与$y_n$的乘积越大的话，那么相应的$u_n^{(T+1)}$应该是最小的。</p><p><img src="http://img.blog.csdn.net/20170728160416115?" alt="这里写图片描述"></p><p>那么在AdaBoost中，随着每轮学习的进行，每个样本的$u_n^{(t)}$是逐渐减小的，直到$u_n^{(T+1)}$最小。以上是从单个样本点来看的。总体来看，所有样本的$u_n^{(T+1)}$之和应该也是最小的。我们的目标就是在最后一轮（T+1）学习后，让所有样本的$u_n^{(T+1)}$之和尽可能地小。$u_n^{(T+1)}$之和表示为如下形式：</p><p><img src="http://img.blog.csdn.net/20170728164526912?" alt="这里写图片描述"></p><p>上式中，$\sum_{t=1}^T\alpha_tg_t(x_n)$被称为linear score，用s表示。对于0/1 error：若ys&lt;0，则$err_{0/1}=1$；若ys&gt;=0，则$err_{0/1}=0$。如下图右边黑色折线所示。对于上式中提到的指数error，即$\hat{err}_{ADA}(s,y)=exp(-ys)$，随着ys的增加，error单调下降，且始终落在0/1 error折线的上面。如下图右边蓝色曲线所示。很明显，$\hat{err}_{ADA}(s,y)$可以看成是0/1 error的上界。所以，我们可以使用$\hat{err}_{ADA}(s,y)$来替代0/1 error，能达到同样的效果。从这点来说，$\sum_{n=1}^Nu_n^{(T+1)}$可以看成是一种error measure，而我们的目标就是让其最小化，求出最小值时对应的各个$\alpha_t$和$g_t(x_n)$。</p><p><img src="http://img.blog.csdn.net/20170728164931978?" alt="这里写图片描述"></p><p>下面我们来研究如何让$\sum_{n=1}^Nu_n^{(T+1)}$取得最小值，思考是否能用梯度下降（gradient descent）的方法来进行求解。我们之前介绍过gradient descent的核心是在某点处做一阶泰勒展开：</p><p><img src="http://img.blog.csdn.net/20170728204308067?" alt="这里写图片描述"></p><p>其中，$w_t$是泰勒展开的位置，v是所要求的下降的最好方向，它是梯度$\nabla E_{in}(w_t)$的反方向，而$\eta$是每次前进的步长。则每次沿着当前梯度的反方向走一小步，就会不断逼近谷底（最小值）。这就是梯度下降算法所做的事情。</p><p>现在，我们对$\check{E}_{ADA}$做梯度下降算法处理，区别是这里的方向是一个函数$g_t$，而不是一个向量$w_t$。其实，函数和向量的唯一区别就是一个下标是连续的，另一个下标是离散的，二者在梯度下降算法应用上并没有大的区别。因此，按照梯度下降算法的展开式，做出如下推导：</p><p><img src="http://img.blog.csdn.net/20170728211939429?" alt="这里写图片描述"></p><p>上式中，$h(x_n)$表示当前的方向，它是一个矩，$\eta$是沿着当前方向前进的步长。我们要求出这样的$h(x_n)$和$\eta$，使得$\check{E}_{ADA}$是在不断减小的。当$\check{E}_{ADA}$取得最小值的时候，那么所有的方向即最佳的$h(x_n)$和$\eta$就都解出来了。上述推导使用了在$-y_n\eta h(x_n)=0$处的一阶泰勒展开近似。这样经过推导之后，$\check{E}_{ADA}$被分解为两个部分，一个是前N个u之和$\sum_{n=1}^Nu_n^{(t)}$，也就是当前所有的$E_{in}$之和；另外一个是包含下一步前进的方向$h(x_n)$和步进长度$\eta$的项$-\eta\sum_{n=1}^Nu_n^{(t)}y_nh(x_n)$。$\check{E}_{ADA}$的这种形式与gradient descent的形式基本是一致的。</p><p>那么接下来，如果要最小化$\check{E}_{ADA}$的话，就要让第二项$-\eta\sum_{n=1}^Nu_n^{(t)}y_nh(x_n)$越小越好。则我们的目标就是找到一个好的$h(x_n)$（即好的方向）来最小化$\sum_{n=1}^Nu_n^{(t)}(-y_nh(x_n))$，此时先忽略步进长度$\eta$。</p><p><img src="http://img.blog.csdn.net/20170729142004595?" alt="这里写图片描述"></p><p>对于binary classification，$y_n$和$h(x_n)$均限定取值-1或+1两种。我们对$\sum_{n=1}^Nu_n^{(t)}(-y_nh(x_n))$做一些推导和平移运算：</p><p><img src="http://img.blog.csdn.net/20170729143137084?" alt="这里写图片描述"></p><p>最终$\sum_{n=1}^Nu_n^{(t)}(-y_nh(x_n))$化简为两项组成，一项是$-\sum_{n=1}^Nu_n^{(t)}$；另一项是$2E_{in}^{u(t)}(h)\cdot N$。则最小化$\sum_{n=1}^Nu_n^{(t)}(-y_nh(x_n))$就转化为最小化$E_{in}^{u(t)}(h)$。要让$E_{in}^{u(t)}(h)$最小化，正是由AdaBoost中的base algorithm所做的事情。所以说，AdaBoost中的base algorithm正好帮我们找到了梯度下降中下一步最好的函数方向。</p><p><img src="http://img.blog.csdn.net/20170729144354065?" alt="这里写图片描述"></p><p>以上就是从数学上，从gradient descent角度验证了AdaBoost中使用base algorithm得到的$g_t$就是让$\check{E}_{ADA}$减小的方向，只不过这个方向是一个函数而不是向量。</p><p>在解决了方向问题后，我们需要考虑步进长度$\eta$如何选取。方法是在确定方向$g_t$后，选取合适的$\eta$，使$\check{E}_{ADA}$取得最小值。也就是说，把$\check{E}_{ADA}$看成是步进长度$\eta$的函数，目标是找到$\check{E}_{ADA}$最小化时对应的$\eta$值。</p><p><img src="http://img.blog.csdn.net/20170729150613470?" alt="这里写图片描述"></p><p>目的是找到在最佳方向上的最大步进长度，也就是steepest decent。我们先把$\check{E}_{ADA}$表达式写下来：</p><p>$$\check{E}_{ADA}=\sum_{n=1}^Nu_n^{(t)}exp(-y_n\eta g_t(x_n))$$</p><p>上式中，有两种情况需要考虑：</p><ul><li><p><strong>$y_n=g_t(x_n)$：$u_n^{(t)}exp(-\eta)$  correct</strong></p></li><li><p><strong>$y_n\neq g_t(x_n)$：$u_n^{(t)}exp(+\eta)$ incorrect</strong></p></li></ul><p>经过推导，可得：</p><p>$$\check{E}_{ADA}=(\sum_{n=1}^Nu_n^{(t)})\cdot ((1-\epsilon_t)exp(-\eta)+\epsilon_t\ exp(+\eta))$$</p><p><img src="http://img.blog.csdn.net/20170729153724406?" alt="这里写图片描述"></p><p>然后对$\eta$求导，令$\frac{\partial \check{E}_{ADA}}{\partial \eta}=0$，得：</p><p>$$\eta_t=ln\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}=\alpha_t$$</p><p>由此看出，最大的步进长度就是$\alpha_t$，即AdaBoost中计算$g_t$所占的权重。所以，AdaBoost算法所做的其实是在gradient descent上找到下降最快的方向和最大的步进长度。这里的方向就是$g_t$，它是一个函数，而步进长度就是$\alpha_t$。也就是说，在AdaBoost中确定$g_t$和$\alpha_t$的过程就相当于在gradient descent上寻找最快的下降方向和最大的步进长度。</p><h3 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h3><p>前面我们从gradient descent的角度来重新介绍了AdaBoost的最优化求解方法。整个过程可以概括为：</p><p><img src="http://img.blog.csdn.net/20170729163241034?" alt="这里写图片描述"></p><p>以上是针对binary classification问题。如果往更一般的情况进行推广，对于不同的error function，比如logistic error function或者regression中的squared error function，那么这种做法是否仍然有效呢？这种情况下的GradientBoost可以写成如下形式：</p><p><img src="http://img.blog.csdn.net/20170729163848352?" alt="这里写图片描述"></p><p>仍然按照gradient descent的思想，上式中，$h(x_n)$是下一步前进的方向，$\eta$是步进长度。此时的error function不是前面所讲的exp了，而是任意的一种error function。因此，对应的hypothesis也不再是binary classification，最常用的是实数输出的hypothesis，例如regression。最终的目标也是求解最佳的前进方向$h(x_n)$和最快的步进长度$\eta$。</p><p><img src="http://img.blog.csdn.net/20170729164531417?" alt="这里写图片描述"></p><p>接下来，我们就来看看如何求解regression的GradientBoost问题。它的表达式如下所示：</p><p><img src="http://img.blog.csdn.net/20170729171758072?" alt="这里写图片描述"></p><p>利用梯度下降的思想，我们把上式进行一阶泰勒展开，写成梯度的形式：</p><p><img src="http://img.blog.csdn.net/20170729193033365?" alt="这里写图片描述"></p><p>上式中，由于regression的error function是squared的，所以，对s的导数就是$2(s_n-y_n)$。其中标注灰色的部分表示常数，对最小化求解并没有影响，所以可以忽略。很明显，要使上式最小化，只要令$h(x_n)$是梯度$2(s_n-y_n)$的反方向就行了，即$h(x_n)=-2(s_n-y_n)$。但是直接这样赋值，并没有对$h(x_n)$的大小进行限制，一般不直接利用这个关系求出$h(x_n)$。</p><p><img src="http://img.blog.csdn.net/20170729194745405?" alt="这里写图片描述"></p><p>实际上$h(x_n)$的大小并不重要，因为有步进长度$\eta$。那么，我们上面的最小化问题中需要对$h(x_n)$的大小做些限制。限制$h(x_n)$的一种简单做法是把$h(x_n)$的大小当成一个惩罚项（$h^2(x_n)$）添加到上面的最小化问题中，这种做法与regularization类似。如下图所示，经过推导和整理，忽略常数项，我们得到最关心的式子是：</p><p>$$min\ \sum_{n=1}^N((h(x_n)-(y_n-s_n))^2)$$</p><p>上式是一个完全平方项之和，$y_n-s_n$表示当前第n个样本真实值和预测值的差，称之为余数。余数表示当前预测能够做到的效果与真实值的差值是多少。那么，如果我们想要让上式最小化，求出对应的$h(x_n)$的话，只要让$h(x_n)$尽可能地接近余数$y_n-s_n$即可。在平方误差上尽可能接近其实很简单，就是使用regression的方法，对所有N个点$(x_n,y_n-s_n)$做squared-error的regression，得到的回归方程就是我们要求的$g_t(x_n)$。</p><p><img src="http://img.blog.csdn.net/20170729212101227?" alt="这里写图片描述"></p><p>以上就是使用GradientBoost的思想来解决regression问题的方法，其中应用了一个非常重要的概念，就是余数$y_n-s_n$。根据这些余数做regression，得到好的矩$g_t(x_n)$，方向函数$g_t(x_n)$也就是由余数决定的。</p><p><img src="http://img.blog.csdn.net/20170729212214760?" alt="这里写图片描述"></p><p>在求出最好的方向函数$g_t(x_n)$之后，就要来求相应的步进长度$\eta$。表达式如下：</p><p><img src="http://img.blog.csdn.net/20170729212637843?" alt="这里写图片描述"></p><p>同样，对上式进行推导和化简，得到如下表达式：</p><p><img src="http://img.blog.csdn.net/20170729213112322?" alt="这里写图片描述"></p><p>上式中也包含了余数$y_n-s_n$，其中$g_t(x_n)$可以看成是$x_n$的特征转换，是已知量。那么，如果我们想要让上式最小化，求出对应的$\eta$的话，只要让$\eta g_t(x_n)$尽可能地接近余数$y_n-s_n$即可。显然，这也是一个regression问题，而且是一个很简单的形如y=ax的线性回归，只有一个未知数$\eta$。只要对所有N个点$(\eta g_t(x_n),y_n-s_n)$做squared-error的linear regression，利用梯度下降算法就能得到最佳的$\eta$。</p><p>将上述这些概念合并到一起，我们就得到了一个最终的演算法Gradient Boosted Decision Tree(GBDT)。可能有人会问，我们刚才一直没有说到Decison Tree，只是讲到了GradientBoost啊？下面我们来看看Decison Tree究竟是在哪出现并使用的。其实刚刚我们在计算方向函数$g_t$的时候，是对所有N个点$(x_n,y_n-s_n)$做squared-error的regression。那么这个回归算法就可以是决策树C&amp;RT模型（决策树也可以用来做regression）。这样，就引入了Decision Tree，并将GradientBoost和Decision Tree结合起来，构成了真正的GBDT算法。GBDT算法的基本流程图如下所示：</p><p><img src="http://img.blog.csdn.net/20170729215009725?" alt="这里写图片描述"></p><p>值得注意的是，$s_n$的初始值一般均设为0，即$s_1=s_2=\cdots =s_N=0$。每轮迭代中，方向函数$g_t$通过C&amp;RT算法做regression，进行求解；步进长度$\eta$通过简单的单参数线性回归进行求解；然后每轮更新$s_n$的值，即$s_n\leftarrow s_n+\alpha_tg_t(x_n)$。T轮迭代结束后，最终得到$G(x)=\sum_{t=1}^T\alpha_tg_t(x)$。</p><p>值得一提的是，本节课第一部分介绍的AdaBoost-DTree是解决binary classification问题，而此处介绍的GBDT是解决regression问题。二者具有一定的相似性，可以说GBDT就是AdaBoost-DTree的regression版本。</p><p><img src="http://img.blog.csdn.net/20170729220455297?" alt="这里写图片描述"></p><h3 id="Summary-ofAggregation-Models"><a href="#Summary-ofAggregation-Models" class="headerlink" title="Summary ofAggregation Models"></a>Summary ofAggregation Models</h3><p>从机器学习技法课程的第7节课笔记到现在的第11节课笔记，我们已经介绍完所有的aggregation模型了。接下来，我们将对这些内容进行一个简单的总结和概括。</p><p>首先，我们介绍了blending。blending就是将所有已知的$g_t$ aggregate结合起来，发挥集体的智慧得到G。值得注意的一点是这里的$g_t$都是已知的。blending通常有三种形式：</p><ul><li><p><strong>uniform：简单地计算所有$g_t$的平均值</strong></p></li><li><p><strong>non-uniform：所有$g_t$的线性组合</strong></p></li><li><p><strong>conditional：所有$g_t$的非线性组合</strong></p></li></ul><p>其中，uniform采用投票、求平均的形式更注重稳定性；而non-uniform和conditional追求的更复杂准确的模型，但存在过拟合的危险。</p><p><img src="http://img.blog.csdn.net/20170730095242485?" alt="这里写图片描述"></p><p>刚才讲的blending是建立在所有$g_t$已知的情况。那如果所有$g_t$未知的情况，对应的就是learning模型，做法就是一边学$g_t$，一边将它们结合起来。learning通常也有三种形式（与blending的三种形式一一对应）：</p><ul><li><p><strong>Bagging：通过bootstrap方法，得到不同$g_t$，计算所有$g_t$的平均值</strong></p></li><li><p><strong>AdaBoost：通过bootstrap方法，得到不同$g_t$，所有$g_t$的线性组合</strong></p></li><li><p><strong>Decision Tree：通过数据分割的形式得到不同的$g_t$，所有$g_t$的非线性组合</strong></p></li></ul><p>然后，本节课我们将AdaBoost延伸到另一个模型GradientBoost。对于regression问题，GradientBoost通过residual fitting的方式得到最佳的方向函数$g_t$和步进长度$\eta$。</p><p><img src="http://img.blog.csdn.net/20170730103158989?" alt="这里写图片描述"></p><p>除了这些基本的aggregation模型之外，我们还可以把某些模型结合起来得到新的aggregation模型。例如，Bagging与Decision Tree结合起来组成了Random Forest。Random Forest中的Decision Tree是比较“茂盛”的树，即每个树的$g_t$都比较强一些。AdaBoost与Decision Tree结合组成了AdaBoost-DTree。AdaBoost-DTree的Decision Tree是比较“矮弱”的树，即每个树的$g_t$都比较弱一些，由AdaBoost将所有弱弱的树结合起来，让综合能力更强。同样，GradientBoost与Decision Tree结合就构成了经典的算法GBDT。</p><p><img src="http://img.blog.csdn.net/20170730105341073?" alt="这里写图片描述"></p><p>Aggregation的核心是将所有的$g_t$结合起来，融合到一起，即集体智慧的思想。这种做法之所以能得到很好的模型G，是因为aggregation具有两个方面的优点：cure underfitting和cure overfitting。</p><p>第一，aggregation models有助于防止欠拟合（underfitting）。它把所有比较弱的$g_t$结合起来，利用集体智慧来获得比较好的模型G。aggregation就相当于是feature transform，来获得复杂的学习模型。</p><p>第二，aggregation models有助于防止过拟合（overfitting）。它把所有$g_t$进行组合，容易得到一个比较中庸的模型，类似于SVM的large margin一样的效果，从而避免一些极端情况包括过拟合的发生。从这个角度来说，aggregation起到了regularization的效果。</p><p>由于aggregation具有这两个方面的优点，所以在实际应用中aggregation models都有很好的表现。</p><p><img src="http://img.blog.csdn.net/20170730125759015?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Gradient Boosted Decision Tree。首先讲如何将AdaBoost与Decision Tree结合起来，即通过sampling和pruning的方法得到AdaBoost-D Tree模型。然后，我们从optimization的角度来看AdaBoost，找到好的hypothesis也就是找到一个好的方向，找到权重$\alpha$也就是找到合适的步进长度。接着，我们从binary classification的0/1 error推广到其它的error function，从Gradient Boosting角度推导了regression的squared error形式。Gradient Boosting其实就是不断迭代，做residual fitting。并将其与Decision Tree算法结合，得到了经典的GBDT算法。最后，我们将所有的aggregation models做了总结和概括，这些模型有的能防止欠拟合有的能防止过拟合，应用十分广泛。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170727224137764?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记10 -- Random Forest</title>
    <link href="https://redstonewill.github.io/2018/03/18/27/"/>
    <id>https://redstonewill.github.io/2018/03/18/27/</id>
    <published>2018-03-18T06:08:43.000Z</published>
    <updated>2018-03-18T06:10:44.505Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170725105700489?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Decision Tree模型。Decision Tree算法的核心是通过递归的方式，将数据集不断进行切割，得到子分支，最终形成数的结构。C&amp;RT算法是决策树比较简单和常用的一种算法，其切割的标准是根据纯度来进行，每次切割都是为了让分支内部纯度最大。最终，决策树不同的分支得到不同的$g_t(x)$（即树的叶子，C&amp;RT算法中，$g_t(x)$是常数）。本节课将介绍随机森林（Random Forest）算法，它是我们之前介绍的Bagging和上节课介绍的Decision Tree的结合。</p><h3 id="Random-Forest-Algorithm"><a href="#Random-Forest-Algorithm" class="headerlink" title="Random Forest Algorithm"></a>Random Forest Algorithm</h3><p>首先我们来复习一下之前介绍过的两个机器学习模型：Bagging和Decision Tree。Bagging是通过bootstrap的方式，从原始的数据集D中得到新的$\hat{D}$；然后再使用一些base algorithm对每个$\hat{D}$都得到相应的$g_t$；最后将所有的$g_t$通过投票uniform的形式组合成一个G，G即为我们最终得到的模型。Decision Tree是通过递归形式，利用分支条件，将原始数据集D切割成一个个子树结构，长成一棵完整的树形结构。Decision Tree最终得到的G(x)是由相应的分支条件b(x)和分支树$G_c(x)$递归组成。</p><p><img src="http://img.blog.csdn.net/20170725105700489?" alt="这里写图片描述"></p><p>Bagging和Decison Tree算法各自有一个很重要的特点。Bagging具有减少不同$g_t$的方差variance的特点。这是因为Bagging采用投票的形式，将所有$g_t$uniform结合起来，起到了求平均的作用，从而降低variance。而Decision Tree具有增大不同$g_t$的方差variance的特点。这是因为Decision Tree每次切割的方式不同，而且分支包含的样本数在逐渐减少，所以它对不同的资料D会比较敏感一些，从而不同的D会得到比较大的variance。</p><p>所以说，Bagging能减小variance，而Decision Tree能增大variance。如果把两者结合起来，能否发挥各自的优势，起到优势互补的作用呢？这就是我们接下来将要讨论的aggregation of aggregation，即使用Bagging的方式把众多的Decision Tree进行uniform结合起来。这种算法就叫做随机森林（Random Forest），它将完全长成的C&amp;RT决策树通过bagging的形式结合起来，最终得到一个庞大的决策模型。</p><p><img src="http://img.blog.csdn.net/20170725133154097?" alt="这里写图片描述"></p><p>Random Forest算法流程图如下所示：</p><p><img src="http://img.blog.csdn.net/20170725134328625?" alt="这里写图片描述"></p><p>Random Forest算法的优点主要有三个。第一，不同决策树可以由不同主机并行训练生成，效率很高；第二，随机森林算法继承了C&amp;RT的优点；第三，将所有的决策树通过bagging的形式结合起来，避免了单个决策树造成过拟合的问题。</p><p><img src="http://img.blog.csdn.net/20170725135521243?" alt="这里写图片描述"></p><p>以上是基本的Random Forest算法，我们再来看一下如何让Random Forest中决策树的结构更有多样性。Bagging中，通过bootstrap的方法得到不同于D的D’，使用这些随机抽取的资料得到不同的$g_t$。除了随机抽取资料获得不同$g_t$的方式之外，还有另外一种方法，就是随机抽取一部分特征。例如，原来有100个特征，现在只从中随机选取30个来构成决策树，那么每一轮得到的树都由不同的30个特征构成，每棵树都不一样。假设原来样本维度是d，则只选择其中的d’（d’小于d）个维度来建立决策树结构。这类似是一种从d维到d’维的特征转换，相当于是从高维到低维的投影，也就是说d’维z空间其实就是d维x空间的一个随机子空间（subspace）。通常情况下，d’远小于d，从而保证算法更有效率。Random Forest算法的作者建议在构建C&amp;RT每个分支b(x)的时候，都可以重新选择子特征来训练，从而得到更具有多样性的决策树。</p><p><img src="http://img.blog.csdn.net/20170725143051066?" alt="这里写图片描述"></p><p>所以说，这种增强的Random Forest算法增加了random-subspace。</p><p><img src="http://img.blog.csdn.net/20170725143437035?" alt="这里写图片描述"></p><p>上面我们讲的是随机抽取特征，除此之外，还可以将现有的特征x，通过数组p进行线性组合，来保持多样性：</p><p>$$\phi_i(x)=p_i^Tx$$</p><p>这种方法使每次分支得到的不再是单一的子特征集合，而是子特征的线性组合（权重不为1）。好比在二维平面上不止得到水平线和垂直线，也能得到各种斜线。这种做法使子特征选择更加多样性。值得注意的是，不同分支i下的$p_i$是不同的，而且向量$p_i$中大部分元素为零，因为我们选择的只是一部分特征，这是一种低维映射。</p><p><img src="http://img.blog.csdn.net/20170725152429905?" alt="这里写图片描述"></p><p>所以，这里的Random Forest算法又有增强，由原来的random-subspace变成了random-combination。顺便提一下，这里的random-combination类似于perceptron模型。</p><p><img src="http://img.blog.csdn.net/20170725152726569?" alt="这里写图片描述"></p><h3 id="Out-Of-Bag-Estimate"><a href="#Out-Of-Bag-Estimate" class="headerlink" title="Out-Of-Bag Estimate"></a>Out-Of-Bag Estimate</h3><p>上一部分我们已经介绍了Random Forest算法，而Random Forest算法重要的一点就是Bagging。接下来将继续探讨bagging中的bootstrap机制到底蕴含了哪些可以为我们所用的东西。</p><p>通过bootstrap得到新的样本集D’，再由D’训练不同的$g_t$。我们知道D’中包含了原样本集D中的一些样本，但也有些样本没有涵盖进去。如下表所示，不同的$g_t$下，红色的<em>表示在$\hat D_t$中没有这些样本。例如对$g_1$来说，$(x_2,y_2)$和$(x_3,y_4)$没有包含进去，对$g_2$来说，$(x_1,y_1)$和$(x_2,y_2)$没有包含进去，等等。每个$g_t$中，红色</em>表示的样本被称为out-of-bag(OOB) example。</p><p><img src="http://img.blog.csdn.net/20170725211414590?" alt="这里写图片描述"></p><p>首先，我们来计算OOB样本到底有多少。假设bootstrap的数量N’=N，那么某个样本$(x_n,y_n)$是OOB的概率是：</p><p>$$(1-\frac1N)^N=\frac{1}{(\frac{N}{N-1})^N}=\frac{1}{(1+\frac{1}{N-1})^N}\approx \frac1e$$</p><p>其中，e是自然对数，N是原样本集的数量。由上述推导可得，每个$g_t$中，OOB数目大约是$\frac1eN$，即大约有三分之一的样本没有在bootstrap中被抽到。</p><p>然后，我们将OOB与之前介绍的Validation进行对比：</p><p><img src="http://img.blog.csdn.net/20170725215140036?" alt="这里写图片描述"></p><p>在Validation表格中，蓝色的$D_{train}$用来得到不同的$g_m^-$，而红色的$D_{val}$用来验证各自的$g_m^-$。$D_{train}$与$D_{val}$没有交集，一般$D_{train}$是$D_{val}$的数倍关系。再看左边的OOB表格，之前我们也介绍过，蓝色的部分用来得到不同的$g_t$，而红色的部分是OOB样本。而我们刚刚也推导过，红色部分大约占N的$\frac1e$。通过两个表格的比较，我们发现OOB样本类似于$D_{val}$，那么是否能使用OOB样本来验证$g_t$的好坏呢？答案是肯定的。但是，通常我们并不需要对单个$g_t$进行验证。因为我们更关心的是由许多$g_t$组合成的G，即使$g_t$表现不太好，只要G表现足够好就行了。那么问题就转化成了如何使用OOB来验证G的好坏。方法是先看每一个样本$(x_n,y_n)$是哪些$g_t$的OOB资料，然后计算其在这些$g_t$上的表现，最后将所有样本的表现求平均即可。例如，样本$(x_N,y_N)$是$g_2$，$g_3$，$g_T$的OOB，则可以计算$(x_N,y_N)$在$G_N^-(x)$上的表现为：</p><p>$$G_N^-(x)=average(g_2,g_3,g_T)$$</p><p>这种做法我们并不陌生，就像是我们之前介绍过的Leave-One-Out Cross Validation，每次只对一个样本进行$g^-$的验证一样，只不过这里选择的是每个样本是哪些$g_t$的OOB，然后再分别进行$G_n^-(x)$的验证。每个样本都当成验证资料一次（与留一法相同），最后计算所有样本的平均表现：</p><p>$$E_{oob}(G)=\frac1N\sum_{n=1}^Nerr(y_n,G_n^-(x_n))$$</p><p>$E_{oob}(G)$估算的就是G的表现好坏。我们把$E_{oob}$称为bagging或者Random Forest的self-validation。</p><p>这种self-validation相比于validation来说还有一个优点就是它不需要重复训练。如下图左边所示，在通过$D_{val}$选择到表现最好的$g_{m^<em>}^-$之后，还需要在$D_{train}$和$D_{val}$组成的所有样本集D上重新对该模型$g_{m^</em>}^-$训练一次，以得到最终的模型系数。但是self-validation在调整随机森林算法相关系数并得到最小的$E_{oob}$之后，就完成了整个模型的建立，无需重新训练模型。随机森林算法中，self-validation在衡量G的表现上通常相当准确。</p><p><img src="http://img.blog.csdn.net/20170726082341574?" alt="这里写图片描述"></p><h3 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h3><p>如果样本资料特征过多，假如有10000个特征，而我们只想从中选取300个特征，这时候就需要舍弃部分特征。通常来说，需要移除的特征分为两类：一类是冗余特征，即特征出现重复，例如“年龄”和“生日”；另一类是不相关特征，例如疾病预测的时候引入的“保险状况”。这种从d维特征到d’维特征的subset-transform $\Phi(x)$称为Feature Selection，最终使用这些d’维的特征进行模型训练。</p><p><img src="http://img.blog.csdn.net/20170726084338825?" alt="这里写图片描述"></p><p>特征选择的优点是：</p><ul><li><p><strong>提高效率，特征越少，模型越简单</strong></p></li><li><p><strong>正则化，防止特征过多出现过拟合</strong></p></li><li><p><strong>去除无关特征，保留相关性大的特征，解释性强</strong></p></li></ul><p>同时，特征选择的缺点是：</p><ul><li><p><strong>筛选特征的计算量较大</strong></p></li><li><p><strong>不同特征组合，也容易发生过拟合</strong></p></li><li><p><strong>容易选到无关特征，解释性差</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170726085416881?" alt="这里写图片描述"></p><p>值得一提的是，在decision tree中，我们使用的decision stump切割方式也是一种feature selection。</p><p>那么，如何对许多维特征进行筛选呢？我们可以通过计算出每个特征的重要性（即权重），然后再根据重要性的排序进行选择即可。</p><p><img src="http://img.blog.csdn.net/20170726092243523?" alt="这里写图片描述"></p><p>这种方法在线性模型中比较容易计算。因为线性模型的score是由每个特征经过加权求和而得到的，而加权系数的绝对值$|w_i|$正好代表了对应特征$x_i$的重要性为多少。$|w_i|$越大，表示对应特征$x_i$越重要，则该特征应该被选择。w的值可以通过对已有的数据集$(x_i,y_i)$建立线性模型而得到。</p><p><img src="http://img.blog.csdn.net/20170726093713158?" alt="这里写图片描述"></p><p>然而，对于非线性模型来说，因为不同特征可能是非线性交叉在一起的，所以计算每个特征的重要性就变得比较复杂和困难。例如，Random Forest就是一个非线性模型，接下来，我们将讨论如何在RF下进行特征选择。</p><p>RF中，特征选择的核心思想是random test。random test的做法是对于某个特征，如果用另外一个随机值替代它之后的表现比之前更差，则表明该特征比较重要，所占的权重应该较大，不能用一个随机值替代。相反，如果随机值替代后的表现没有太大差别，则表明该特征不那么重要，可有可无。所以，通过比较某特征被随机值替代前后的表现，就能推断出该特征的权重和重要性。</p><p>那么random test中的随机值如何选择呢？通常有两种方法：一是使用uniform或者gaussian抽取随机值替换原特征；一是通过permutation的方式将原来的所有N个样本的第i个特征值重新打乱分布（相当于重新洗牌）。比较而言，第二种方法更加科学，保证了特征替代值与原特征的分布是近似的（只是重新洗牌而已）。这种方法叫做permutation test（随机排序测试），即在计算第i个特征的重要性的时候，将N个样本的第i个特征重新洗牌，然后比较D和$D^{(p)}$表现的差异性。如果差异很大，则表明第i个特征是重要的。</p><p><img src="http://img.blog.csdn.net/20170726143830318?" alt="这里写图片描述"></p><p>知道了permutation test的原理后，接下来要考虑的问题是如何衡量上图中的performance，即替换前后的表现。显然，我们前面介绍过performance可以用$E_{oob}(G)$来衡量。但是，对于N个样本的第i个特征值重新洗牌重置的$D^{(p)}$，要对它进行重新训练，而且每个特征都要重复训练，然后再与原D的表现进行比较，过程非常繁琐。为了简化运算，RF的作者提出了一种方法，就是把permutation的操作从原来的training上移到了OOB validation上去，记为$E_{oob}(G^{(p)})\rightarrow E_{oob}^{(p)}(G)$。也就是说，在训练的时候仍然使用D，但是在OOB验证的时候，将所有的OOB样本的第i个特征重新洗牌，验证G的表现。这种做法大大简化了计算复杂度，在RF的feature selection中应用广泛。</p><p><img src="http://img.blog.csdn.net/20170726151729634?" alt="这里写图片描述"></p><h3 id="Random-Forest-in-Action"><a href="#Random-Forest-in-Action" class="headerlink" title="Random Forest in Action"></a>Random Forest in Action</h3><p>最后，我们通过实际的例子来看一下RF的特点。首先，仍然是一个二元分类的例子。如下图所示，左边是一个C&amp;RT树没有使用bootstrap得到的模型分类效果，其中不同特征之间进行了随机组合，所以有斜线作为分类线；中间是由bootstrap（N’=N/2）后生成的一棵决策树组成的随机森林，图中加粗的点表示被bootstrap选中的点；右边是将一棵决策树进行bagging后的分类模型，效果与中间图是一样的，都是一棵树。</p><p><img src="http://img.blog.csdn.net/20170726163347833?" alt="这里写图片描述"></p><p>当t=100，即选择了100棵树时，中间的模型是第100棵决策树构成的，还是只有一棵树；右边的模型是由100棵决策树bagging起来的，如下图所示：</p><p><img src="http://img.blog.csdn.net/20170726164544531?" alt="这里写图片描述"></p><p>当t=200时：</p><p><img src="http://img.blog.csdn.net/20170726164429459?" alt="这里写图片描述"></p><p>当t=300时：</p><p><img src="http://img.blog.csdn.net/20170726164627674?" alt="这里写图片描述"></p><p>当t=400时：</p><p><img src="http://img.blog.csdn.net/20170726164705931?" alt="这里写图片描述"></p><p>当t=500时：</p><p><img src="http://img.blog.csdn.net/20170726164745342?" alt="这里写图片描述"></p><p>当t=600时：</p><p><img src="http://img.blog.csdn.net/20170726164831176?" alt="这里写图片描述"></p><p>当t=700时：</p><p><img src="http://img.blog.csdn.net/20170726164913572?" alt="这里写图片描述"></p><p>当t=800时：</p><p><img src="http://img.blog.csdn.net/20170726164952799?" alt="这里写图片描述"></p><p>当t=900时：</p><p><img src="http://img.blog.csdn.net/20170726165038648?" alt="这里写图片描述"></p><p>当t=1000时：</p><p><img src="http://img.blog.csdn.net/20170726165122742?" alt="这里写图片描述"></p><p>随着树木个数的增加，我们发现，分界线越来越光滑而且得到了large-margin-like boundary，类似于SVM一样的效果。也就是说，树木越多，分类器的置信区间越大。</p><p>然后，我们再来看一个比较复杂的例子，二维平面上分布着许多离散点，分界线形如sin函数。当只有一棵树的时候（t=1），下图左边表示单一树组成的RF，右边表示所有树bagging组合起来构成的RF。因为只有一棵树，所以左右两边效果一致。</p><p><img src="http://img.blog.csdn.net/20170726170024403?" alt="这里写图片描述"></p><p>当t=6时：</p><p><img src="http://img.blog.csdn.net/20170726170110624?" alt="这里写图片描述"></p><p>当t=11时：</p><p><img src="http://img.blog.csdn.net/20170726170152368?" alt="这里写图片描述"></p><p>当t=16时：</p><p><img src="http://img.blog.csdn.net/20170726170228226?" alt="这里写图片描述"></p><p>当t=21时：</p><p><img src="http://img.blog.csdn.net/20170726170319362?" alt="这里写图片描述"></p><p>可以看到，当RF由21棵树构成的时候，分界线就比较平滑了，而且它的边界比单一树构成的RF要robust得多，更加平滑和稳定。</p><p>最后，基于上面的例子，再让问题复杂一点：在平面上添加一些随机噪声。当t=1时，如下图所示：</p><p><img src="http://img.blog.csdn.net/20170726170845858?" alt="这里写图片描述"></p><p>当t=6时：</p><p><img src="http://img.blog.csdn.net/20170726170944858?" alt="这里写图片描述"></p><p>当t=11时：</p><p><img src="http://img.blog.csdn.net/20170726171026145?" alt="这里写图片描述"></p><p>当t=16时：</p><p><img src="http://img.blog.csdn.net/20170726171107707?" alt="这里写图片描述"></p><p>当t=21时：</p><p><img src="http://img.blog.csdn.net/20170726171144679?" alt="这里写图片描述"></p><p>从上图中，我们发现21棵树的时候，随机noise的影响基本上能够修正和消除。这种bagging投票的机制能够保证较好的降噪性，从而得到比较稳定的结果。</p><p>经过以上三个例子，我们发现RF中，树的个数越多，模型越稳定越能表现得好。在实际应用中，应该尽可能选择更多的树。值得一提的是，RF的表现同时也与random seed有关，即随机的初始值也会影响RF的表现。</p><p><img src="http://img.blog.csdn.net/20170726172115021?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Random Forest算法模型。RF将bagging与decision tree结合起来，通过把众多的决策树组进行组合，构成森林的形式，利用投票机制让G表现最佳，分类模型更稳定。其中为了让decision tree的随机性更强一些，可以采用randomly projected subspaces操作，即将不同的features线性组合起来，从而进行各式各样的切割。同时，我们也介绍了可以使用OOB样本来进行self-validation，然后可以使用self-validation来对每个特征进行permutaion test，得到不同特征的重要性，从而进行feature selection。总的来说，RF算法能够得到比较平滑的边界，稳定性强，前提是有足够多的树。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170725105700489?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记9 -- Decision Tree</title>
    <link href="https://redstonewill.github.io/2018/03/18/26/"/>
    <id>https://redstonewill.github.io/2018/03/18/26/</id>
    <published>2018-03-18T06:06:39.000Z</published>
    <updated>2018-03-18T06:08:24.631Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170719082956412?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Adaptive Boosting。AdaBoost演算法通过调整每笔资料的权重，得到不同的hypotheses，然后将不同的hypothesis乘以不同的系数$\alpha$进行线性组合。这种演算法的优点是，即使底层的演算法g不是特别好（只要比乱选好点），经过多次迭代后算法模型会越来越好，起到了boost提升的效果。本节课将在此基础上介绍一种新的aggregation算法：决策树（Decision Tree）。</p><h3 id="Decision-Tree-Hypothesis"><a href="#Decision-Tree-Hypothesis" class="headerlink" title="Decision Tree Hypothesis"></a>Decision Tree Hypothesis</h3><p>从第7节课开始，我们就一直在介绍aggregation model。aggregation的核心就是将许多可供选择使用的比较好的hypothesis融合起来，利用集体的智慧组合成G，使其得到更好的机器学习预测模型。下面，我们先来看看已经介绍过的aggregation type有哪些。</p><p><img src="http://img.blog.csdn.net/20170719082956412?" alt="这里写图片描述"></p><p>aggregation type有三种：uniform，non-uniform，conditional。它有两种情况，一种是所有的g是已知的，即blending。对应的三种类型分别是voting/averaging，linear和stacking。另外一种情况是所有g未知，只能通过手上的资料重构g，即learning。其中uniform和non-uniform分别对应的是Bagging和AdaBoost算法，而conditional对应的就是我们本节课将要介绍的Decision Tree算法。</p><p>决策树（Decision Tree）模型是一种传统的算法，它的处理方式与人类思维十分相似。例如下面这个例子，对下班时间、约会情况、提交截止时间这些条件进行判断，从而决定是否要进行在线课程测试。如下图所示，整个流程类似一个树状结构。</p><p><img src="http://img.blog.csdn.net/20170719084744044?" alt="这里写图片描述"></p><p>图中每个条件和选择都决定了最终的结果，Y or N。蓝色的圆圈表示树的叶子，即最终的决定。</p><p>把这种树状结构对应到一个hypothesis G(x)中，G(x)的表达式为：</p><p>$$G(x)=\sum_{t=1}^Tq_t(x)\cdot g_t(x)$$</p><p>G(x)由许多$g_t(x)$组成，即aggregation的做法。每个$g_t(x)$就代表上图中的蓝色圆圈（树的叶子）。这里的$g_t(x)$是常数，因为是处理简单的classification问题。我们把这些$g_t(x)$称为base hypothesis。$q_t(x)$表示每个$g_t(x)$成立的条件，代表上图中橘色箭头的部分。不同的$g_t(x)$对应于不同的$q_t(x)$，即从树的根部到顶端叶子的路径不同。图中中的菱形代表每个简单的节点。所以，这些base hypothesis和conditions就构成了整个G(x)的形式，就像一棵树一样，从根部到顶端所有的叶子都安全映射到上述公式上去了。</p><p><img src="http://img.blog.csdn.net/20170719103654190?" alt="这里写图片描述"></p><p>决策树实际上就是在模仿人类做决策的过程。一直以来，决策树的应用十分广泛而且分类预测效果都很不错，而它在数学上的理论完备性不充分，倒也不必在意。</p><p>如果从另外一个方面来看决策树的形式，不同于上述G(x)的公式，我们可以利用条件分支的思想，将整体G(x)分成若干个$G_c(x)$，也就是把整个大树分成若干个小树，如下所示：</p><p>$$G(x)=\sum_{c=1}^C[b(x)=c]\cdot G_c(x)$$</p><p>上式中，G(x)表示完整的大树，即full-tree hypothesis，b(x)表示每个分支条件，即branching criteria，$G_c(x)$表示第c个分支下的子树，即sub-tree。这种结构被称为递归型的数据结构，即将大树分割成不同的小树，再将小树继续分割成更小的子树。所以，决策树可以分为两部分：root和sub-trees。</p><p><img src="http://img.blog.csdn.net/20170719103835724?" alt="这里写图片描述"></p><p>在详细推导决策树算法之前，我们先来看一看它的优点和缺点。首先，decision tree的优点有：</p><ul><li><p><strong>模型直观，便于理解，应用广泛</strong></p></li><li><p><strong>算法简单，容易实现</strong></p></li><li><p><strong>训练和预测时，效率较高</strong></p></li></ul><p>然而，decision tree也有相应的缺点：</p><ul><li><p><strong>缺少足够的理论支持</strong></p></li><li><p><strong>如何选择合适的树结构对初学者来说比较困惑</strong></p></li><li><p><strong>决策树代表性的演算法比较少</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170719155104812?" alt="这里写图片描述"></p><h3 id="Decision-Tree-Algorithm"><a href="#Decision-Tree-Algorithm" class="headerlink" title="Decision Tree Algorithm"></a>Decision Tree Algorithm</h3><p>我们可以用递归形式将decision tree表示出来，它的基本的算法可以写成：</p><p><img src="http://img.blog.csdn.net/20170720073120706?" alt="这里写图片描述"></p><p>这个Basic Decision Tree Algorithm的流程可以分成四个部分，首先学习设定划分不同分支的标准和条件是什么；接着将整体数据集D根据分支个数C和条件，划为不同分支下的子集Dc；然后对每个分支下的Dc进行训练，得到相应的机器学习模型Gc；最后将所有分支下的Gc合并到一起，组成大矩G(x)。但值得注意的是，这种递归的形式需要终止条件，否则程序将一直进行下去。当满足递归的终止条件之后，将会返回基本的hypothesis $g_t(x)$。</p><p><img src="http://img.blog.csdn.net/20170720074057776?" alt="这里写图片描述"></p><p>所以，决策树的基本演算法包含了四个选择：</p><ul><li><p><strong>分支个数（number of branches）</strong></p></li><li><p><strong>分支条件（branching criteria）</strong></p></li><li><p><strong>终止条件（termination criteria）</strong></p></li><li><p><strong>基本算法（base hypothesis）</strong></p></li></ul><p>下面我们来介绍一种常用的决策树模型算法，叫做Classification and Regression Tree(C&amp;RT)。C&amp;RT算法有两个简单的设定，首先，分支的个数C=2，即二叉树（binary tree）的数据结构；然后，每个分支最后的$g_t(x)$（数的叶子）是一个常数。按照最小化$E_{in}$的目标，对于binary/multiclass classification(0/1 error)问题，看正类和负类哪个更多，$g_t(x)$取所占比例最多的那一类$y_n$；对于regression(squared error)问题，$g_t(x)$则取所有$y_n$的平均值。</p><p><img src="http://img.blog.csdn.net/20170720081326313?" alt="这里写图片描述"></p><p>对于决策树的基本演算法流程，C&amp;RT还有一些简单的设定。首先，C&amp;RT分支个数C=2，一般采用上节课介绍过的decision stump的方法进行数据切割。也就是每次在一个维度上，只对一个特征feature将数据一分为二，左子树和右子树，分别代表不同的类别。然而，怎么切割才能让数据划分得最好呢（error最小）？C&amp;RT中使用纯净度purifying这个概念来选择最好的decision stump。purifying的核心思想就是每次切割都尽可能让左子树和右子树中同类样本占得比例最大或者$y_n$都很接近（regression），即错误率最小。比如说classifiacation问题中，如果左子树全是正样本，右子树全是负样本，那么它的纯净度就很大，说明该分支效果很好。</p><p><img src="http://img.blog.csdn.net/20170720083357302?" alt="这里写图片描述"></p><p>根据C&amp;RT中purifying的思想，我们得到选择合适的分支条件b(x)的表达式如上所示。最好的decision stump重点包含两个方面：一个是刚刚介绍的分支纯净度purifying，purifying越大越好，而这里使用purifying相反的概念impurity，则impurity越小越好；另外一个是左右分支纯净度所占的权重，权重大小由该分支的数据量决定，分支包含的样本个数越多，则所占权重越大，分支包含的样本个数越少，则所占权重越小。上式中的$|D_c\ with\ h|$代表了分支c所占的权重。这里b(x)类似于error function（这也是为什么使用impurity代替purifying的原因），选择最好的decision stump，让所有分支的不纯度最小化，使b(x)越小越好。</p><p>不纯度Impurity如何用函数的形式量化？一种简单的方法就是类比于$E_{in}$，看预测值与真实值的误差是多少。对于regression问题，它的impurity可表示为：</p><p>$$impurity(D)=\frac1N\sum_{n=1}^N(y_n-\overline{y})^2$$</p><p>其中，$\overline{y}$表示对应分支下所有$y_n$的均值。</p><p>对应classification问题，它的impurity可表示为：</p><p>$$impurity(D)=\frac1N\sum_{n=1}^N[y_n\neq y^*]$$</p><p>其中，$y^*$表示对应分支下所占比例最大的那一类。</p><p><img src="http://img.blog.csdn.net/20170720090259338?" alt="这里写图片描述"></p><p>以上这些impurity是基于原来的regression error和classification error直接推导的。进一步来看classification的impurity functions，如果某分支条件下，让其中一个分支纯度最大，那么就选择对应的decision stump，即得到的classification error为：</p><p>$$1-max_{1\leq k\leq K}\frac{\sum_{n=1}^N[y_n=k]}{N}$$</p><p>其中，K为分支个数。</p><p>上面这个式子只考虑纯度最大的那个分支，更好的做法是将所有分支的纯度都考虑并计算在内，用基尼指数（Gini index）表示：</p><p>$$1-\sum_{k=1}^K(\frac{\sum_{n=1}^N[y_n=k]}{N})^2$$</p><p>Gini index的优点是将所有的class在数据集中的分布状况和所占比例全都考虑了，这样让decision stump的选择更加准确。</p><p><img src="http://img.blog.csdn.net/20170720112908397?" alt="这里写图片描述"></p><p>对于决策树C&amp;RT算法，通常来说，上面介绍的各种impurity functions中，Gini index更适合求解classification问题，而regression error更适合求解regression问题。</p><p>C&amp;RT算法迭代终止条件有两种情况，第一种情况是当前各个分支下包含的所有样本$y_n$都是同类的，即不纯度impurity为0，表示该分支已经达到了最佳分类程度。第二种情况是该特征下所有的$x_n$相同，无法对其进行区分，表示没有decision stumps。遇到这两种情况，C&amp;RT算法就会停止迭代。</p><p><img src="http://img.blog.csdn.net/20170720135537933?" alt="这里写图片描述"></p><p>所以，C&amp;RT算法遇到迭代终止条件后就成为完全长成树（fully-grown tree）。它每次分支为二，是二叉树结构，采用purify来选择最佳的decision stump来划分，最终得到的叶子（$g_t(x)$）是常数。</p><h3 id="Decision-Tree-Heuristics-in-C-amp-RT"><a href="#Decision-Tree-Heuristics-in-C-amp-RT" class="headerlink" title="Decision Tree Heuristics in C&amp;RT"></a>Decision Tree Heuristics in C&amp;RT</h3><p>现在我们已经知道了C&amp;RT算法的基本流程：</p><p><img src="http://img.blog.csdn.net/20170720152355327?" alt="这里写图片描述"></p><p>可以看到C&amp;RT算法在处理binary classification和regression问题时非常简单实用，而且，处理muti-class classification问题也十分容易。</p><p>考虑这样一个问题，有N个样本，如果我们每次只取一个样本点作为分支，那么在经过N-1次分支之后，所有的样本点都能完全分类正确。最终每片叶子上只有一个样本，有N片叶子，即必然能保证$E_{in}=0$。这样看似是完美的分割，但是不可避免地造成VC Dimension无限大，造成模型复杂度增加，从而出现过拟合现象。为了避免overfit，我们需要在C&amp;RT算法中引入正则化，来控制整个模型的复杂度。</p><p>考虑到避免模型过于复杂的方法是减少叶子（$g_t(x)$）的数量，那么可以令regularizer就为决策树中叶子的总数，记为$\Omega(G)$。正则化的目的是尽可能减少$\Omega(G)$的值。这样，regularized decision tree的形式就可以表示成：</p><p>$$argmin_{(all\ possible\ G)}\ E_{in}(G)+\lambda\Omega(G)$$</p><p>我们把这种regularized decision tree称为pruned decision tree。pruned是修剪的意思，通过regularization来修剪决策树，去掉多余的叶子，更简洁化，从而达到避免过拟合的效果。</p><p>那么如何确定修剪多少叶子，修剪哪些叶子呢？假设由C&amp;RT算法得到一棵完全长成树（fully-grown tree），总共10片叶子。首先分别减去其中一片叶子，剩下9片，将这10种情况比较，取$E_{in}$最小的那个模型；然后再从9片叶子的模型中分别减去一片，剩下8片，将这9种情况比较，取$E_{in}$最小的那个模型。以此类推，继续修建叶子。这样，最终得到包含不同叶子的几种模型，将这几个使用regularized decision tree的error function来进行选择，确定包含几片叶子的模型误差最小，就选择该模型。另外，参数$\lambda$可以通过validation来确定最佳值。</p><p><img src="http://img.blog.csdn.net/20170721083658001?" alt="这里写图片描述"></p><p>我们一直讨论决策树上的叶子（features）都是numerical features，而实际应用中，决策树的特征值可能不是数字量，而是类别（categorical features）。对于numerical features，我们直接使用decision stump进行数值切割；而对于categorical features，我们仍然可以使用decision subset，对不同类别进行“左”和“右”，即是与不是（0和1）的划分。numerical features和categorical features的具体区别如下图所示：</p><p><img src="http://img.blog.csdn.net/20170721084601173?" alt="这里写图片描述"></p><p>在决策树中预测中，还会遇到一种问题，就是当某些特征缺失的时候，没有办法进行切割和分支选择。一种常用的方法就是surrogate branch，即寻找与该特征相似的替代feature。如何确定是相似的feature呢？做法是在决策树训练的时候，找出与该特征相似的feature，如果替代的feature与原feature切割的方式和结果是类似的，那么就表明二者是相似的，就把该替代的feature也存储下来。当预测时遇到原feature缺失的情况，就用替代feature进行分支判断和选择。</p><p><img src="http://img.blog.csdn.net/20170721090058551?" alt="这里写图片描述"></p><h3 id="Decision-Tree-in-Action"><a href="#Decision-Tree-in-Action" class="headerlink" title="Decision Tree in Action"></a>Decision Tree in Action</h3><p>最后我们来举个例子看看C&amp;RT算法究竟是如何进行计算的。例如下图二维平面上分布着许多正负样本，我们使用C&amp;RT算法来对其进行决策树的分类。</p><p><img src="http://img.blog.csdn.net/20170721220210716?" alt="这里写图片描述"></p><p>第一步：</p><p><img src="http://img.blog.csdn.net/20170721220326437?" alt="这里写图片描述"></p><p>第二步：</p><p><img src="http://img.blog.csdn.net/20170721220405953?" alt="这里写图片描述"></p><p>第三步：</p><p><img src="http://img.blog.csdn.net/20170721220449192?" alt="这里写图片描述"></p><p>第四步：</p><p><img src="http://img.blog.csdn.net/20170721220537242?" alt="这里写图片描述"></p><p>在进行第四步切割之后，我们发现每个分支都已经非常纯净了，没有办法继续往下切割。此时表明已经满足了迭代终止条件，这时候就可以回传base hypothesis，构成sub tree，然后每个sub tree再往上整合形成tree，最后形成我们需要的完全决策树。如果将边界添加上去，可得到下图：</p><p><img src="http://img.blog.csdn.net/20170721221314795?" alt="这里写图片描述"></p><p>得到C&amp;RT算法的切割方式之后，我们与AdaBoost-Stump算法进行比较：</p><p><img src="http://img.blog.csdn.net/20170721221458536?" alt="这里写图片描述"></p><p>我们之前就介绍过，AdaBoost-Stump算法的切割线是横跨整个平面的；而C&amp;RT算法的切割线是基于某个条件的，所以一般不会横跨整个平面。比较起来，虽然C&amp;RT和AdaBoost-Stump都采用decision stump方式进行切割，但是二者在细节上还是有所区别。</p><p>再看一个数据集分布比较复杂的例子，C&amp;RT和AdaBoost-Stump的切割方式对比效果如下图所示：</p><p><img src="http://img.blog.csdn.net/20170721222051208?" alt="这里写图片描述"></p><p>通常来说，由于C&amp;RT是基于条件进行切割的，所以C&amp;RT比AdaBoost-Stump分类切割更有效率。总结一下，C&amp;RT决策树有以下特点：</p><p><img src="http://img.blog.csdn.net/20170721222446843?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Decision Tree。首先将decision tree hypothesis对应到不同分支下的矩$g_t(x)$。然后再介绍决策树算法是如何通过递归的形式建立起来。接着详细研究了决策树C&amp;RT算法对应的数学模型和算法架构流程。最后通过一个实际的例子来演示决策树C&amp;RT算法是如何一步一步进行分类的。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170719082956412?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记8 -- Adaptive Boosting</title>
    <link href="https://redstonewill.github.io/2018/03/18/25/"/>
    <id>https://redstonewill.github.io/2018/03/18/25/</id>
    <published>2018-03-18T06:01:09.000Z</published>
    <updated>2018-03-18T06:02:40.916Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170713163950772?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要开始介绍Aggregation Models，目的是将不同的hypothesis得到的$g_t$集合起来，利用集体智慧得到更好的预测模型G。首先我们介绍了Blending，blending是将已存在的所有$g_t$结合起来，可以是uniformly，linearly，或者non-linearly组合形式。然后，我们讨论了在没有那么多$g_t$的情况下，使用bootstrap方式，从已有数据集中得到新的类似的数据集，从而得到不同的$g_t$。这种做法称为bagging。本节课将继续从这些概念出发，介绍一种新的演算法。</p><h3 id="Motivation-of-Boosting"><a href="#Motivation-of-Boosting" class="headerlink" title="Motivation of Boosting"></a>Motivation of Boosting</h3><p>我们先来看一个简单的识别苹果的例子，老师展示20张图片，让6岁孩子们通过观察，判断其中哪些图片的内容是苹果。从判断的过程中推导如何解决二元分类问题的方法。</p><p>显然这是一个监督式学习，20张图片包括它的标签都是已知的。首先，学生Michael回答说：所有的苹果应该是圆形的。根据Michael的判断，对应到20张图片中去，大部分苹果能被识别出来，但也有错误。其中错误包括有的苹果不是圆形，而且圆形的水果也不一定是苹果。如下图所示：</p><p><img src="http://img.blog.csdn.net/20170713163950772?" alt="这里写图片描述"></p><p>上图中蓝色区域的图片代表分类错误。显然，只用“苹果是圆形的”这一个条件不能保证分类效果很好。我们把蓝色区域（分类错误的图片）放大，分类正确的图片缩小，这样在接下来的分类中就会更加注重这些错误样本。</p><p>然后，学生Tina观察被放大的错误样本和上一轮被缩小的正确样本，回答说：苹果应该是红色的。根据Tina的判断，得到的结果如下图所示：</p><p><img src="http://img.blog.csdn.net/20170713171109291?" alt="这里写图片描述"></p><p>上图中蓝色区域的图片一样代表分类错误，即根据这个苹果是红色的条件，使得青苹果和草莓、西红柿都出现了判断错误。那么结果就是把这些分类错误的样本放大化，其它正确的样本缩小化。同样，这样在接下来的分类中就会更加注重这些错误样本。</p><p>接着，学生Joey经过观察又说：苹果也可能是绿色的。根据Joey的判断，得到的结果如下图所示：</p><p><img src="http://img.blog.csdn.net/20170713214123596?" alt="这里写图片描述"></p><p>上图中蓝色区域的图片一样代表分类错误，根据苹果是绿色的条件，使得图中蓝色区域都出现了判断错误。同样把这些分类错误的样本放大化，其它正确的样本缩小化，在下一轮判断继续对其修正。</p><p>后来，学生Jessica又发现：上面有梗的才是苹果。得到如下结果：</p><p><img src="http://img.blog.csdn.net/20170713214711978?" alt="这里写图片描述"></p><p>经过这几个同学的推论，苹果被定义为：圆的，红色的，也可能是绿色的，上面有梗。从一个一个的推导过程中，我们似乎得到一个较为准确的苹果的定义。虽然可能不是非常准确，但是要比单一的条件要好得多。也就是说把所有学生对苹果的定义融合起来，最终得到一个比较好的对苹果的总体定义。这种做法就是我们本节课将要讨论的演算法。这些学生代表的就是简单的hypotheses $g_t$，将所有$g_t$融合，得到很好的预测模型G。例如，二维平面上简单的hypotheses（水平线和垂直线），这些简单$g_t$最终组成的较复杂的分类线能够较好地将正负样本完全分开，即得到了好的预测模型。</p><p><img src="http://img.blog.csdn.net/20170713215718130?" alt="这里写图片描述"></p><p>所以，上个苹果的例子中，不同的学生代表不同的hypotheses $g_t$；最终得到的苹果总体定义就代表hypothesis G；而老师就代表演算法A，指导学生的注意力集中到关键的例子中（错误样本），从而得到更好的苹果定义。其中的数学原理，我们下一部分详细介绍。</p><p><img src="http://img.blog.csdn.net/20170713215800108?" alt="这里写图片描述"></p><h3 id="Diversity-by-Re-weighting"><a href="#Diversity-by-Re-weighting" class="headerlink" title="Diversity by Re-weighting"></a>Diversity by Re-weighting</h3><p>在介绍这个演算法之前，我们先来讲一下上节课就介绍过的bagging。Bagging的核心是bootstrapping，通过对原始数据集D不断进行bootstrap的抽样动作，得到与D类似的数据集$\hat{D}_t$，每组$\hat{D}_t$都能得到相应的$g_t$，从而进行aggregation的操作。现在，假如包含四个样本的D经过bootstrap，得到新的$\hat{D}_t$如下：</p><p><img src="http://img.blog.csdn.net/20170714080644583?" alt="这里写图片描述"></p><p>那么，对于新的$\hat{D}<em>t$，把它交给base algorithm，找出$E</em>{in}$最小时对应的$g_t$，如下图右边所示。</p><p>$$E_{in}^{0/1}(h)=\frac14\sum_{n=1}^4[y\neq h(x)]$$</p><p>由于$\hat{D}_t$完全是D经过bootstrap得到的，其中样本$(x_1,y_1)$出现2次，$(x_2,y_2)$出现1次，$(x_3,y_3)$出现0次，$(x_4,y_4)$出现1次。引入一个参数$u_i$来表示原D中第i个样本在$\hat{D}_t$中出现的次数，如下图左边所示。</p><p>$$E_{in}^u(h)=\frac14\sum_{n=1}^4u_n^{(t)}\cdot [y_n\neq h(x)]$$</p><p><img src="http://img.blog.csdn.net/20170714081506965?" alt="这里写图片描述"></p><p>参数u相当于是权重因子，当$\hat{D}_t$中第i个样本出现的次数越多的时候，那么对应的$u_i$越大，表示在error function中对该样本的惩罚越多。所以，从另外一个角度来看bagging，它其实就是通过bootstrap的方式，来得到这些$u_i$值，作为犯错样本的权重因子，再用base algorithn最小化包含$u_i$的error function，得到不同的$g_t$。这个error function被称为bootstrap-weighted error。</p><p>这种算法叫做Weightd Base Algorithm，目的就是最小化bootstrap-weighted error。</p><p><img src="http://img.blog.csdn.net/20170714083230109?" alt="这里写图片描述"></p><p>其实，这种weightd base algorithm我们之前就介绍过类似的算法形式。例如在soft-margin SVM中，我们引入允许犯错的项，同样可以将每个点的error乘以权重因子$u_n$。加上该项前的参数C，经过QP，最终得到$0\leq \alpha_n\leq Cu_n$，有别于之前介绍的$0\leq \alpha_n\leq C$。这里的$u_n$相当于每个犯错的样本的惩罚因子，并会反映到$\alpha_n$的范围限定上。</p><p>同样在logistic regression中，同样可以对每个犯错误的样本乘以相应的$u_n$，作为惩罚因子。$u_n$表示该错误点出现的次数，$u_n$越大，则对应的惩罚因子越大，则在最小化error时就应该更加重视这些点。</p><p><img src="http://img.blog.csdn.net/20170714085048224?" alt="这里写图片描述"></p><p>其实这种example-weighted learning，我们在机器学习基石课程第8次笔记中就介绍过class-weighted的思想。二者道理是相通的。</p><p>知道了u的概念后，我们知道不同的u组合经过base algorithm得到不同的$g_t$。那么如何选取u，使得到的$g_t$之间有很大的不同呢？之所以要让所有的$g_t$差别很大，是因为上节课aggregation中，我们介绍过$g_t$越不一样，其aggregation的效果越好，即每个人的意见越不相同，越能运用集体的智慧，得到好的预测模型。</p><p>为了得到不同的$g_t$，我们先来看看$g_t$和$g_{t+1}$是怎么得到的：</p><p><img src="http://img.blog.csdn.net/20170714131902089?" alt="这里写图片描述"></p><p>如上所示，$g_t$是由$u_n^{t}$得到的，$g_{t+1}$是由$u_n^{(t+1)}$得到的。如果$g_t$这个模型在使用$u_n^{(t+1)}$的时候得到的error很大，即预测效果非常不好，那就表示由$u_n^{(t+1)}$计算的$g_{t+1}$会与$g_t$有很大不同。而$g_{t+1}$与$g_t$差异性大正是我们希望看到的。</p><p>怎么做呢？方法是利用$g_t$在使用$u_n^{(t+1)}$的时候表现很差的条件，越差越好。如果在$g_t$作用下，$u_n^{(t+1)}$中的表现（即error）近似为0.5的时候，表明$g_t$对$u_n^{(t+1)}$的预测分类没有什么作用，就像抛硬币一样，是随机选择的。这样的做法就能最大限度地保证$g_{t+1}$会与$g_t$有较大的差异性。其数学表达式如下所示：</p><p><img src="http://img.blog.csdn.net/20170714134048908?" alt="这里写图片描述"></p><p>乍看上面这个式子，似乎不好求解。但是，我们对它做一些等价处理，其中分式中分子可以看成$g_t$作用下犯错误的点，而分母可以看成犯错的点和没有犯错误的点的集合，即所有样本点。其中犯错误的点和没有犯错误的点分别用橘色方块和绿色圆圈表示：</p><p><img src="http://img.blog.csdn.net/20170714135429196?" alt="这里写图片描述"></p><p>要让分式等于0.5，显然只要将犯错误的点和没有犯错误的点的数量调成一样就可以了。也就是说，在$g_t$作用下，让犯错的$u_n^{(t+1)}$数量和没有犯错的$u_n^{(t+1)}$数量一致就行（包含权重$u_n^{t+1}$）。一种简单的方法就是利用放大和缩小的思想（本节课开始引入识别苹果的例子中提到的放大图片和缩小图片就是这个目的），将犯错误的$u_n^{t}$和没有犯错误的$u_n^{t}$做相应的乘积操作，使得二者值变成相等。例如$u_n^{t}$ of incorrect为1126，$u_n^{t}$ of correct为6211，要让$u_n^{(t+1)}$中错误比例正好是0.5，可以这样做，对于incorrect $u_n^{(t+1)}$：</p><p>$$u_n^{(t+1)}\leftarrow u_n^{(t)}\cdot 6211$$</p><p>对于correct $u_n^{(t+1)}$：</p><p>$$u_n^{(t+1)}\leftarrow u_n^{(t)}\cdot 1126$$</p><p>或者利用犯错的比例来做，令weighted incorrect rate和weighted correct rate分别设为$\frac{1126}{7337}$和$\frac{6211}{7337}$。一般求解方式是令犯错率为$\epsilon_t$，在计算$u_n^{(t+1)}$的时候，$u_n^{t}$分别乘以$(1-\epsilon_t)$和$\epsilon_t$。</p><p><img src="http://img.blog.csdn.net/20170714141601750?" alt="这里写图片描述"></p><h3 id="Adaptive-Boosting-Algorithm"><a href="#Adaptive-Boosting-Algorithm" class="headerlink" title="Adaptive Boosting Algorithm"></a>Adaptive Boosting Algorithm</h3><p>上一部分，我们介绍了在计算$u_n^{(t+1)}$的时候，$u_n^{t}$分别乘以$(1-\epsilon_t)$和$\epsilon_t$。下面将构造一个新的尺度因子：</p><p>$$\diamond t=\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}$$</p><p>那么引入这个新的尺度因子之后，对于错误的$u_n^{t}$，将它乘以$\diamond t$；对于正确的$u_n^{t}$，将它除以$\diamond t$。这种操作跟之前介绍的分别乘以$(1-\epsilon_t)$和$\epsilon_t$的效果是一样的。之所以引入$\diamond t$是因为它告诉我们更多的物理意义。因为如果$\epsilon_t\leq\frac12$，得到$\diamond t\geq1$，那么接下来错误的$u_n^{t}$与$\diamond t$的乘积就相当于把错误点放大了，而正确的$u_n^{t}$与$\diamond t$的相除就相当于把正确点缩小了。这种scale up incorrect和scale down correct的做法与本节课开始介绍的学生识别苹果的例子中放大错误的图片和缩小正确的图片是一个原理，让学生能够将注意力更多地放在犯错误的点上。通过这种scaling-up incorrect的操作，能够保证得到不同于$g_t$的$g_{t+1}$。</p><p><img src="http://img.blog.csdn.net/20170714152321580?" alt="这里写图片描述"></p><p>值得注意的是上述的结论是建立在$\epsilon_t\leq\frac12$的基础上，如果$\epsilon_t\geq\frac12$，那么就做相反的推论即可。关于$\epsilon_t\geq\frac12$的情况，我们稍后会进行说明。</p><p>从这个概念出发，我们可以得到一个初步的演算法。其核心步骤是每次迭代时，利用$\diamond t=\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}$把$u_t$更新为$u_{t+1}$。具体迭代步骤如下：</p><p><img src="http://img.blog.csdn.net/20170717080641948?" alt="这里写图片描述"></p><p>但是，上述步骤还有两个问题没有解决，第一个问题是初始的$u^{(1)}$应为多少呢？一般来说，为了保证第一次$E_{in}$最小的话，设$u^{(1)}=\frac1N$即可。这样最开始的$g_1$就能由此推导。第二个问题，最终的G(x)应该怎么求？是将所有的g(t)合并uniform在一起吗？一般来说并不是这样直接uniform求解，因为$g_{t+1}$是通过$g_t$得来的，二者在$E_{in}$上的表现差别比较大。所以，一般是对所有的g(t)进行linear或者non-linear组合来得到G(t)。</p><p><img src="http://img.blog.csdn.net/20170717081850838?" alt="这里写图片描述"></p><p>接下来的内容，我们将对上面的第二个问题进行探讨，研究一种算法，将所有的g(t)进行linear组合。方法是计算$g(t)$的同时，就能计算得到其线性组合系数$\alpha_t$，即aggregate linearly on the fly。这种算法使最终求得$g_{t+1}$的时候，所有$g_t$的线性组合系数$\alpha$也求得了，不用再重新计算$\alpha$了。这种Linear Aggregation on the Fly算法流程为：</p><p><img src="http://img.blog.csdn.net/20170717083113667?" alt="这里写图片描述"></p><p>如何在每次迭代的时候计算$\alpha_t$呢？我们知道$\alpha_t$与$\epsilon_t$是相关的：$\epsilon_t$越小，对应的$\alpha_t$应该越大，$\epsilon_t$越大，对应的$\alpha_t$应该越小。又因为$\diamond t$与$\epsilon_t$是正相关的，所以，$\alpha_t$应该是$\diamond t$的单调函数。我们构造$\alpha_t$为：</p><p>$$\alpha_t=ln(\diamond t)$$</p><p>$\alpha_t$这样取值是有物理意义的，例如当$\epsilon_t=\frac12$时，error很大，跟掷骰子这样的随机过程没什么两样，此时对应的$\diamond t=1$，$\alpha_t=0$，即此$g_t$对G没有什么贡献，权重应该设为零。而当$\epsilon_t=0$时，没有error，表示该$g_t$预测非常准，此时对应的$\diamond t=\infty$，$\alpha_t=\infty$，即此$g_t$对G贡献非常大，权重应该设为无穷大。</p><p><img src="http://img.blog.csdn.net/20170717085137932?" alt="这里写图片描述"></p><p>这种算法被称为Adaptive Boosting。它由三部分构成：base learning algorithm A，re-weighting factor $\diamond t$和linear aggregation $\alpha_t$。这三部分分别对应于我们在本节课开始介绍的例子中的Student，Teacher和Class。</p><p><img src="http://img.blog.csdn.net/20170717085756381?" alt="这里写图片描述"></p><p>综上所述，完整的adaptive boosting（AdaBoost）Algorithm流程如下：</p><p><img src="http://img.blog.csdn.net/20170717112519198?" alt="这里写图片描述"></p><p>从我们之前介绍过的VC bound角度来看，AdaBoost算法理论上满足：</p><p><img src="http://img.blog.csdn.net/20170717112851795?" alt="这里写图片描述"></p><p>上式中，$E_{out}(G)$的上界由两部分组成，一项是$E_{in}(G)$，另一项是模型复杂度O(*)。模型复杂度中$d_{vc}(H)$是$g_t$的VC Dimension，T是迭代次数，可以证明G的$d_{vc}$服从$O(d_{vc}(H)\cdot Tlog\ T)$。</p><p>对这个VC bound中的第一项$E_{in}(G)$来说，有一个很好的性质：如果满足$\epsilon_t\leq \epsilon&lt;\frac12$，则经过$T=O(log\ N)$次迭代之后，$E_{in}(G)$能减小到等于零的程度。而当N很大的时候，其中第二项也能变得很小。因为这两项都能变得很小，那么整个$E_{out}(G)$就能被限定在一个有限的上界中。</p><p>其实，这种性质也正是AdaBoost算法的精髓所在。只要每次的$\epsilon_t\leq \epsilon&lt;\frac12$，即所选择的矩g比乱猜的表现好一点点，那么经过每次迭代之后，矩g的表现都会比原来更好一些，逐渐变强，最终得到$E_{in}=0$且$E_{out}$很小。</p><p><img src="http://img.blog.csdn.net/20170717132338143?" alt="这里写图片描述"></p><h3 id="Adaptive-Boosting-in-Action"><a href="#Adaptive-Boosting-in-Action" class="headerlink" title="Adaptive Boosting in Action"></a>Adaptive Boosting in Action</h3><p>上一小节我们已经介绍了选择一个“弱弱”的算法A（$\epsilon_t\leq \epsilon&lt;\frac12$，比乱猜好就行），就能经过多次迭代得到$E_{in}=0$。我们称这种形式为decision stump模型。下面介绍一个例子，来看看AdaBoost是如何使用decision stump解决实际问题的。</p><p>如下图所示，二维平面上分布一些正负样本点，利用decision stump来做切割。</p><p><img src="http://img.blog.csdn.net/20170717134058765?" alt="这里写图片描述"></p><p>第一步：</p><p><img src="http://img.blog.csdn.net/20170717134139058?" alt="这里写图片描述"></p><p>第二步：</p><p><img src="http://img.blog.csdn.net/20170717134354783?" alt="这里写图片描述"></p><p>第三步：</p><p><img src="http://img.blog.csdn.net/20170717134445972?" alt="这里写图片描述"></p><p>第四步：</p><p><img src="http://img.blog.csdn.net/20170717134548872?" alt="这里写图片描述"></p><p>第五步：</p><p><img src="http://img.blog.csdn.net/20170717134642556?" alt="这里写图片描述"></p><p>可以看到，经过5次迭代之后，所有的正负点已经被完全分开了，则最终得到的分类线为：</p><p><img src="http://img.blog.csdn.net/20170717134743082?" alt="这里写图片描述"></p><p>另外一个例子，对于一个相对比较复杂的数据集，如下图所示。它的分界线从视觉上看应该是一个sin波的形式。如果我们再使用AdaBoost算法，通过decision stump来做切割。在迭代切割100次后，得到的分界线如下所示。</p><p><img src="http://img.blog.csdn.net/20170717135425498?" alt="这里写图片描述"></p><p>可以看出，AdaBoost-Stump这种非线性模型得到的分界线对正负样本有较好的分离效果。</p><p>课程中还介绍了一个AdaBoost-Stump在人脸识别方面的应用：</p><p><img src="http://img.blog.csdn.net/20170717140200102?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Adaptive Boosting。首先通过讲一个老师教小学生识别苹果的例子，来引入Boosting的思想，即把许多“弱弱”的hypotheses合并起来，变成很强的预测模型。然后重点介绍这种算法如何实现，关键在于每次迭代时，给予样本不同的系数u，宗旨是放大错误样本，缩小正确样本，得到不同的小矩g。并且在每次迭代时根据错误$\epsilon$值的大小，给予不同$g_t$不同的权重。最终由不同的$g_t$进行组合得到整体的预测模型G。实际证明，Adaptive Boosting能够得到有效的预测模型。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170713163950772?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记7 -- Blending and Bagging</title>
    <link href="https://redstonewill.github.io/2018/03/18/24/"/>
    <id>https://redstonewill.github.io/2018/03/18/24/</id>
    <published>2018-03-18T05:58:22.000Z</published>
    <updated>2018-03-18T06:00:20.499Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170711084001106?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Support Vector Regression，将kernel model引入到regression中。首先，通过将ridge regression和representer theorem结合起来，得到kernel ridge regression。但是其解是dense的，即不部分不为零。为了得到sparse解，我们将regularized tube error和Lagrange dual结合起来，利用SVM dual的推导方法，得到support vector regression的sparse解。本系列1-6节课主要介绍Kernel Models及其应用，从本节课开始，讲介绍Aggregation Models，即如何将不同的hypothesis和features结合起来，让模型更好。本节课将介绍其中的两个方法，一个是Blending，一个是Bagging。</p><h3 id="Motivation-of-Aggregation"><a href="#Motivation-of-Aggregation" class="headerlink" title="Motivation of Aggregation"></a>Motivation of Aggregation</h3><p>首先举个例子来说明为什么要使用Aggregation。假如你有T个朋友，每个朋友向你预测推荐明天某支股票会涨还是会跌，对应的建议分别是$g_1,g_2,\cdots,g_T$，那么你该选择哪个朋友的建议呢？即最终选择对股票预测的$g_t(x)$是什么样的？</p><p>第一种方法是从T个朋友中选择一个最受信任，对股票预测能力最强的人，直接听从他的建议就好。这是一种普遍的做法，对应的就是validation思想，即选择犯错误最小的模型。第二种方法，如果每个朋友在股票预测方面都是比较厉害的，都有各自的专长，那么就同时考虑T个朋友的建议，将所有结果做个投票，一人一票，最终决定出对该支股票的预测。这种方法对应的是uniformly思想。第三种方法，如果每个朋友水平不一，有的比较厉害，投票比重应该更大一些，有的比较差，投票比重应该更小一些。那么，仍然对T个朋友进行投票，只是每个人的投票权重不同。这种方法对应的是non-uniformly的思想。第四种方法与第三种方法类似，但是权重不是固定的，根据不同的条件，给予不同的权重。比如如果是传统行业的股票，那么给这方面比较厉害的朋友较高的投票权重，如果是服务行业，那么就给这方面比较厉害的朋友较高的投票权重。以上所述的这四种方法都是将不同人不同意见融合起来的方式，接下来我们就要讨论如何将这些做法对应到机器学习中去。Aggregation的思想与这个例子是类似的，即把多个hypothesis结合起来，得到更好的预测效果。</p><p><img src="http://img.blog.csdn.net/20170711084001106?" alt="这里写图片描述"></p><p>将刚刚举的例子的各种方法用数学化的语言和机器学习符号归纳表示出来，其中G(x)表示最终选择的模型。</p><p>第一种方法对应的模型：</p><p>$$G(x)=g_{t_*}(x)\ with\ t_*=argmin_{t\in{1,2,\cdots,T}}\ E_{val}(g_t^-)$$</p><p>第二种方法对应的模型：</p><p>$$G(x)=sign(\sum_{t=1}^T1\cdot g_t(x))$$</p><p>第三种方法对应的模型：</p><p>$$G(x)=sign(\sum_{t=1}^T\alpha_t\cdot g_t(x))\ with\ \alpha_t\geq0$$</p><p>第四种方法对应的模型：</p><p>$$G(x)=sign(\sum_{t=1}^Tq_t(x)\cdot g_t(x))\ with\ q_t(x)\geq0$$</p><p><img src="http://img.blog.csdn.net/20170711090151610?" alt="这里写图片描述"></p><p>注意这里提到的第一种方法是通过验证集来选择最佳模型，不能使用$E_{in}(g_t)$来代替$E_{val}(g_t^-)$。经过Validation，选择最小的$E_{val}$，保证$E_{out}$最小，从而将对应的模型作为最佳的选择。</p><p>但是第一种方法只是从众多可能的hypothesis中选择最好的模型，并不能发挥集体的智慧。而Aggregation的思想是博采众长，将可能的hypothesis优势集合起来，将集体智慧融合起来，使预测模型达到更好的效果。</p><p>下面先来看一个例子，通过这个例子说明为什么Aggregation能work得更好。</p><p><img src="http://img.blog.csdn.net/20170711133648721?" alt="这里写图片描述"></p><p>如上图所示，平面上分布着一些待分类的点。如果要求只能用一条水平的线或者垂直的线进行分类，那不论怎么选取直线，都达不到最佳的分类效果。这实际上就是上面介绍的第一种方法：validation。但是，如果可以使用集体智慧，比如一条水平线和两条垂直线组合而成的图中折线形式，就可以将所有的点完全分开，得到了最优化的预测模型。</p><p>这个例子表明，通过将不同的hypotheses均匀地结合起来，得到了比单一hypothesis更好的预测模型。这就是aggregation的优势所在，它提高了预测模型的power，起到了特征转换（feature transform）的效果。</p><p><img src="http://img.blog.csdn.net/20170711135405460?" alt="这里写图片描述"></p><p>我们再从另外一方面来看，同样是平面上分布着一些待分类的点，使用PLA算法，可以得到很多满足条件的分类线，如下图所示：</p><p><img src="http://img.blog.csdn.net/20170711140155940?" alt="这里写图片描述"></p><p>这无数条PLA选择出来的直线对应的hypothesis都是满足分类要求的。但是我们最想得到的分类直线是中间那条距离所有点都比较远的黑色直线，这与之前SVM目标是一致的。如果我们将所有可能的hypothesis结合起来，以投票的方式进行组合选择，最终会发现投票得到的分类线就是中间和黑色那条。这从哲学的角度来说，就是对各种效果较好的可能性进行组合，得到的结果一般是中庸的、最合适的，即对应图中那条黑色直线。所以，aggregation也起到了正则化（regularization）的效果，让预测模型更具有代表性。</p><p><img src="http://img.blog.csdn.net/20170711141311004?" alt="这里写图片描述"></p><p>基于以上的两个例子，我们得到了aggregation的两个优势：feature transform和regularization。我们之前在机器学习基石课程中就介绍过，feature transform和regularization是对立的，还把它们分别比作踩油门和踩刹车。如果进行feature transform，那么regularization的效果通常很差，反之亦然。也就是说，单一模型通常只能倾向于feature transform和regularization之一，在两者之间做个权衡。但是aggregation却能将feature transform和regularization各自的优势结合起来，好比把油门和刹车都控制得很好，从而得到不错的预测模型。</p><h3 id="Uniform-Blending"><a href="#Uniform-Blending" class="headerlink" title="Uniform Blending"></a>Uniform Blending</h3><p>那对于我们已经选择的性能较好的一些矩$g_t$，如何将它们进行整合、合并，来得到最佳的预测模型呢？这个过程称为blending。</p><p>最常用的一种方法是uniform blending，应用于classification分类问题，做法是将每一个可能的矩赋予权重1，进行投票，得到的G(x)表示为：</p><p>$$g(x)=sign(\sum_{t=1}^T1\cdot g_t(x)$$</p><p>这种方法对应三种情况：第一种情况是每个候选的矩$g_t$都完全一样，这跟选其中任意一个$g_t$效果相同；第二种情况是每个候选的矩$g_t$都有一些差别，这是最常遇到的，大都可以通过投票的形式使多数意见修正少数意见，从而得到很好的模型，如下图所示；第三种情况是多分类问题，选择投票数最多的那一类即可。</p><p><img src="http://img.blog.csdn.net/20170711211033149?" alt="这里写图片描述"></p><p>如果是regression回归问题，uniform blending的做法很简单，就是将所有的矩$g_t$求平均值：</p><p>$$G(x)=\frac1T\sum_{t=1}^Tg_t(x)$$</p><p>uniform blending for regression对应两种情况：第一种情况是每个候选的矩$g_t$都完全一样，这跟选其中任意一个$g_t$效果相同；第二种情况是每个候选的矩$g_t$都有一些差别，有的$g_t&gt;f(x)$，有的$g_t&lt;f(x)$，此时求平均值的操作可能会消去这种大于和小于的影响，从而得到更好的回归模型。因此，从直觉上来说，求平均值的操作更加稳定，更加准确。</p><p><img src="http://img.blog.csdn.net/20170711212419704?" alt="这里写图片描述"></p><p>对于uniform blending，一般要求每个候选的矩$g_t$都有一些差别。这样，通过不同矩$g_t$的组合和集体智慧，都能得到比单一矩$g_t$更好的模型。</p><p>刚才我们提到了uniform blending for regression中，计算$g_t$的平均值可能比单一的$g_t$更稳定，更准确。下面进行简单的推导和证明。</p><p><img src="http://img.blog.csdn.net/20170711214143674?" alt="这里写图片描述"></p><p>推导过程中注意$G(t)=avg(g_t)$。经过推导，我们发现$avg((g_t(x)-f(x))^2)$与$(G-f)^2$之间差了$avg((g_t-G)^2)$项，且是大于零的。从而得到$g_t$与目标函数f的差值要比G与f的差值大。</p><p>刚才是对单一的x进行证明，如果从期望角度，对整个x分布进行上述公式的整理，得到：</p><p><img src="http://img.blog.csdn.net/20170711215426911?" alt="这里写图片描述"></p><p>从结果上来看，$avg(E_{out}(g_t))\geq E_{out}(G)$，从而证明了从平均上来说，计算$g_t$的平均值G(t)要比单一的$g_t$更接近目标函数f，regression效果更好。</p><p>我们已经知道G是数目为T的$g_t$的平均值。令包含N个数据的样本D独立同分布于$P^N$，每次从新的$D_t$中学习得到新的$g_t$，在对$g_t$求平均得到G，当做无限多次，即T趋向于无穷大的时候：</p><p>$$\overline{g}=lim_{T\rightarrow \infty}\ G=lim_{T\rightarrow \infty}\ \frac1T\sum_{t=1}^Tg_t=\epsilon_DA(D)$$</p><p><img src="http://img.blog.csdn.net/20170712080425995?" alt="这里写图片描述"></p><p>当T趋于无穷大的时候，$G=\overline{g}$，则有如下等式成立：</p><p><img src="http://img.blog.csdn.net/20170712080756020?" alt="这里写图片描述"></p><p>上述等式中左边表示演算法误差的期望值；右边第二项表示不同$g_t$的平均误差共识，用偏差bias表示；右边第一项表示不同$g_t$与共识的差距是多少，反映$g_t$之间的偏差，用方差variance表示。也就是说，一个演算法的平均表现可以被拆成两项，一个是所有$g_t$的共识，一个是不同$g_t$之间的差距是多少，即bias和variance。而uniform blending的操作时求平均的过程，这样就削减弱化了上式第一项variance的值，从而演算法的表现就更好了，能得到更加稳定的表现。</p><h3 id="Linear-and-Any-Blending"><a href="#Linear-and-Any-Blending" class="headerlink" title="Linear and Any Blending"></a>Linear and Any Blending</h3><p>上一部分讲的是uniform blending，即每个$g_t$所占的权重都是1，求平均的思想。下面我们将介绍linear blending，每个$g_t$赋予的权重$\alpha_t$并不相同，其中$\alpha_t\geq0$。我们最终得到的预测结果等于所有$g_t$的线性组合。</p><p><img src="http://img.blog.csdn.net/20170712082617337?" alt="这里写图片描述"></p><p>如何确定$\alpha_t$的值，方法是利用误差最小化的思想，找出最佳的$\alpha_t$，使$E_{in}(\alpha)$取最小值。例如对于linear blending for regression，$E_{in}(\alpha)$可以写成下图左边形式，其中$\alpha_t$是带求解参数，$g_t(x_n)$是每个矩得到的预测值，由已知矩得到。这种形式很类似于下图右边的形式，即加上特征转换$\phi_i(x_n)$的linear regression模型。两个式子中的$g_t(x_n)$对应于$\phi_i(x_n)$，唯一不同的就是linear blending for regression中$\alpha_t\geq0$，而linear regression中$w_i$没有限制。</p><p><img src="http://img.blog.csdn.net/20170712085402079?" alt="这里写图片描述"></p><p>这种求解$\alpha_t$的方法就像是使用two-level learning，类似于我们之前介绍的probabilistic SVM。这里，我们先计算$g_t(x_n)$，再进行linear regression得到$\alpha_t$值。总的来说，linear blending由三个部分组成：LinModel，hypotheses as transform，constraints。其中值得注意的一点就是，计算过程中可以把$g_t$当成feature transform，求解过程就跟之前没有什么不同，除了$\alpha\geq0$的条件限制。</p><p><img src="http://img.blog.csdn.net/20170712134910640?" alt="这里写图片描述"></p><p>我们来看一下linear blending中的constraint $\alpha_t\geq0$。这个条件是否一定要成立呢？如果$\alpha_t&lt;0$，会带来什么后果呢？其实$\alpha_t&lt;0$并不会影响分类效果，只需要将正类看成负类，负类当成正类即可。例如分类问题，判断该点是正类对应的$\alpha_t&lt;0$，则它就表示该点是负类，且对应的$-\alpha_t&gt;0$。如果我们说这个样本是正类的概率是-99%，意思也就是说该样本是负类的概率是99%。$\alpha_t\geq0$和$\alpha_t&lt;0$的效果是等同的一致的。所以，我们可以把$\alpha_t\geq0$这个条件舍去，这样linear blending就可以使用常规方法求解。</p><p><img src="http://img.blog.csdn.net/20170712141217975?" alt="这里写图片描述"></p><p>Linear Blending中使用的$g_t$是通过模型选择而得到的，利用validation，从$D_{train}$中得到$g_1^-,g_2^-,\cdots,g_T^-$。然后将$D_{train}$中每个数据点经过各个矩的计算得到的值，代入到相应的linear blending计算公式中，迭代优化得到对应$\alpha$值。最终，再利用所有样本数据，得到新的$g_t$代替$g_t^-$，则G(t)就是$g_t$的线性组合而不是$g_t^-$，系数是$\alpha_t$。</p><p><img src="http://img.blog.csdn.net/20170712144039981?" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20170712144146977?" alt="这里写图片描述"></p><p>除了linear blending之外，还可以使用任意形式的blending。linear blending中，G(t)是g(t)的线性组合；any blending中，G(t)可以是g(t)的任何函数形式（非线性）。这种形式的blending也叫做Stacking。any blending的优点是模型复杂度提高，更容易获得更好的预测模型；缺点是复杂模型也容易带来过拟合的危险。所以，在使用any blending的过程中要时刻注意避免过拟合发生，通过采用regularization的方法，让模型具有更好的泛化能力。</p><h3 id="Bagging-Bootstrap-Aggregation"><a href="#Bagging-Bootstrap-Aggregation" class="headerlink" title="Bagging(Bootstrap Aggregation)"></a>Bagging(Bootstrap Aggregation)</h3><p>总结一些上面讲的内容，blending的做法就是将已经得到的矩$g_t$进行aggregate的操作。具体的aggregation形式包括：uniform，non-uniforn和conditional。</p><p><img src="http://img.blog.csdn.net/20170712150343056?" alt="这里写图片描述"></p><p>现在考虑一个问题：如何得到不同的$g_t$呢？可以选取不同模型H；可以设置不同的参数，例如$\eta$、迭代次数n等；可以由算法的随机性得到，例如PLA、随机种子等；可以选择不同的数据样本等。这些方法都可能得到不同的$g_t$。</p><p><img src="http://img.blog.csdn.net/20170712151234676?" alt="这里写图片描述"></p><p>那如何利用已有的一份数据集来构造出不同的$g_t$呢？首先，我们回顾一下之前介绍的bias-variance，即一个演算法的平均表现可以被拆成两项，一个是所有$g_t$的共识（bias），一个是不同$g_t$之间的差距是多少（variance）。其中每个$g_t$都是需要新的数据集的。只有一份数据集的情况下，如何构造新的数据集？</p><p><img src="http://img.blog.csdn.net/20170712151854730?" alt="这里写图片描述"></p><p>其中，$\overline{g}$是在矩个数T趋向于无穷大的时候，不同的$g_t$计算平均得到的值。这里我们为了得到$\overline{g}$，做两个近似条件：</p><ul><li><p><strong>有限的T；</strong></p></li><li><p><strong>由已有数据集D构造出$D_t~P^N$，独立同分布</strong></p></li></ul><p>第一个条件没有问题，第二个近似条件的做法就是bootstrapping。bootstrapping是统计学的一个工具，思想就是从已有数据集D中模拟出其他类似的样本$D_t$。</p><p><img src="http://img.blog.csdn.net/20170712152918350?" alt="这里写图片描述"></p><p>bootstrapping的做法是，假设有N笔资料，先从中选出一个样本，再放回去，再选择一个样本，再放回去，共重复N次。这样我们就得到了一个新的N笔资料，这个新的$\breve{D_t}$中可能包含原D里的重复样本点，也可能没有原D里的某些样本，$\breve{D_t}$与D类似但又不完全相同。值得一提的是，抽取-放回的操作不一定非要是N，次数可以任意设定。例如原始样本有10000个，我们可以抽取-放回3000次，得到包含3000个样本的$\breve{D_t}$也是完全可以的。利用bootstrap进行aggragation的操作就被称为bagging。</p><p><img src="http://img.blog.csdn.net/20170712154142461?" alt="这里写图片描述"></p><p>下面举个实际中Bagging Pocket算法的例子。如下图所示，先通过bootstrapping得到25个不同样本集，再使用pocket算法得到25个不同的$g_t$，每个pocket算法迭代1000次。最后，再利用blending，将所有的$g_t$融合起来，得到最终的分类线，如图中黑线所示。可以看出，虽然bootstrapping会得到差别很大的分类线（灰线），但是经过blending后，得到的分类线效果是不错的，则bagging通常能得到最佳的分类模型。</p><p><img src="http://img.blog.csdn.net/20170712155019738?" alt="这里写图片描述"></p><p>值得注意的是，只有当演算法对数据样本分布比较敏感的情况下，才有比较好的表现。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了blending和bagging的方法，它们都属于aggregation，即将不同的$g_t$合并起来，利用集体的智慧得到更加优化的G(t)。Blending通常分为三种情况：Uniform Blending，Linear Blending和Any Blending。其中，uniform blending采样最简单的“一人一票”的方法，linear blending和any blending都采用标准的two-level learning方法，类似于特征转换的操作，来得到不同$g_t$的线性组合或非线性组合。最后，我们介绍了如何利用bagging（bootstrap aggregation），从已有数据集D中模拟出其他类似的样本$D_t$，而得到不同的$g_t$，再合并起来，优化预测模型。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170711084001106?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记6 -- Support Vector Regression</title>
    <link href="https://redstonewill.github.io/2018/03/18/23/"/>
    <id>https://redstonewill.github.io/2018/03/18/23/</id>
    <published>2018-03-18T03:23:36.000Z</published>
    <updated>2018-03-18T03:44:31.196Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170708142619499?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Kernel Logistic Regression，讨论如何把SVM的技巧应用在soft-binary classification上。方法是使用2-level learning，先利用SVM得到参数b和w，然后再用通用的logistic regression优化算法，通过迭代优化，对参数b和w进行微调，得到最佳解。然后，也介绍了可以通过Representer Theorem，在z空间中，引入SVM的kernel技巧，直接对logistic regression进行求解。本节课将延伸上节课的内容，讨论如何将SVM的kernel技巧应用到regression问题上。</p><h3 id="Kernel-Ridge-Regression"><a href="#Kernel-Ridge-Regression" class="headerlink" title="Kernel Ridge Regression"></a>Kernel Ridge Regression</h3><p>首先回顾一下上节课介绍的Representer Theorem，对于任何包含正则项的L2-regularized linear model，它的最佳化解w都可以写成是z的线性组合形式，因此，也就能引入kernel技巧，将模型kernelized化。</p><p><img src="http://img.blog.csdn.net/20170708142619499?" alt="这里写图片描述"></p><p>那么如何将regression模型变成kernel的形式呢？我们之前介绍的linear/ridge regression最常用的错误估计是squared error，即$err(y,w^Tz)=(y-w^Tz)^2$。这种形式对应的解是analytic solution，即可以使用线性最小二乘法，通过向量运算，直接得到最优化解。那么接下来我们就要研究如何将kernel引入到ridge regression中去，得到与之对应的analytic solution。</p><p>我们先把Kernel Ridge Regression问题写下来：</p><p><img src="http://img.blog.csdn.net/20170708143552496?" alt="这里写图片描述"></p><p>其中，最佳解$w_<em>$必然是z的线性组合。那么我们就把$w_</em>=\sum_{n=1}^N\beta_nz_n$代入到ridge regression中，将z的内积用kernel替换，把求$w_*$的问题转化成求$\beta_n$的问题，得到：</p><p><img src="http://img.blog.csdn.net/20170708144926721?" alt="这里写图片描述"></p><p>ridge regression可以写成矩阵的形式，其中第一项可以看成是$\beta_n$的正则项，而第二项可以看成是$\beta_n$的error function。这样，我们的目的就是求解该式最小化对应的$\beta_n$值，这样就解决了kernel ridge regression问题。</p><p>求解$\beta_n$的问题可以写成如下形式：</p><p><img src="http://img.blog.csdn.net/20170708145512253?" alt="这里写图片描述"></p><p>$E_{aug}(\beta)$是关于$\beta$的二次多项式，要对$E_{aug}(\beta)$求最小化解，这种凸二次最优化问题，只需要先计算其梯度，再令梯度为零即可。$\nabla E_{aug}(\beta)$已经在上式中写出来了，令其等于零，即可得到一种可能的$\beta$的解析解为：</p><p>$$\beta=(\lambda I+K)^{-1}y$$</p><p>这里需要关心的问题是$(\lambda I+K)$的逆矩阵是否存在？答案是肯定的。因为我们之前介绍过，核函数K满足Mercer’s condition，它是半正定的，而且$\lambda&gt;0$，所以$(\lambda I+K)$一定是可逆的。从计算的时间复杂上来说，由于$(\lambda I+K)$是NxN大小的，所以时间复杂度是$O(N^3)$。还有一点，$\nabla E_{aug}(\beta)$是由两项乘积构成的，另一项是K，会不会出现K=0的情况呢？其实，由于核函数K表征的是z空间的内积，一般而言，除非两个向量互相垂直，内积才为零，否则，一般情况下K不等于零。这个原因也决定了$(\lambda I+K)$是dense matrix，即$\beta$的解大部分都是非零值。这个性质，我们之后还会说明。</p><p>所以说，我们可以通过kernel来解决non-linear regression的问题。下面比较一下linear ridge regression和kernel ridge regression的关系。</p><p><img src="http://img.blog.csdn.net/20170708155331930?" alt="这里写图片描述"></p><p>如上图所示，左边是linear ridge regression，是一条直线；右边是kernel ridge regression，是一条曲线。大致比较一下，右边的曲线拟合的效果更好一些。这两种regression有什么样的优点和缺点呢？对于linear ridge regression来说，它是线性模型，只能拟合直线；其次，它的训练复杂度是$O(d^3+d^2N)$，预测的复杂度是$O(d)$，如果N比d大很多时，这种模型就更有效率。而对于kernel ridge regression来说，它转换到z空间，使用kernel技巧，得到的是非线性模型，所以更加灵活；其次，它的训练复杂度是$O(N^3)$，预测的复杂度是$O(N)$，均只与N有关。当N很大的时候，计算量就很大，所以，kernel ridge regression适合N不是很大的场合。比较下来，可以说linear和kernel实际上是效率（efficiency）和灵活（flexibility）之间的权衡。</p><p><img src="http://img.blog.csdn.net/20170708160254603?" alt="这里写图片描述"></p><h3 id="Support-Vector-Regression-Primal"><a href="#Support-Vector-Regression-Primal" class="headerlink" title="Support Vector Regression Primal"></a>Support Vector Regression Primal</h3><p>我们在机器学习基石课程中介绍过linear regression可以用来做classification，那么上一部分介绍的kernel ridge regression同样可以来做classification。我们把kernel ridge regression应用在classification上取个新的名字，叫做least-squares SVM（LSSVM）。</p><p>先来看一下对于某个问题，soft-margin Gaussian SVM和Gaussian LSSVM结果有哪些不一样的地方。</p><p><img src="http://img.blog.csdn.net/20170708165152565?" alt="这里写图片描述"></p><p>如上图所示，如果只看分类边界的话，soft-margin Gaussian SVM和Gaussian LSSVM差别不是很大，即的到的分类线是几乎相同的。但是如果看Support Vector的话（图中方框标注的点），左边soft-margin Gaussian SVM的SV不多，而右边Gaussian LSSVM中基本上每个点都是SV。这是因为soft-margin Gaussian SVM中的$\alpha_n$大部分是等于零，$\alpha_n&gt;0$的点只占少数，所以SV少。而对于LSSVM，我们上一部分介绍了$\beta$的解大部分都是非零值，所以对应的每个点基本上都是SV。SV太多会带来一个问题，就是做预测的矩$g(x)=\sum_{n=1}^N\beta_nK(x_n,x)$，如果$\beta_n$非零值较多，那么g的计算量也比较大，降低计算速度。基于这个原因，soft-margin Gaussian SVM更有优势。</p><p><img src="http://img.blog.csdn.net/20170708171711889?" alt="这里写图片描述"></p><p>那么，针对LSSVM中dense $\beta$的缺点，我们能不能使用一些方法来的得到sparse $\beta$，使得SV不会太多，从而得到和soft-margin SVM同样的分类效果呢？下面我们将尝试解决这个问题。</p><p>方法是引入一个叫做Tube Regression的做法，即在分类线上下分别划定一个区域（中立区），如果数据点分布在这个区域内，则不算分类错误，只有误分在中立区域之外的地方才算error。</p><p><img src="http://img.blog.csdn.net/20170708174337480?" alt="这里写图片描述"></p><p>假定中立区的宽度为$2\epsilon$，$\epsilon&gt;0$,那么error measure就可以写成：$err(y,s)=max(0,|s-y|-\epsilon)$，对应上图中红色标注的距离。</p><p><img src="http://img.blog.csdn.net/20170708174952966?" alt="这里写图片描述"></p><p>通常把这个error叫做$\epsilon$-insensitive error，这种max的形式跟我们上节课中介绍的hinge error measure形式其实是类似的。所以，我们接下来要做的事情就是将L2-regularized tube regression做类似于soft-margin SVM的推导，从而得到sparse $\beta$。</p><p>首先，我们把tube regression中的error与squared error做个比较：</p><p><img src="http://img.blog.csdn.net/20170708180829090?" alt="这里写图片描述"></p><p>然后，将err(y,s)与s的关系曲线分别画出来：</p><p><img src="http://img.blog.csdn.net/20170708181020406?" alt="这里写图片描述"></p><p>上图中，红色的线表示squared error，蓝色的线表示tube error。我们发现，当|s-y|比较小即s比较接近y的时候，squared error与tube error是差不多大小的。而在|s-y|比较大的区域，squared error的增长幅度要比tube error大很多。error的增长幅度越大，表示越容易受到noise的影响，不利于最优化问题的求解。所以，从这个方面来看，tube regression的这种error function要更好一些。</p><p>现在，我们把L2-Regularized Tube Regression写下来：</p><p><img src="http://img.blog.csdn.net/20170708205719827?" alt="这里写图片描述"></p><p>这个最优化问题，由于其中包含max项，并不是处处可微分的，所以不适合用GD/SGD来求解。而且，虽然满足representer theorem，有可能通过引入kernel来求解，但是也并不能保证得到sparsity $\beta$。从另一方面考虑，我们可以把这个问题转换为带条件的QP问题，仿照dual SVM的推导方法，引入kernel，得到KKT条件，从而保证解$\beta$是sparse的。</p><p><img src="http://img.blog.csdn.net/20170708210614893?" alt="这里写图片描述"></p><p>所以，我们就可以把L2-Regularized Tube Regression写成跟SVM类似的形式：</p><p><img src="http://img.blog.csdn.net/20170708210828256?" alt="这里写图片描述"></p><p>值得一提的是，系数$\lambda$和C是反比例相关的，$\lambda$越大对应C越小，$\lambda$越小对应C越大。而且该式也把$w_0$即b单独拿了出来，这跟我们之前推导SVM的解的方法是一致的。</p><p>现在我们已经有了Standard Support Vector Regression的初始形式，这还是不是一个标准的QP问题。我们继续对该表达式做一些转化和推导：</p><p><img src="http://img.blog.csdn.net/20170708211909816?" alt="这里写图片描述"></p><p>如上图右边所示，即为标准的QP问题，其中$\xi_n^{\bigvee}$和$\xi_n^{\bigwedge}$分别表示upper tube violations和lower tube violations。这种形式叫做Support Vector Regression（SVR） primal。</p><p><img src="http://img.blog.csdn.net/20170708212831107?" alt="这里写图片描述"></p><p>SVR的标准QP形式包含几个重要的参数：C和$\epsilon$。C表示的是regularization和tube violation之间的权衡。large C倾向于tube violation，small C则倾向于regularization。$\epsilon$表征了tube的区域宽度，即对错误点的容忍程度。$\epsilon$越大，则表示对错误的容忍度越大。$\epsilon$是可设置的常数，是SVR问题中独有的，SVM中没有这个参数。另外，SVR的QP形式共有$\hat{d}+1+2N$个参数，2N+2N个条件。</p><p><img src="http://img.blog.csdn.net/20170708213803381?" alt="这里写图片描述"></p><h3 id="Support-Vector-Regression-Dual"><a href="#Support-Vector-Regression-Dual" class="headerlink" title="Support Vector Regression Dual"></a>Support Vector Regression Dual</h3><p>现在我们已经得到了SVR的primal形式，接下来将推导SVR的Dual形式。首先，与SVM对偶形式一样，先令拉格朗日因子$\alpha^{\bigvee}$和$\alpha^{\bigwedge}$，分别是与$\xi_n^{\bigvee}$和$\xi_n^{\bigwedge}$不等式相对应。这里忽略了与$\xi_n^{\bigvee}\geq0$和$\xi_n^{\bigwedge}\geq0$对应的拉格朗日因子。</p><p><img src="http://img.blog.csdn.net/20170709102015594?" alt="这里写图片描述"></p><p>然后，与SVM一样做同样的推导和化简，拉格朗日函数对相关参数偏微分为零，得到相应的KKT条件：</p><p><img src="http://img.blog.csdn.net/20170709102506198?" alt="这里写图片描述"></p><p>接下来，通过观察SVM primal与SVM dual的参数对应关系，直接从SVR primal推导出SVR dual的形式。（具体数学推导，此处忽略！）</p><p><img src="http://img.blog.csdn.net/20170709103540709?" alt="这里写图片描述"></p><p>最后，我们就要来讨论一下SVR的解是否真的是sparse的。前面已经推导了SVR dual形式下推导的解w为：</p><p>$$w=\sum_{n=1}^N(\alpha_n^{\bigwedge}-\alpha_n^{\bigvee})z_n$$</p><p>相应的complementary slackness为：</p><p><img src="http://img.blog.csdn.net/20170709104346150?" alt="这里写图片描述"></p><p>对于分布在tube中心区域内的点，满足$|w^Tz_n+b-y_n|&lt;\epsilon$，此时忽略错误，$\xi_n^{\bigvee}$和$\xi_n^{\bigwedge}$都等于零。则complementary slackness两个等式的第二项均不为零，必然得到$\alpha_n^{\bigwedge}=0$和$\alpha_n^{\bigvee}=0$，即$\beta_n=\alpha_n^{\bigwedge}-\alpha_n^{\bigvee}=0$。</p><p>所以，对于分布在tube内的点，得到的解$\beta_n=0$，是sparse的。而分布在tube之外的点，$\beta_n\neq0$。至此，我们就得到了SVR的sparse解。</p><h3 id="Summary-of-Kernel-Models"><a href="#Summary-of-Kernel-Models" class="headerlink" title="Summary of Kernel Models"></a>Summary of Kernel Models</h3><p>这部分将对我们介绍过的所有的kernel模型做个概括和总结。我们总共介绍过三种线性模型，分别是PLA/pocket，regularized logistic regression和linear ridge regression。这三种模型都可以使用国立台湾大学的Chih-Jen Lin博士开发的Liblinear库函数来解决。</p><p>另外，我们介绍了linear soft-margin SVM，其中的error function是$\hat{err}_{svm}$，可以通过标准的QP问题来求解。linear soft-margin SVM和PLA/pocket一样都是解决同样的问题。然后，还介绍了linear SVR问题，它与linear ridge regression一样都是解决同样的问题，从SVM的角度，使用$err_{tube}$，转换为QP问题进行求解，这也是我们本节课的主要内容。</p><p><img src="http://img.blog.csdn.net/20170709132228041?" alt="这里写图片描述"></p><p>上图中相应的模型也可以转化为dual形式，引入kernel，整体的框图如下：</p><p><img src="http://img.blog.csdn.net/20170709132519188?" alt="这里写图片描述"></p><p>其中SVM，SVR和probabilistic SVM都可以使用国立台湾大学的Chih-Jen Lin博士开发的LLibsvm库函数来解决。通常来说，这些模型中SVR和probabilistic SVM最为常用。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了SVR，我们先通过representer theorem理论，将ridge regression转化为kernel的形式，即kernel ridge regression，并推导了SVR的解。但是得到的解是dense的，大部分为非零值。所以，我们定义新的tube regression，使用SVM的推导方法，来最小化regularized tube errors，转化为对偶形式，得到了sparse的解。最后，我们对介绍过的所有kernel模型做个总结，简单概述了各自的特点。在实际应用中，我们要根据不同的问题进行合适的模型选择。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170708142619499?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记5 -- Kernel Logistic Regression</title>
    <link href="https://redstonewill.github.io/2018/03/18/22/"/>
    <id>https://redstonewill.github.io/2018/03/18/22/</id>
    <published>2018-03-18T03:15:40.000Z</published>
    <updated>2018-03-18T03:41:38.506Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170705230810204?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Soft-Margin SVM，即如果允许有分类错误的点存在，那么在原来的Hard-Margin SVM中添加新的惩罚因子C，修正原来的公式，得到新的$\alpha_n$值。最终的到的$\alpha_n$有个上界，上界就是C。Soft-Margin SVM权衡了large-margin和error point之前的关系，目的是在尽可能犯更少错误的前提下，得到最大分类边界。本节课将把Soft-Margin SVM和我们之前介绍的Logistic Regression联系起来，研究如何使用kernel技巧来解决更多的问题。</p><h3 id="Soft-Margin-SVM-as-Regularized-Model"><a href="#Soft-Margin-SVM-as-Regularized-Model" class="headerlink" title="Soft-Margin SVM as Regularized Model"></a>Soft-Margin SVM as Regularized Model</h3><p>先复习一下我们已经介绍过的内容，我们最早开始讲了Hard-Margin Primal的数学表达式，然后推导了Hard-Margin Dual形式。后来，为了允许有错误点的存在（或者noise），也为了避免模型过于复杂化，造成过拟合，我们建立了Soft-Margin Primal的数学表达式，并引入了新的参数C作为权衡因子，然后也推导了其Soft-Margin Dual形式。因为Soft-Margin Dual SVM更加灵活、便于调整参数，所以在实际应用中，使用Soft-Margin Dual SVM来解决分类问题的情况更多一些。</p><p><img src="http://img.blog.csdn.net/20170705230810204?" alt="这里写图片描述"></p><p>Soft-Margin Dual SVM有两个应用非常广泛的工具包，分别是Libsvm和Liblinear。 Libsvm和Liblinear都是国立台湾大学的Chih-Jen Lin博士开发的，Chih-Jen Lin的个人网站为：<a href="http://www.csie.ntu.edu.tw/~cjlin/index.html" target="_blank" rel="noopener">Welcome to Chih-Jen Lin’s Home Page</a></p><p>下面我们再来回顾一下Soft-Margin SVM的主要内容。我们的出发点是用$\xi_n$来表示margin violation，即犯错值的大小，没有犯错对应的$\xi_n=0$。然后将有条件问题转化为对偶dual形式，使用QP来得到最佳化的解。</p><p>从另外一个角度来看，$\xi_n$描述的是点$(x_n,y_n)$ 距离$y_n(w^Tz_n+b)=1$的边界有多远。第一种情况是violating margin，即不满足$y_n(w^Tz_n+b)\geq1$。那么$\xi_n$可表示为：$\xi_n=1-y_n(w^Tz_n+b)&gt;0$。第二种情况是not violating margin，即点$(x_n,y_n)$ 在边界之外，满足$y_n(w^Tz_n+b)\geq1$的条件，此时$\xi_n=0$。我们可以将两种情况整合到一个表达式中，对任意点：</p><p>$$\xi_n=max(1-y_n(w^Tz_n+b),0)$$</p><p>上式表明，如果有voilating margin，则$1-y_n(w^Tz_n+b)&gt;0$，$\xi_n=1-y_n(w^Tz_n+b)$；如果not violating margin，则$1-y_n(w^Tz_n+b)&lt;0$，$\xi_n=0$。整合之后，我们可以把Soft-Margin SVM的最小化问题写成如下形式：</p><p>$$\frac12w^Tw+C\sum_{n=1}^Nmax(1-y_n(w^Tz_n+b),0)$$</p><p>经过这种转换之后，表征犯错误值大小的变量$\xi_n$就被消去了，转而由一个max操作代替。</p><p><img src="http://img.blog.csdn.net/20170706081744914?" alt="这里写图片描述"></p><p>为什么要将把Soft-Margin SVM转换为这种unconstrained form呢？我们再来看一下转换后的形式，其中包含两项，第一项是w的内积，第二项关于y和w，b，z的表达式，似乎有点像一种错误估计$\hat{err}$，则类似这样的形式：</p><p>$$min\ \frac12w^Tw+C\sum\hat{err}$$</p><p>看到这样的形式我们应该很熟悉，因为之前介绍的L2 Regularization中最优化问题的表达式跟这个是类似的：</p><p>$$min\ \frac{\lambda}{N}w^Tw+\frac1N\sum err$$</p><p><img src="http://img.blog.csdn.net/20170706083142170?" alt="这里写图片描述"></p><p>这里提一下，既然unconstrained form SVM与L2 Regularization的形式是一致的，而且L2 Regularization的解法我们之前也介绍过，那么为什么不直接利用这种方法来解决unconstrained form SVM的问题呢？有两个原因。一个是这种无条件的最优化问题无法通过QP解决，即对偶推导和kernel都无法使用；另一个是这种形式中包含的max()项可能造成函数并不是处处可导，这种情况难以用微分方法解决。</p><p>我们在第一节课中就介绍过Hard-Margin SVM与Regularization Model是有关系的。Regularization的目标是最小化$E_{in}$，条件是$w^Tw\leq C$，而Hard-Margin SVM的目标是最小化$w^Tw$，条件是$E_{in}=0$，即它们的最小化目标和限制条件是相互对调的。对于L2 Regularization来说，条件和最优化问题结合起来，整体形式写成：</p><p>$$\frac{\lambda}{N}w^Tw+E_{in}$$</p><p>而对于Soft-Margin SVM来说，条件和最优化问题结合起来，整体形式写成：</p><p>$$\frac12w^Tw+CN\hat{E_{in}}$$</p><p><img src="http://img.blog.csdn.net/20170706085330431?" alt="这里写图片描述"></p><p>通过对比，我们发现L2 Regularization和Soft-Margin SVM的形式是相同的，两个式子分别包含了参数$\lambda$和C。Soft-Margin SVM中的large margin对应着L2 Regularization中的short w，也就是都让hyperplanes更简单一些。我们使用特别的$\hat{err}$来代表可以容忍犯错误的程度，即soft margin。L2 Regularization中的$\lambda$和Soft-Margin SVM中的C也是相互对应的，$\lambda$越大，w会越小，Regularization的程度就越大；C越小，$\hat{E_{in}}$会越大，相应的margin就越大。所以说增大C，或者减小$\lambda$，效果是一致的，Large-Margin等同于Regularization，都起到了防止过拟合的作用。</p><p><img src="http://img.blog.csdn.net/20170706101351607?" alt="这里写图片描述"></p><p>建立了Regularization和Soft-Margin SVM的关系，接下来我们将尝试看看是否能把SVM作为一个regularized的模型进行扩展，来解决其它一些问题。</p><h3 id="SVM-versus-Logistic-Regression"><a href="#SVM-versus-Logistic-Regression" class="headerlink" title="SVM versus Logistic Regression"></a>SVM versus Logistic Regression</h3><p>上一小节，我们已经把Soft-Margin SVM转换成无条件的形式：</p><p><img src="http://img.blog.csdn.net/20170706112629915?" alt="这里写图片描述"></p><p>上式中第二项的$max(1-y_n(w^Tz_n+b),0)$倍设置为$\hat{err}$。下面我们来看看$\hat{err}$与之前再二元分类中介绍过的$err_{0/1}$有什么关系。</p><p>对于$err_{0/1}$，它的linear score $s=w^Tz_n+b$，当$ys\geq0$时，$err_{0/1}=0$；当$ys&lt;0$时，$err_{0/1}=1$，呈阶梯状，如下图所示。而对于$\hat{err}$，当$ys\geq0$时，$err_{0/1}=0$；当$ys&lt;0$时，$err_{0/1}=1-ys$，呈折线状，如下图所示，通常把$\hat{err}_{svm}$称为hinge error measure。比较两条error曲线，我们发现$\hat{err}_{svm}$始终在$err_{0/1}$的上面，则$\hat{err}_{svm}$可作为$err_{0/1}$的上界。所以，可以使用$\hat{err}_{svm}$来代替$err_{0/1}$，解决二元线性分类问题，而且$\hat{err}_{svm}$是一个凸函数，使它在最佳化问题中有更好的性质。</p><p><img src="http://img.blog.csdn.net/20170706140323646?" alt="这里写图片描述"></p><p>紧接着，我们再来看一下logistic regression中的error function。逻辑回归中，$err_{sce}=log_2(1+exp(-ys))$，当ys=0时，$err_{sce}=1$。它的err曲线如下所示。</p><p><img src="http://img.blog.csdn.net/20170706141204821?" alt="这里写图片描述"></p><p>很明显，$err_{sce}$也是$err_{0/1}$的上界，而$err_{sce}$与$\hat{err}<em>{svm}$也是比较相近的。因为当ys趋向正无穷大的时候，$err</em>{sce}$和$\hat{err}<em>{svm}$都趋向于零；当ys趋向负无穷大的时候，$err</em>{sce}$和$\hat{err}_{svm}$都趋向于正无穷大。正因为二者的这种相似性，我们可以把SVM看成是L2-regularized logistic regression。</p><p>总结一下，我们已经介绍过几种Binary Classification的Linear Models，包括PLA，Logistic Regression和Soft-Margin SVM。PLA是相对简单的一个模型，对应的是$err_{0/1}$，通过不断修正错误的点来获得最佳分类线。它的优点是简单快速，缺点是只对线性可分的情况有用，线性不可分的情况需要用到pocket算法。Logistic Regression对应的是$err_{sce}$，通常使用GD/SGD算法求解最佳分类线。它的优点是凸函数$err_{sce}$便于最优化求解，而且有regularization作为避免过拟合的保证；缺点是$err_{sce}$作为$err_{0/1}$的上界，当ys很小（负值）时，上界变得更宽松，不利于最优化求解。Soft-Margin SVM对应的是$\hat{err}_{svm}$，通常使用QP求解最佳分类线。它的优点和Logistic Regression一样，凸优化问题计算简单而且分类线比较“粗壮”一些；缺点也和Logistic Regression一样，当ys很小（负值）时，上界变得过于宽松。其实，Logistic Regression和Soft-Margin SVM都是在最佳化$err_{0/1}$的上界而已。</p><p><img src="http://img.blog.csdn.net/20170706144406136?" alt="这里写图片描述"></p><p>至此，可以看出，求解regularized logistic regression的问题等同于求解soft-margin SVM的问题。反过来，如果我们求解了一个soft-margin SVM的问题，那这个解能否直接为regularized logistic regression所用？来预测结果是正类的几率是多少，就像regularized logistic regression做的一样。我们下一小节将来解答这个问题。</p><h3 id="SVM-for-Soft-Binary-Classification"><a href="#SVM-for-Soft-Binary-Classification" class="headerlink" title="SVM for Soft Binary Classification"></a>SVM for Soft Binary Classification</h3><p>接下来，我们探讨如何将SVM的结果应用在Soft Binary Classification中，得到是正类的概率值。</p><p>第一种简单的方法是先得到SVM的解$(b_{svm},w_{svm})$，然后直接代入到logistic regression中，得到$g(x)=\theta(w_{svm}^Tx+b_{svm})$。这种方法直接使用了SVM和logistic regression的相似性，一般情况下表现还不错。但是，这种形式过于简单，与logistic regression的关联不大，没有使用到logistic regression中好的性质和方法。</p><p>第二种简单的方法是同样先得到SVM的解$(b_{svm},w_{svm})$，然后把$(b_{svm},w_{svm})$作为logistic regression的初始值，再进行迭代训练修正，速度比较快，最后，将得到的b和w代入到g(x)中。这种做法有点显得多此一举，因为并没有比直接使用logistic regression快捷多少。</p><p><img src="http://img.blog.csdn.net/20170706153919029?" alt="这里写图片描述"></p><p>这两种方法都没有融合SVM和logistic regression各自的优势，下面构造一个模型，融合了二者的优势。构造的模型g(x)表达式为：</p><p>$$g(x)=\theta(A\cdot(w_{svm}^T\Phi(x)+b_{svm})+B)$$</p><p>与上述第一种简单方法不同，我们额外增加了放缩因子A和平移因子B。首先利用SVM的解$(b_{svm},w_{svm})$来构造这个模型，放缩因子A和平移因子B是待定系数。然后再用通用的logistic regression优化算法，通过迭代优化，得到最终的A和B。一般来说，如果$(b_{svm},w_{svm})$较为合理的话，满足A&gt;0且$B\approx0$。</p><p><img src="http://img.blog.csdn.net/20170706155120610?" alt="这里写图片描述"></p><p>那么，新的logistic regression表达式为：</p><p><img src="http://img.blog.csdn.net/20170706160545395?" alt="这里写图片描述"></p><p>这个表达式看上去很复杂，其实其中的$(b_{svm},w_{svm})$已经在SVM中解出来了，实际上的未知参数只有A和B两个。归纳一下，这种Probabilistic SVM的做法分为三个步骤：</p><p><img src="http://img.blog.csdn.net/20170706161137869?" alt="这里写图片描述"></p><p>这种soft binary classifier方法得到的结果跟直接使用SVM classifier得到的结果可能不一样，这是因为我们引入了系数A和B。一般来说，soft binary classifier效果更好。至于logistic regression的解法，可以选择GD、SGD等等。</p><h3 id="Kernel-Logistic-Regression"><a href="#Kernel-Logistic-Regression" class="headerlink" title="Kernel Logistic Regression"></a>Kernel Logistic Regression</h3><p>上一小节我们介绍的是通过kernel SVM在z空间中求得logistic regression的近似解。如果我们希望直接在z空间中直接求解logistic regression，通过引入kernel，来解决最优化问题，又该怎么做呢？SVM中使用kernel，转化为QP问题，进行求解，但是logistic regression却不是个QP问题，看似好像没有办法利用kernel来解决。</p><p>我们先来看看之前介绍的kernel trick为什么会work，kernel trick就是把z空间的内积转换到x空间中比较容易计算的函数。如果w可以表示为z的线性组合，即$w_*=\sum_{n=1}^N\beta_nz_n$的形式，那么乘积项$w_*^Tz=\sum_{n=1}^N\beta_nz_n^Tz=\sum_{n=1}^N\beta_nK(x_n,x)$，即其中包含了z的内积。也就是w可以表示为z的线性组合是kernel trick可以work的关键。</p><p>我们之前介绍过SVM、PLA包扩logistic regression都可以表示成z的线性组合，这也提供了一种可能，就是将kernel应用到这些问题中去，简化z空间的计算难度。</p><p><img src="http://img.blog.csdn.net/20170706230717900?" alt="这里写图片描述"></p><p>有这样一个理论，对于L2-regularized linear model，如果它的最小化问题形式为如下的话，那么最优解$w_*=\sum_{n=1}^N\beta_nz_n$。</p><p><img src="http://img.blog.csdn.net/20170706231305238?" alt="这里写图片描述"></p><p>下面给出简单的证明，假如最优解$w_*=w_{||}+w_{\bot}$。其中，$w_{||}$和$w_{\bot}$分别是平行z空间和垂直z空间的部分。我们需要证明的是$w_{\bot}=0$。利用反证法，假如$w_{\bot}\neq0$，考虑$w_*$与$w_{||}$的比较。第一步先比较最小化问题的第二项：$err(y,w_*^Tz_n)=err(y_n,(w_{||}+w_{\bot})^Tz_n=err(y_n,w_{||}^Tz_n)$，即第二项是相等的。然后第二步比较第一项：$w_*^Tw_*=w_{||}^Tw_{||}+2w_{||}^Tw_{\bot}+w_{\bot}^Tw_{\bot}&gt;w_{||}^Tw_{||}$，即$w_*$对应的L2-regularized linear model值要比$w_{||}$大，这就说明$w_*$并不是最优解，从而证明$w_{\bot}$必然等于零，即$w_*=\sum_{n=1}^N\beta_nz_n$一定成立，$w_*$一定可以写成z的线性组合形式。</p><p><img src="http://img.blog.csdn.net/20170706233401559?" alt="这里写图片描述"></p><p>经过证明和分析，我们得到了结论是任何L2-regularized linear model都可以使用kernel来解决。</p><p>现在，我们来看看如何把kernel应用在L2-regularized logistic regression上。上面我们已经证明了$w_*$一定可以写成z的线性组合形式，即$w_*=\sum_{n=1}^N\beta_nz_n$。那么我们就无需一定求出$w_*$，而只要求出其中的$\beta_n$就行了。怎么求呢？直接将$w_*=\sum_{n=1}^N\beta_nz_n$代入到L2-regularized logistic regression最小化问题中，得到：</p><p><img src="http://img.blog.csdn.net/20170707075257770?" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20170707080638752?" alt="这里写图片描述"></p><p>上式中，所有的w项都换成$\beta_n$来表示了，变成了没有条件限制的最优化问题。我们把这种问题称为kernel logistic regression，即引入kernel，将求w的问题转换为求$\beta_n$的问题。</p><p>从另外一个角度来看Kernel Logistic Regression（KLR）：</p><p><img src="http://img.blog.csdn.net/20170707081255169?" alt="这里写图片描述"></p><p>上式中log项里的$\sum_{m=1}^N\beta_mK(x_m,x_n)$可以看成是变量$\beta$和$K(x_m,x_n)$的内积。上式第一项中的$\sum_{n=1}^N\sum_{m=1}^N\beta_n\beta_mK(x_n,x_m)$可以看成是关于$\beta$的正则化项$\beta^TK\beta$。所以，KLR是$\beta$的线性组合，其中包含了kernel内积项和kernel regularizer。这与SVM是相似的形式。</p><p>但值得一提的是，KLR中的$\beta_n$与SVM中的$\alpha_n$是有区别的。SVM中的$\alpha_n$大部分为零，SV的个数通常是比较少的；而KLR中的$\beta_n$通常都是非零值。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Kernel Logistic Regression。首先把Soft-Margin SVM解释成Regularized Model，建立二者之间的联系，其实Soft-Margin SVM就是一个L2-regularization，对应着hinge error messure。然后利用它们之间的相似性，讨论了如何利用SVM的解来得到Soft Binary Classification。方法是先得到SVM的解，再在logistic regression中引入参数A和B，迭代训练，得到最佳解。最后介绍了Kernel Logistic Regression，证明L2-regularized logistic regression中，最佳解$w_*$一定可以写成z的线性组合形式，从而可以将kernel引入logistic regression中，使用kernel思想在z空间直接求解L2-regularized logistic regression问题。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170705230810204?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记4 -- Soft-Margin Support Vector Machine</title>
    <link href="https://redstonewill.github.io/2018/03/18/21/"/>
    <id>https://redstonewill.github.io/2018/03/18/21/</id>
    <published>2018-03-18T02:58:08.000Z</published>
    <updated>2018-03-18T03:00:55.902Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170704082607300?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了Kernel SVM。先将特征转换和计算内积这两个步骤合并起来，简化计算、提高计算速度，再用Dual SVM的求解方法来解决。Kernel SVM不仅能解决简单的线性分类问题，也可以求解非常复杂甚至是无限多维的分类问题，关键在于核函数的选择，例如线性核函数、多项式核函数和高斯核函数等等。但是，我们之前讲的这些方法都是Hard-Margin SVM，即必须将所有的样本都分类正确才行。这往往需要更多更复杂的特征转换，甚至造成过拟合。本节课将介绍一种Soft-Margin SVM，目的是让分类错误的点越少越好，而不是必须将所有点分类正确，也就是允许有noise存在。这种做法很大程度上不会使模型过于复杂，不会造成过拟合，而且分类效果是令人满意的。</p><h3 id="Motivation-and-Primal-Problem"><a href="#Motivation-and-Primal-Problem" class="headerlink" title="Motivation and Primal Problem"></a>Motivation and Primal Problem</h3><p>上节课我们说明了一点，就是SVM同样可能会造成overfit。原因有两个，一个是由于我们的SVM模型（即kernel）过于复杂，转换的维度太多，过于powerful了；另外一个是由于我们坚持要将所有的样本都分类正确，即不允许错误存在，造成模型过于复杂。如下图所示，左边的图$\Phi_1$是线性的，虽然有几个点分类错误，但是大部分都能完全分开。右边的图$\Phi_4$是四次多项式，所有点都分类正确了，但是模型比较复杂，可能造成过拟合。直观上来说，左边的图是更合理的模型。</p><p><img src="http://img.blog.csdn.net/20170704082607300?" alt="这里写图片描述"></p><p>如何避免过拟合？方法是允许有分类错误的点，即把某些点当作是noise，放弃这些noise点，但是尽量让这些noise个数越少越好。回顾一下我们在机器学习基石笔记中介绍的pocket算法，pocket的思想不是将所有点完全分开，而是找到一条分类线能让分类错误的点最少。而Hard-Margin SVM的目标是将所有点都完全分开，不允许有错误点存在。为了防止过拟合，我们可以借鉴pocket的思想，即允许有犯错误的点，目标是让这些点越少越好。</p><p><img src="http://img.blog.csdn.net/20170704083643796?" alt="这里写图片描述"></p><p>为了引入允许犯错误的点，我们将Hard-Margin SVM的目标和条件做一些结合和修正，转换为如下形式：</p><p><img src="http://img.blog.csdn.net/20170704083927515?" alt="这里写图片描述"></p><p>修正后的条件中，对于分类正确的点，仍需满足$y_n(w^Tz_n+b)\geq 1$，而对于noise点，满足$y_n(w^Tz_n+b)\geq -\infty$，即没有限制。修正后的目标除了$\frac12w^Tw$项，还添加了$y_n\neq sign(w^Tz_n+b)$，即noise点的个数。参数C的引入是为了权衡目标第一项和第二项的关系，即权衡large margin和noise tolerance的关系。</p><p>我们再对上述的条件做修正，将两个条件合并，得到：</p><p><img src="http://img.blog.csdn.net/20170704090202170?" alt="这里写图片描述"></p><p>这个式子存在两个不足的地方。首先，最小化目标中第二项是非线性的，不满足QP的条件，所以无法使用dual或者kernel SVM来计算。然后，对于犯错误的点，有的离边界很近，即error小，而有的离边界很远，error很大，上式的条件和目标没有区分small error和large error。这种分类效果是不完美的。</p><p><img src="http://img.blog.csdn.net/20170704091211117?" alt="这里写图片描述"></p><p>为了改正这些不足，我们继续做如下修正：</p><p><img src="http://img.blog.csdn.net/20170704091355472?" alt="这里写图片描述"></p><p>修正后的表达式中，我们引入了新的参数$\xi_n$来表示每个点犯错误的程度值，$\xi_n\geq0$。通过使用error值的大小代替是否有error，让问题变得易于求解，满足QP形式要求。这种方法类似于我们在机器学习基石笔记中介绍的0/1 error和squared error。这种soft-margin SVM引入新的参数$\xi$。</p><p>至此，最终的Soft-Margin SVM的目标为：</p><p>$$min(b,w,\xi)\ \frac12w^Tw+C\cdot\sum_{n=1}^N\xi_n$$</p><p>条件是：</p><p>$$y_n(w^Tz_n+b)\geq 1-\xi_n$$</p><p>$$\xi_n\geq0$$</p><p>其中，$\xi_n$表示每个点犯错误的程度，$\xi_n=0$，表示没有错误，$\xi_n$越大，表示错误越大，即点距离边界（负的）越大。参数C表示尽可能选择宽边界和尽可能不要犯错两者之间的权衡，因为边界宽了，往往犯错误的点会增加。large C表示希望得到更少的分类错误，即不惜选择窄边界也要尽可能把更多点正确分类；small C表示希望得到更宽的边界，即不惜增加错误点个数也要选择更宽的分类边界。</p><p>与之对应的QP问题中，由于新的参数$\xi_n$的引入，总共参数个数为$\hat d+1+N$，限制条件添加了$\xi_n\geq0$，则总条件个数为2N。</p><p><img src="http://img.blog.csdn.net/20170704100607061?" alt="这里写图片描述"></p><h3 id="Dual-Problem"><a href="#Dual-Problem" class="headerlink" title="Dual Problem"></a>Dual Problem</h3><p>接下来，我们将推导Soft-Margin SVM的对偶dual形式，从而让QP计算更加简单，并便于引入kernel算法。首先，我们把Soft-Margin SVM的原始形式写出来：</p><p><img src="http://img.blog.csdn.net/20170704143333672?" alt="这里写图片描述"></p><p>然后，跟我们在第二节课中介绍的Hard-Margin SVM做法一样，构造一个拉格朗日函数。因为引入了$\xi_n$，原始问题有两类条件，所以包含了两个拉格朗日因子$\alpha_n$和$\beta_n$。拉格朗日函数可表示为如下形式：</p><p><img src="http://img.blog.csdn.net/20170704144256286?" alt="这里写图片描述"></p><p>接下来，我们跟第二节课中的做法一样，利用Lagrange dual problem，将Soft-Margin SVM问题转换为如下形式：</p><p><img src="http://img.blog.csdn.net/20170704144748340?" alt="这里写图片描述"></p><p>根据之前介绍的KKT条件，我们对上式进行简化。上式括号里面的是对拉格朗日函数$L(b,w,\xi,\alpha,\beta)$计算最小值。那么根据梯度下降算法思想：最小值位置满足梯度为零。</p><p>我们先对$\xi_n$做偏微分：</p><p>$$\frac{\partial L}{\partial \xi_n}=0=C-\alpha_n-\beta_n$$</p><p>根据上式，得到$\beta_n=C-\alpha_n$，因为有$\beta_n\geq0$，所以限制$0\leq\alpha_n\leq C$。将$\beta_n=C-\alpha_n$代入到dual形式中并化简，我们发现$\beta_n$和$\xi_n$都被消去了：</p><p><img src="http://img.blog.csdn.net/20170704150122322?" alt="这里写图片描述"></p><p>这个形式跟Hard-Margin SVM中的dual形式是基本一致的，只是条件不同。那么，我们分别令拉个朗日函数L对b和w的偏导数为零，分别得到：</p><p>$$\sum_{n=1}^N\alpha_ny_n=0$$</p><p>$$w=\sum_{n=1}^N\alpha_ny_nz_n$$</p><p>经过化简和推导，最终标准的Soft-Margin SVM的Dual形式如下图所示：</p><p><img src="http://img.blog.csdn.net/20170704151156715?" alt="这里写图片描述"></p><p>Soft-Margin SVM Dual与Hard-Margin SVM Dual基本一致，只有一些条件不同。Hard-Margin SVM Dual中$\alpha_n\geq0$，而Soft-Margin SVM Dual中$0\leq\alpha_n\leq C$，且新的拉格朗日因子$\beta_n=C-\alpha_n$。在QP问题中，Soft-Margin SVM Dual的参数$\alpha_n$同样是N个，但是，条件由Hard-Margin SVM Dual中的N+1个变成2N+1个，这是因为多了N个$\alpha_n$的上界条件。</p><p>对于Soft-Margin SVM Dual这部分推导不太清楚的同学，可以看下第二节课的笔记：<a href="http://blog.csdn.net/red_stone1/article/details/73822768" target="_blank" rel="noopener">台湾大学林轩田机器学习技法课程学习笔记2 – Dual Support Vector Machine</a></p><h3 id="Messages-behind-Soft-Margin-SVM"><a href="#Messages-behind-Soft-Margin-SVM" class="headerlink" title="Messages behind Soft-Margin SVM"></a>Messages behind Soft-Margin SVM</h3><p>推导完Soft-Margin SVM Dual的简化形式后，就可以利用QP，找到Q，p，A，c对应的值，用软件工具包得到$\alpha_n$的值。或者利用核函数的方式，同样可以简化计算，优化分类效果。Soft-Margin SVM Dual计算$\alpha_n$的方法过程与Hard-Margin SVM Dual的过程是相同的。</p><p><img src="http://img.blog.csdn.net/20170704153246056?" alt="这里写图片描述"></p><p>但是如何根据$\alpha_n$的值计算b呢？在Hard-Margin SVM Dual中，有complementary slackness条件：$\alpha_n(1-y_n(w^Tz_n+b))=0$，找到SV，即$\alpha_s&gt;0$的点，计算得到$b=y_s-w^Tz_s$。</p><p>那么，在Soft-Margin SVM Dual中，相应的complementary slackness条件有两个（因为两个拉格朗日因子$\alpha_n$和$\beta_n$）：</p><p>$$\alpha_n(1-\xi_n-y_n(w^Tz_n+b))=0$$</p><p>$$\beta_n\xi_n=(C-\alpha_n)\xi=0$$</p><p>找到SV，即$\alpha_s&gt;0$的点，由于参数$\xi_n$的存在，还不能完全计算出b的值。根据第二个complementary slackness条件，如果令$C-\alpha_n\neq0$，即$\alpha_n\neq C$，则一定有$\xi_n=0$，代入到第一个complementary slackness条件，即可计算得到$b=y_s-w^Tz_s$。我们把$0&lt;\alpha_s&lt;C$的点称为free SV。引入核函数后，b的表达式为：</p><p>$$b=y_s-\sum_{SV}\alpha_ny_nK(x_n,x_s)$$</p><p>上面求解b提到的一个假设是$\alpha_s&lt;C$，这个假设是否一定满足呢？如果没有free SV，所有$\alpha_s$大于零的点都满足$\alpha_s=C$怎么办？一般情况下，至少存在一组SV使$\alpha_s&lt;C$的概率是很大的。如果出现没有free SV的情况，那么b通常会由许多不等式条件限制取值范围，值是不确定的，只要能找到其中满足KKT条件的任意一个b值就可以了。这部分细节比较复杂，不再赘述。</p><p><img src="http://img.blog.csdn.net/20170704161945487?" alt="这里写图片描述"></p><p>接下来，我们看看C取不同的值对margin的影响。例如，对于Soft-Margin Gaussian SVM，C分别取1，10，100时，相应的margin如下图所示：</p><p><img src="http://img.blog.csdn.net/20170704162711810?" alt="这里写图片描述"></p><p>从上图可以看出，C=1时，margin比较粗，但是分类错误的点也比较多，当C越来越大的时候，margin越来越细，分类错误的点也在减少。正如前面介绍的，C值反映了margin和分类正确的一个权衡。C越小，越倾向于得到粗的margin，宁可增加分类错误的点；C越大，越倾向于得到高的分类正确率，宁可margin很细。我们发现，当C值很大的时候，虽然分类正确率提高，但很可能把noise也进行了处理，从而可能造成过拟合。也就是说Soft-Margin Gaussian SVM同样可能会出现过拟合现象，所以参数$(\gamma,C)$的选择非常重要。</p><p>我们再来看看$\alpha_n$取不同值是对应的物理意义。已知$0\leq\alpha_n\leq C$满足两个complementary slackness条件：</p><p>$$\alpha_n(1-\xi_n-y_n(w^Tz_n+b))=0$$</p><p>$$\beta_n\xi_n=(C-\alpha_n)\xi=0$$</p><p>若$\alpha_n=0$，得$\xi_n=0$。$\xi_n=0$表示该点没有犯错，$\alpha_n=0$表示该点不是SV。所以对应的点在margin之外（或者在margin上），且均分类正确。</p><p>若$0&lt;\alpha_n&lt;C$，得$\xi_n=0$，且$y_n(w^Tz_n+b)=1$。$\xi_n=0$表示该点没有犯错，$y_n(w^Tz_n+b)=1$表示该点在margin上。这些点即free SV，确定了b的值。</p><p>若$\alpha_n=C$，不能确定$\xi_n$是否为零，且得到$1-y_n(w^Tz_n+b)=\xi_n$，这个式表示该点偏离margin的程度，$\xi_n$越大，偏离margin的程度越大。只有当$\xi_n=0$时，该点落在margin上。所以这种情况对应的点在margin之内负方向（或者在margin上），有分类正确也有分类错误的。这些点称为bounded SV。</p><p>所以，在Soft-Margin SVM Dual中，根据$\alpha_n$的取值，就可以推断数据点在空间的分布情况。</p><p><img src="http://img.blog.csdn.net/20170704170804624?" alt="这里写图片描述"></p><h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>在Soft-Margin SVM Dual中，kernel的选择、C等参数的选择都非常重要，直接影响分类效果。例如，对于Gaussian SVM，不同的参数$(C,\gamma)$，会得到不同的margin，如下图所示。</p><p><img src="http://img.blog.csdn.net/20170704200115449?" alt="这里写图片描述"></p><p>其中横坐标是C逐渐增大的情况，纵坐标是$\gamma$逐渐增大的情况。不同的$(C,\gamma)$组合，margin的差别很大。那么如何选择最好的$(C,\gamma)$等参数呢？最简单最好用的工具就是validation。</p><p>validation我们在机器学习基石课程中已经介绍过，只需要将由不同$(C,\gamma)$等参数得到的模型在验证集上进行cross validation，选取$E_{cv}$最小的对应的模型就可以了。例如上图中各种$(C,\gamma)$组合得到的$E_{cv}$如下图所示：</p><p><img src="http://img.blog.csdn.net/20170704202325241?" alt="这里写图片描述"></p><p>因为左下角的$E_{cv}(C,\gamma)$最小，所以就选择该$(C,\gamma)$对应的模型。通常来说，$E_{cv}(C,\gamma)$并不是$(C,\gamma)$的连续函数，很难使用最优化选择（例如梯度下降）。一般做法是选取不同的离散的$(C,\gamma)$值进行组合，得到最小的$E_{cv}(C,\gamma)$，其对应的模型即为最佳模型。这种算法就是我们之前在机器学习基石中介绍过的V-Fold cross validation，在SVM中使用非常广泛。</p><p>V-Fold cross validation的一种极限就是Leave-One-Out CV，也就是验证集只有一个样本。对于SVM问题，它的验证集Error满足：</p><p>$$E_{loocv}\leq \frac{SV}{N}$$</p><p>也就是说留一法验证集Error大小不超过支持向量SV占所有样本的比例。下面做简单的证明。令样本总数为N，对这N个点进行SVM分类后得到margin，假设第N个点$(x_N,y_N)$的$\alpha_N=0$，不是SV，即远离margin（正距离）。这时候，如果我们只使用剩下的N-1个点来进行SVM分类，那么第N个点$(x_N,y_N)$必然是分类正确的点，所得的SVM margin跟使用N个点的到的是完全一致的。这是因为我们假设第N个点是non-SV，对SV没有贡献，不影响margin的位置和形状。所以前N-1个点和N个点得到的margin是一样的。</p><p>那么，对于non-SV的点，它的$g^-=g$，即对第N个点，它的Error必然为零：</p><p>$$e_{non-SV}=err(g^-,non-SV)=err(g,non-SV)=0$$</p><p>另一方面，假设第N个点$\alpha_N\neq0$，即对于SV的点，它的Error可能是0，也可能是1，必然有：</p><p>$$e_{SV}\leq1$$</p><p>综上所述，即证明了$E_{loocv}\leq \frac{SV}{N}$。这符合我们之前得到的结论，即只有SV影响margin，non-SV对margin没有任何影响，可以舍弃。</p><p>SV的数量在SVM模型选择中也是很重要的。一般来说，SV越多，表示模型可能越复杂，越有可能会造成过拟合。所以，通常选择SV数量较少的模型，然后在剩下的模型中使用cross-validation，比较选择最佳模型。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Soft-Margin SVM。我们的出发点是与Hard-Margin SVM不同，不一定要将所有的样本点都完全分开，允许有分类错误的点，而使margin比较宽。然后，我们增加了$\xi_n$作为分类错误的惩罚项，根据之前介绍的Dual SVM，推导出了Soft-Margin SVM的QP形式。得到的$\alpha_n$除了要满足大于零，还有一个上界C。接着介绍了通过$\alpha_n$值的大小，可以将数据点分为三种：non-SVs，free SVs，bounded SVs，这种更清晰的物理解释便于数据分析。最后介绍了如何选择合适的SVM模型，通常的办法是cross-validation和利用SV的数量进行筛选。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170704082607300?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记3 -- Kernel Support Vector Machine</title>
    <link href="https://redstonewill.github.io/2018/03/18/20/"/>
    <id>https://redstonewill.github.io/2018/03/18/20/</id>
    <published>2018-03-18T02:54:13.000Z</published>
    <updated>2018-03-18T02:56:48.751Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170630081046212?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了SVM的对偶形式，即dual SVM。Dual SVM也是一个二次规划问题，可以用QP来进行求解。之所以要推导SVM的对偶形式是因为：首先，它展示了SVM的几何意义；然后，从计算上，求解过程“好像”与所在维度$\hat d$无关，规避了$\hat d$很大时难以求解的情况。但是，上节课的最后，我们也提到dual SVM的计算过程其实跟$\hat d$还是有关系的。那么，能不能完全摆脱对$\hat d$的依赖，从而减少SVM计算量呢？这就是我们本节课所要讲的主要内容。</p><h3 id="Kernel-Trick"><a href="#Kernel-Trick" class="headerlink" title="Kernel Trick"></a>Kernel Trick</h3><p>我们上节课推导的dual SVM是如下形式：</p><p><img src="http://img.blog.csdn.net/20170630081046212?" alt="这里写图片描述"></p><p>其中$\alpha$是拉格朗日因子，共N个，这是我们要求解的，而条件共有N+1个。我们来看向量$Q_D$中的$q_{n,m}=y_ny_mz_n^Tz_m$，看似这个计算与$\hat d$无关，但是$z_n^Tz_m$的内积中不得不引入$\hat d$。也就是说，如果$\hat d$很大，计算$z_n^Tz_m$的复杂度也会很高，同样会影响QP问题的计算效率。可以说，$q_{n,m}=y_ny_mz_n^Tz_m$这一步是计算的瓶颈所在。</p><p>其实问题的关键在于$z_n^Tz_m$内积求解上。我们知道，z是由x经过特征转换而来：</p><p>$$z_n^Tz_m=\Phi(x_n)\Phi(x_m)$$</p><p>如果从x空间来看的话，$z_n^Tz_m$分为两个步骤：1. 进行特征转换$\Phi(x_n)$和$\Phi(x_m)$；2. 计算$\Phi(x_n)$与$\Phi(x_m)$的内积。这种先转换再计算内积的方式，必然会引入$\hat d$参数，从而在$\hat d$很大的时候影响计算速度。那么，若把这两个步骤联合起来，是否可以有效地减小计算量，提高计算速度呢？</p><p>我们先来看一个简单的例子，对于二阶多项式转换，各种排列组合为：</p><p><img src="http://img.blog.csdn.net/20170630091408601?" alt="这里写图片描述"></p><p>这里提一下，为了简单起见，我们把$x_0=1$包含进来，同时将二次项$x_1x_2$和$x_2x_1$也包含进来。转换之后再做内积并进行推导，得到：</p><p><img src="http://img.blog.csdn.net/20170630092526343?" alt="这里写图片描述"></p><p>其中$x^Tx’$是x空间中特征向量的内积。所以，$\Phi_2(x)$与$\Phi_2(x’)$的内积的复杂度由原来的$O(d^2)$变成$O(d)$，只与x空间的维度d有关，而与z空间的维度$\hat d$无关，这正是我们想要的！</p><p>至此，我们发现如果把特征转换和z空间计算内积这两个步骤合并起来，有可能会简化计算。因为我们只是推导了二阶多项式会提高运算速度，这个特例并不具有一般推论性。但是，我们还是看到了希望。</p><p>我们把合并特征转换和计算内积这两个步骤的操作叫做Kernel Function，用大写字母K表示。例如刚刚讲的二阶多项式例子，它的kernel function为：</p><p>$$K_{\Phi}(x,x’)=\Phi(x)^T\Phi(x’)$$</p><p>$$K_{\Phi_2}(x,x’)=1+(x^Tx’)+(x^Tx’)^2$$</p><p>有了kernel function之后，我们来看看它在SVM里面如何使用。在dual SVM中，二次项系数$q_{n,m}$中有z的内积计算，就可以用kernel function替换：</p><p>$$q_{n,m}=y_ny_mz_n^Tz_m=y_ny_mK(x_n,x_m)$$</p><p>所以，直接计算出$K(x_n,x_m)$，再代入上式，就能得到$q_{n,m}$的值。</p><p>$q_{n,m}$值计算之后，就能通过QP得到拉格朗日因子$\alpha_n$。然后，下一步就是计算b（取$\alpha_n$&gt;0的点，即SV），b的表达式中包含z，可以作如下推导：</p><p>$$b=y_s-w^Tz_s=y_s-(\sum_{n=1}^N\alpha_ny_nz_n)^Tz_s=y_s-\sum_{n=1}^N\alpha_ny_n(K(x_n,x_s))$$</p><p>这样得到的b就可以用kernel function表示，而与z空间无关。</p><p>最终我们要求的矩$g_{SVM}$可以作如下推导：</p><p>$$g_{SVM}(x)=sign(w^T\Phi(x)+b)=sign((\sum_{n=1}^N\alpha_ny_nz_n)^Tz+b)=sign(\sum_{n=1}^N\alpha_ny_n(K(x_n,x))+b)$$</p><p>至此，dual SVM中我们所有需要求解的参数都已经得到了，而且整个计算过程中都没有在z空间作内积，即与z无关。我们把这个过程称为kernel trick，也就是把特征转换和计算内积两个步骤结合起来，用kernel function来避免计算过程中受$\hat d$的影响，从而提高运算速度。</p><p><img src="http://img.blog.csdn.net/20170630105432632?" alt="这里写图片描述"></p><p>那么总结一下，引入kernel funtion后，SVM算法变成：</p><p><img src="http://img.blog.csdn.net/20170630105722080?" alt="这里写图片描述"></p><p>分析每个步骤的时间复杂度为：</p><p><img src="http://img.blog.csdn.net/20170630110019354?" alt="这里写图片描述"></p><p>我们把这种引入kernel function的SVM称为kernel SVM，它是基于dual SVM推导而来的。kernel SVM同样只用SV（$\alpha_n$&gt;0）就能得到最佳分类面，而且整个计算过程中摆脱了$\hat d$的影响，大大提高了计算速度。</p><h3 id="Polynomial-Kernel"><a href="#Polynomial-Kernel" class="headerlink" title="Polynomial Kernel"></a>Polynomial Kernel</h3><p>我们刚刚通过一个特殊的二次多项式导出了相对应的kernel，其实二次多项式的kernel形式是多种的。例如，相应系数的放缩构成完全平方公式等。下面列举了几种常用的二次多项式kernel形式：</p><p><img src="http://img.blog.csdn.net/20170703080852707?" alt="这里写图片描述"></p><p>比较一下，第一种$\Phi_2(x)$（蓝色标记）和第三种$\Phi_2(x)$（绿色标记）从某种角度来说是一样的，因为都是二次转换，对应到同一个z空间。但是，它们系数不同，内积就会有差异，那么就代表有不同的距离，最终可能会得到不同的SVM margin。所以，系数不同，可能会得到不同的SVM分界线。通常情况下，第三种$\Phi_2(x)$（绿色标记）简单一些，更加常用。</p><p><img src="http://img.blog.csdn.net/20170703081851356?" alt="这里写图片描述"></p><p>不同的转换，对应到不同的几何距离，得到不同的距离，这是什么意思呢？举个例子，对于我们之前介绍的一般的二次多项式kernel，它的SVM margin和对应的SV如下图（中）所示。对于上面介绍的完全平方公式形式，自由度$\gamma=0.001$，它的SVM margin和对应的SV如下图（左）所示。比较发现，这种SVM margin比较简单一些。对于自由度$\gamma=1000$，它的SVM margin和对应的SV如下图（右）所示。与前两种比较，margin和SV都有所不同。</p><p><img src="http://img.blog.csdn.net/20170703082844954?" alt="这里写图片描述"></p><p>通过改变不同的系数，得到不同的SVM margin和SV，如何选择正确的kernel，非常重要。</p><p>归纳一下，引入$\zeta\geq 0$和$\gamma&gt;0$，对于Q次多项式一般的kernel形式可表示为：</p><p><img src="http://img.blog.csdn.net/20170703083722140?" alt="这里写图片描述"></p><p>所以，使用高阶的多项式kernel有两个优点：</p><ul><li><p><strong>得到最大SVM margin，SV数量不会太多，分类面不会太复杂，防止过拟合，减少复杂度</strong></p></li><li><p><strong>计算过程避免了对$\hat d$的依赖，大大简化了计算量。</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170703084625483?" alt="这里写图片描述"></p><p>顺便提一下，当多项式阶数Q=1时，那么对应的kernel就是线性的，即本系列课程第一节课所介绍的内容。对于linear kernel，计算方法是简单的，而且也是我们解决SVM问题的首选。还记得机器学习基石课程中介绍的奥卡姆剃刀定律（Occam’s Razor）吗？</p><h3 id="Gaussian-Kernel"><a href="#Gaussian-Kernel" class="headerlink" title="Gaussian Kernel"></a>Gaussian Kernel</h3><p>刚刚我们介绍的Q阶多项式kernel的阶数是有限的，即特征转换的$\hat d$是有限的。但是，如果是无限多维的转换$\Phi(x)$，是否还能通过kernel的思想，来简化SVM的计算呢？答案是肯定的。</p><p>先举个例子，简单起见，假设原空间是一维的，只有一个特征x，我们构造一个kernel function为高斯函数：</p><p>$$K(x,x’)=e^{-(x-x’)^2}$$</p><p>构造的过程正好与二次多项式kernel的相反，利用反推法，先将上式分解并做泰勒展开：</p><p><img src="http://img.blog.csdn.net/20170703093947389?" alt="这里写图片描述"></p><p>将构造的K(x,x’)推导展开为两个$\Phi(x)$和$\Phi(x’)$的乘积，其中：</p><p>$$\Phi(x)=e^{-x^2}\cdot (1,\sqrt \frac{2}{1!}x,\sqrt \frac{2^2}{2!}x^2,\cdots)$$</p><p>通过反推，我们得到了$\Phi(x)$，$\Phi(x)$是无限多维的，它就可以当成特征转换的函数，且$\hat d$是无限的。这种$\Phi(x)$得到的核函数即为Gaussian kernel。</p><p>更一般地，对于原空间不止一维的情况（d&gt;1），引入缩放因子$\gamma&gt;0$，它对应的Gaussian kernel表达式为：</p><p>$$K(x,x’)=e^{-\gamma||x-x’||^2}$$</p><p>那么引入了高斯核函数，将有限维度的特征转换拓展到无限的特征转换中。根据本节课上一小节的内容，由K，计算得到$\alpha_n$和b，进而得到矩$g_{SVM}$。将其中的核函数K用高斯核函数代替，得到：</p><p>$$g_{SVM}(x)=sign(\sum_{SV}\alpha_ny_nK(x_n,x)+b)=sign(\sum_{SV}\alpha_ny_ne^{(-\gamma||x-x_n||^2)}+b)$$</p><p>通过上式可以看出，$g_{SVM}$有n个高斯函数线性组合而成，其中n是SV的个数。而且，每个高斯函数的中心都是对应的SV。通常我们也把高斯核函数称为径向基函数（Radial Basis Function, RBF）。</p><p><img src="http://img.blog.csdn.net/20170703101252712?" alt="这里写图片描述"></p><p>总结一下，kernel SVM可以获得large-margin的hyperplanes，并且可以通过高阶的特征转换使$E_{in}$尽可能地小。kernel的引入大大简化了dual SVM的计算量。而且，Gaussian kernel能将特征转换扩展到无限维，并使用有限个SV数量的高斯函数构造出矩$g_{SVM}$。</p><p><img src="http://img.blog.csdn.net/20170703102031293?" alt="这里写图片描述"></p><p>值得注意的是，缩放因子$\gamma$取值不同，会得到不同的高斯核函数，hyperplanes不同，分类效果也有很大的差异。举个例子，$\gamma$分别取1, 10, 100时对应的分类效果如下：</p><p><img src="http://img.blog.csdn.net/20170703103142607?" alt="这里写图片描述"></p><p>从图中可以看出，当$\gamma$比较小的时候，分类线比较光滑，当$\gamma$越来越大的时候，分类线变得越来越复杂和扭曲，直到最后，分类线变成一个个独立的小区域，像小岛一样将每个样本单独包起来了。为什么会出现这种区别呢？这是因为$\gamma$越大，其对应的高斯核函数越尖瘦，那么有限个高斯核函数的线性组合就比较离散，分类效果并不好。所以，SVM也会出现过拟合现象，$\gamma$的正确选择尤为重要，不能太大。</p><h3 id="Comparison-of-Kernels"><a href="#Comparison-of-Kernels" class="headerlink" title="Comparison of Kernels"></a>Comparison of Kernels</h3><p>目前为止，我们已经介绍了几种kernel，下面来对几种kernel进行比较。</p><p>首先，Linear Kernel是最简单最基本的核，平面上对应一条直线，三维空间里对应一个平面。Linear Kernel可以使用上一节课介绍的Dual SVM中的QP直接计算得到。</p><p><img src="http://img.blog.csdn.net/20170703112425643?" alt="这里写图片描述"></p><p>Linear Kernel的优点是计算简单、快速，可以直接使用QP快速得到参数值，而且从视觉上分类效果非常直观，便于理解；缺点是如果数据不是线性可分的情况，Linear Kernel就不能使用了。</p><p><img src="http://img.blog.csdn.net/20170703113330995?" alt="这里写图片描述"></p><p>然后，Polynomial Kernel的hyperplanes是由多项式曲线构成。</p><p><img src="http://img.blog.csdn.net/20170703131711028?" alt="这里写图片描述"></p><p>Polynomial Kernel的优点是阶数Q可以灵活设置，相比linear kernel限制更少，更贴近实际样本分布；缺点是当Q很大时，K的数值范围波动很大，而且参数个数较多，难以选择合适的值。</p><p><img src="http://img.blog.csdn.net/20170703132120216?" alt="这里写图片描述"></p><p>对于Gaussian Kernel，表示为高斯函数形式。</p><p><img src="http://img.blog.csdn.net/20170703133450677?" alt="这里写图片描述"></p><p>Gaussian Kernel的优点是边界更加复杂多样，能最准确地区分数据样本，数值计算K值波动较小，而且只有一个参数，容易选择；缺点是由于特征转换到无限维度中，w没有求解出来，计算速度要低于linear kernel，而且可能会发生过拟合。</p><p><img src="http://img.blog.csdn.net/20170703134358134?" alt="这里写图片描述"></p><p>除了这三种kernel之外，我们还可以使用其它形式的kernel。首先，我们考虑kernel是什么？实际上kernel代表的是两笔资料x和x’，特征变换后的相似性即内积。但是不能说任何计算相似性的函数都可以是kernel。有效的kernel还需满足几个条件：</p><ul><li><p><strong>K是对称的</strong></p></li><li><p><strong>K是半正定的</strong></p></li></ul><p>这两个条件不仅是必要条件，同时也是充分条件。所以，只要我们构造的K同时满足这两个条件，那它就是一个有效的kernel。这被称为Mercer 定理。事实上，构造一个有效的kernel是比较困难的。</p><p><img src="http://img.blog.csdn.net/20170703135827622?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了Kernel Support Vector Machine。首先，我们将特征转换和计算内积的操作合并到一起，消除了$\hat d$的影响，提高了计算速度。然后，分别推导了Polynomial Kernel和Gaussian Kernel，并列举了各自的优缺点并做了比较。对于不同的问题，应该选择合适的核函数进行求解，以达到最佳的分类效果。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170630081046212?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记2 -- Dual Support Vector Machine</title>
    <link href="https://redstonewill.github.io/2018/03/18/19/"/>
    <id>https://redstonewill.github.io/2018/03/18/19/</id>
    <published>2018-03-18T02:50:33.000Z</published>
    <updated>2018-03-18T02:52:29.417Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170627195157734?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>上节课我们主要介绍了线性支持向量机（Linear Support Vector Machine）。Linear SVM的目标是找出最“胖”的分割线进行正负类的分离，方法是使用二次规划来求出分类线。本节课将从另一个方面入手，研究对偶支持向量机（Dual Support Vector Machine），尝试从新的角度计算得出分类线，推广SVM的应用范围。</p><h3 id="Motivation-of-Dual-SVM"><a href="#Motivation-of-Dual-SVM" class="headerlink" title="Motivation of Dual SVM"></a>Motivation of Dual SVM</h3><p>首先，我们回顾一下，对于非线性SVM，我们通常可以使用非线性变换将变量从x域转换到z域中。然后，在z域中，根据上一节课的内容，使用线性SVM解决问题即可。上一节课我们说过，使用SVM得到large-margin，减少了有效的VC Dimension，限制了模型复杂度；另一方面，使用特征转换，目的是让模型更复杂，减小$E_{in}$。所以说，非线性SVM是把这两者目的结合起来，平衡这两者的关系。那么，特征转换下，求解QP问题在z域中的维度设为$\hat d +1$，如果模型越复杂，则$\hat d +1$越大，相应求解这个QP问题也变得很困难。当$\hat d$无限大的时候，问题将会变得难以求解，那么有没有什么办法可以解决这个问题呢？一种方法就是使SVM的求解过程不依赖$\hat d$，这就是我们本节课所要讨论的主要内容。</p><p><img src="http://img.blog.csdn.net/20170627195157734?" alt="这里写图片描述"></p><p>比较一下，我们上一节课所讲的Original SVM二次规划问题的变量个数是$\hat d +1$，有N个限制条件；而本节课，我们把问题转化为对偶问题（’Equivalent’ SVM），同样是二次规划，只不过变量个数变成N个，有N+1个限制条件。这种对偶SVM的好处就是问题只跟N有关，与$\hat d$无关，这样就不存在上文提到的当$\hat d$无限大时难以求解的情况。</p><p><img src="http://img.blog.csdn.net/20170627195918132?" alt="这里写图片描述"></p><p>如何把问题转化为对偶问题（’Equivalent’ SVM），其中的数学推导非常复杂，本文不做详细数学论证，但是会从概念和原理上进行简单的推导。</p><p>还记得我们在《机器学习基石》课程中介绍的Regularization中，在最小化$E_{in}$的过程中，也添加了限制条件：$w^Tw\leq C$。我们的求解方法是引入拉格朗日因子$\lambda$，将有条件的最小化问题转换为无条件的最小化问题：$min\ E_{aug}(w)=E_{in}(w)+\frac{\lambda}{N}w^Tw$，最终得到的w的最优化解为：</p><p>$$\nabla E_{in}(w)+\frac{2\lambda}{N}w=0$$</p><p>所以，在regularization问题中，$\lambda$是已知常量，求解过程变得容易。那么，对于dual SVM问题，同样可以引入$\lambda$，将条件问题转换为非条件问题，只不过$\lambda$是未知参数，且个数是N，需要对其进行求解。</p><p><img src="http://img.blog.csdn.net/20170627202803919?" alt="这里写图片描述"></p><p>如何将条件问题转换为非条件问题？上一节课我们介绍的SVM中，目标是：$min\ \frac12w^Tw$，条件是：$y_n(w^Tz_n+b)\geq 1,\ for\ n=1,2,\cdots,N$。首先，我们令拉格朗日因子为$\alpha_n$（区别于regularization），构造一个函数：</p><p>$$L(b,w,\alpha)=\frac12w^Tw+\sum_{n=1}^N\alpha_n(1-y_n(w^Tz_n+b))$$</p><p>这个函数右边第一项是SVM的目标，第二项是SVM的条件和拉格朗日因子$\alpha_n$的乘积。我们把这个函数称为拉格朗日函数，其中包含三个参数：b，w，$\alpha_n$。</p><p><img src="http://img.blog.csdn.net/20170627215728198?" alt="这里写图片描述"></p><p>下面，我们利用拉格朗日函数，把SVM构造成一个非条件问题：</p><p><img src="http://img.blog.csdn.net/20170627225749786?" alt="这里写图片描述"></p><p>该最小化问题中包含了最大化问题，怎么解释呢？首先我们规定拉格朗日因子$\alpha_n\geq0$，根据SVM的限定条件可得：$(1-y_n(w^Tz_n+b))\leq0$，如果没有达到最优解，即有不满足$(1-y_n(w^Tz_n+b))\leq0$的情况，因为$\alpha_n\geq0$，那么必然有$\sum_n\alpha_n(1-y_n(w^Tz_n+b))\geq0$。对于这种大于零的情况，其最大值是无解的。如果对于所有的点，均满足$(1-y_n(w^Tz_n+b))\leq0$，那么必然有$\sum_n\alpha_n(1-y_n(w^Tz_n+b))\leq0$，则当$\sum_n\alpha_n(1-y_n(w^Tz_n+b))=0$时，其有最大值，最大值就是我们SVM的目标：$\frac12w^Tw$。因此，这种转化为非条件的SVM构造函数的形式是可行的。</p><h3 id="Lagrange-Dual-SVM"><a href="#Lagrange-Dual-SVM" class="headerlink" title="Lagrange Dual SVM"></a>Lagrange Dual SVM</h3><p>现在，我们已经将SVM问题转化为与拉格朗日因子$\alpha_n$有关的最大最小值形式。已知$\alpha_n\geq0$，那么对于任何固定的$\alpha’$，且$\alpha_n’\geq0$，一定有如下不等式成立：</p><p><img src="http://img.blog.csdn.net/20170628075805823?" alt="这里写图片描述"></p><p>对上述不等式右边取最大值，不等式同样成立：</p><p><img src="http://img.blog.csdn.net/20170628080019645?" alt="这里写图片描述"></p><p>上述不等式表明，我们对SVM的min和max做了对调，满足这样的关系，这叫做Lagrange dual problem。不等式右边是SVM问题的下界，我们接下来的目的就是求出这个下界。</p><p>已知$\geq$是一种弱对偶关系，在二次规划QP问题中，如果满足以下三个条件：</p><ul><li><p><strong>函数是凸的（convex primal）</strong></p></li><li><p><strong>函数有解（feasible primal）</strong></p></li><li><p><strong>条件是线性的（linear constraints）</strong></p></li></ul><p>那么，上述不等式关系就变成强对偶关系，$\geq$变成=，即一定存在满足条件的解$(b,w,\alpha)$，使等式左边和右边都成立，SVM的解就转化为右边的形式。</p><p>经过推导，SVM对偶问题的解已经转化为无条件形式：</p><p><img src="http://img.blog.csdn.net/20170628083339835?" alt="这里写图片描述"></p><p>其中，上式括号里面的是对拉格朗日函数$L(b,w,\alpha)$计算最小值。那么根据梯度下降算法思想：最小值位置满足梯度为零。首先，令$L(b,w,\alpha)$对参数b的梯度为零：</p><p>$$\frac{\partial L(b,w,\alpha)}{\partial b}=0=-\sum_{n=1}^N\alpha_ny_n$$</p><p>也就是说，最优解一定满足$\sum_{n=1}^N\alpha_ny_n=0$。那么，我们把这个条件代入计算max条件中（与$\alpha_n\geq0$同为条件），并进行化简：</p><p><img src="http://img.blog.csdn.net/20170628084913755?" alt="这里写图片描述"></p><p>这样，SVM表达式消去了b，问题化简了一些。然后，再根据最小值思想，令$L(b,w,\alpha)$对参数w的梯度为零：</p><p>$$\frac{\partial L(b,w,\alpha}{\partial w}=0=w-\sum_{n=1}^N\alpha_ny_nz_n$$</p><p>即得到：</p><p>$$w=\sum_{n=1}^N\alpha_ny_nz_n$$</p><p>也就是说，最优解一定满足$w=\sum_{n=1}^N\alpha_ny_nz_n$。那么，同样我们把这个条件代入并进行化简：</p><p><img src="http://img.blog.csdn.net/20170628090217878?" alt="这里写图片描述"></p><p>这样，SVM表达式消去了w，问题更加简化了。这时候的条件有3个：</p><ul><li><p>all $\alpha_n\geq0$</p></li><li><p>$\sum_{n=1}^N\alpha_ny_n=0$</p></li><li><p>$w=\sum_{n=1}^N\alpha_ny_nz_n$</p></li></ul><p>SVM简化为只有$\alpha_n$的最佳化问题，即计算满足上述三个条件下，函数$-\frac12||\sum_{n=1}^N\alpha_ny_nz_n||^2+\sum_{n=1}^N\alpha_n$最小值时对应的$\alpha_n$是多少。</p><p>总结一下，SVM最佳化形式转化为只与$\alpha_n$有关：</p><p><img src="http://img.blog.csdn.net/20170628091730046?" alt="这里写图片描述"></p><p>其中，满足最佳化的条件称之为Karush-Kuhn-Tucker(KKT)：</p><p><img src="http://img.blog.csdn.net/20170628091859925?" alt="这里写图片描述"></p><p>在下一部分中，我们将利用KKT条件来计算最优化问题中的$\alpha$，进而得到b和w。</p><h3 id="Solving-Dual-SVM"><a href="#Solving-Dual-SVM" class="headerlink" title="Solving Dual SVM"></a>Solving Dual SVM</h3><p>上面我们已经得到了dual SVM的简化版了，接下来，我们继续对它进行一些优化。首先，将max问题转化为min问题，再做一些条件整理和推导，得到：</p><p><img src="http://img.blog.csdn.net/20170628125859622?" alt="这里写图片描述"></p><p>显然，这是一个convex的QP问题，且有N个变量$\alpha_n$，限制条件有N+1个。则根据上一节课讲的QP解法，找到Q，p，A，c对应的值，用软件工具包进行求解即可。</p><p><img src="http://img.blog.csdn.net/20170628131919549?" alt="这里写图片描述"></p><p>求解过程很清晰，但是值得注意的是，$q_{n,m}=y_ny_mz^T_nz_m$，大部分值是非零的，称为dense。当N很大的时候，例如N=30000，那么对应的$Q_D$的计算量将会很大，存储空间也很大。所以一般情况下，对dual SVM问题的矩阵$Q_D$，需要使用一些特殊的方法，这部分内容就不再赘述了。</p><p><img src="http://img.blog.csdn.net/20170628140938851?" alt="这里写图片描述"></p><p>得到$\alpha_n$之后，再根据之前的KKT条件，就可以计算出w和b了。首先利用条件$w=\sum\alpha_ny_nz_n$得到w，然后利用条件$\alpha_n(1-y_n(w^Tz_n+b))=0$，取任一$\alpha_n\neq0$即$\alpha_n$&gt;0的点，得到$1-y_n(w^Tz_n+b)=0$，进而求得$b=y_n-w^Tz_n$。</p><p><img src="http://img.blog.csdn.net/20170628144714622?" alt="这里写图片描述"></p><p>值得注意的是，计算b值，$\alpha_n$&gt;0时，有$y_n(w^Tz_n+b)=1$成立。$y_n(w^Tz_n+b)=1$正好表示的是该点在SVM分类线上，即fat boundary。也就是说，满足$\alpha_n$&gt;0的点一定落在fat boundary上，这些点就是Support Vector。这是一个非常有趣的特性。</p><h3 id="Messages-behind-Dual-SVM"><a href="#Messages-behind-Dual-SVM" class="headerlink" title="Messages behind Dual SVM"></a>Messages behind Dual SVM</h3><p>回忆一下，上一节课中，我们把位于分类线边界上的点称为support vector（candidates）。本节课前面介绍了$\alpha_n$&gt;0的点一定落在分类线边界上，这些点称之为support vector（注意没有candidates）。也就是说分类线上的点不一定都是支持向量，但是满足$\alpha_n$&gt;0的点，一定是支持向量。</p><p><img src="http://img.blog.csdn.net/20170628153020643?" alt="这里写图片描述"></p><p>SV只由$\alpha_n$&gt;0的点决定，根据上一部分推导的w和b的计算公式，我们发现，w和b仅由SV即$\alpha_n$&gt;0的点决定，简化了计算量。这跟我们上一节课介绍的分类线只由“胖”边界上的点所决定是一个道理。也就是说，样本点可以分成两类：一类是support vectors，通过support vectors可以求得fattest hyperplane；另一类不是support vectors，对我们求得fattest hyperplane没有影响。</p><p><img src="http://img.blog.csdn.net/20170628153642180?" alt="这里写图片描述"></p><p>回过头来，我们来比较一下SVM和PLA的w公式：</p><p><img src="http://img.blog.csdn.net/20170628154103081?" alt="这里写图片描述"></p><p>我们发现，二者在形式上是相似的。$w_{SVM}$由fattest hyperplane边界上所有的SV决定，$w_{PLA}$由所有当前分类错误的点决定。$w_{SVM}$和$w_{PLA}$都是原始数据点$y_nz_n$的线性组合形式，是原始数据的代表。</p><p><img src="http://img.blog.csdn.net/20170628154618376?" alt="这里写图片描述"></p><p>总结一下，本节课和上节课主要介绍了两种形式的SVM，一种是Primal Hard-Margin SVM，另一种是Dual Hard_Margin SVM。Primal Hard-Margin SVM有$\hat d+1$个参数，有N个限制条件。当$\hat d+1$很大时，求解困难。而Dual Hard_Margin SVM有N个参数，有N+1个限制条件。当数据量N很大时，也同样会增大计算难度。两种形式都能得到w和b，求得fattest hyperplane。通常情况下，如果N不是很大，一般使用Dual SVM来解决问题。</p><p><img src="http://img.blog.csdn.net/20170628155410408?" alt="这里写图片描述"></p><p>这节课提出的Dual SVM的目的是为了避免计算过程中对$\hat d$的依赖，而只与N有关。但是，Dual SVM是否真的消除了对$\hat d$的依赖呢？其实并没有。因为在计算$q_{n,m}=y_ny_mz_n^Tz_m$的过程中，由z向量引入了$\hat d$，实际上复杂度已经隐藏在计算过程中了。所以，我们的目标并没有实现。下一节课我们将继续研究探讨如何消除对$\hat d$的依赖。</p><p><img src="http://img.blog.csdn.net/20170628160120576?" alt="这里写图片描述"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了SVM的另一种形式：Dual SVM。我们这样做的出发点是为了移除计算过程对$\hat d$的依赖。Dual SVM的推导过程是通过引入拉格朗日因子$\alpha$，将SVM转化为新的非条件形式。然后，利用QP，得到最佳解的拉格朗日因子$\alpha$。再通过KKT条件，计算得到对应的w和b。最终求得fattest hyperplane。下一节课，我们将解决Dual SVM计算过程中对$\hat d$的依赖问题。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170627195157734?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>台湾大学林轩田机器学习技法课程学习笔记1 -- Linear Support Vector Machine</title>
    <link href="https://redstonewill.github.io/2018/03/18/18/"/>
    <id>https://redstonewill.github.io/2018/03/18/18/</id>
    <published>2018-03-18T02:25:58.000Z</published>
    <updated>2018-03-18T02:52:42.883Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://img.blog.csdn.net/20170621075532782?imageView/2/w/500/q/100" alt="这里写图片描述"><br><a id="more"></a></p><blockquote><p>我的CSDN博客地址：<a href="http://blog.csdn.net/red_stone1" target="_blank" rel="noopener">红色石头的专栏</a><br>我的知乎主页：<a href="https://www.zhihu.com/people/red_stone_wl" target="_blank" rel="noopener">红色石头</a><br>我的微博：<a href="https://weibo.com/6479023696/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="noopener">RedstoneWill的微博</a><br>我的GitHub：<a href="https://github.com/RedstoneWill" target="_blank" rel="noopener">RedstoneWill的GitHub</a><br>我的微信公众号：红色石头的机器学习之路（ID：redstonewill）<br>欢迎大家关注我！共同学习，共同进步！</p></blockquote><p>关于台湾大学林轩田老师的《机器学习基石》课程，我们已经总结了16节课的笔记。这里附上基石第一节课的博客地址：</p><p><a href="http://blog.csdn.net/red_stone1/article/details/72899485" target="_blank" rel="noopener">台湾大学林轩田机器学习基石课程学习笔记1 – The Learning Problem</a></p><p>本系列同样分成16节课，将会介绍《机器学习基石》的进阶版《机器学习技法》，更深入地探讨机器学习一些高级算法和技巧。</p><h3 id="Large-Margin-Separating-Hyperplane"><a href="#Large-Margin-Separating-Hyperplane" class="headerlink" title="Large-Margin Separating Hyperplane"></a>Large-Margin Separating Hyperplane</h3><p>回顾一下我们之前介绍了linear classification，对于线性可分的情况，我们可以使用PLA/pocket算法在平面或者超平面上把正负类分开。</p><p><img src="http://img.blog.csdn.net/20170621075532782?" alt="这里写图片描述"></p><p>例如对平面2D这种情况，我们可以找到一条直线，能将正类和负类完全分开。但是，这样的直线通常不止一条，如下图所示。那么，下图中的三条分类线都能将数据分开，但是哪条线更好呢？</p><p><img src="http://img.blog.csdn.net/20170621080123771?" alt="这里写图片描述"></p><p>这三条直线都是由PLA/pocket算法不断修正错误点而最终产生的，整个确定直线形状的过程是随机的。单从分类效果上看，这三条直线都满足要求，而且都满足VC bound要求，模型复杂度$\Omega(H)$是一样的，即具有一定的泛化能力。但是，如果要选择的话，凭第一感觉，我们还是会选择第三条直线，感觉它的分类效果更好一些。那这又是为什么呢？</p><p>先给个简单解释，一般情况下，训练样本外的测量数据应该分布在训练样本附近，但与训练样本的位置有一些偏差。若要保证对未知的测量数据也能进行正确分类，最好让分类直线距离正类负类的点都有一定的距离。这样能让每个样本点附近的圆形区域是“安全”的。圆形区域越大，表示分类直线对测量数据误差的容忍性越高，越“安全”。</p><p><img src="http://img.blog.csdn.net/20170621082437517?" alt="这里写图片描述"></p><p>如上图所示，左边的点距离分类直线的最小距离很小，它的圆形区域很小。那么，这种情况下，分类线对测量数据误差的容忍性就很差，测量数据与样本数据稍有偏差，很有可能就被误分。而右边的点距离分类直线的最小距离更大一些，其圆形区域也比较大。这种情况下，分类线对测量数据误差的容忍性就相对来说大很多，不容易误分。也就是说，左边分类线和右边分类线的最大区别是对这类测量误差的容忍度不同。</p><p>那么，如果每一笔训练资料距离分类线越远的话，就表示分类型可以忍受更多的测量误差（noise）。我们之前在《机器学习基石》中介绍过，noise是造成overfitting的主要原因，而测量误差也是一种noise。所以，如果分类线对测量误差的容忍性越好的话，表示这是一条不错的分类线。那么，我们的目标就是找到这样一条最“健壮”的线，即距离数据点越远越好。</p><p><img src="http://img.blog.csdn.net/20170621092003010?" alt="这里写图片描述"></p><p>上面我们用圆形区域表示分类线能够容忍多少误差，也就相当于计算点到直线的距离。距离越大，表示直线越“胖”，越能容忍误差；距离越小，表示直线越“瘦”，越不能容忍误差。越胖越好（像杨贵妃那样的哦~）。</p><p><img src="http://img.blog.csdn.net/20170621092840092?" alt="这里写图片描述"></p><p>如何定义分类线有多胖，就是看距离分类线最近的点与分类线的距离，我们把它用margin表示。分类线由权重w决定，目的就是找到使margin最大时对应的w值。整体来说，我们的目标就是找到这样的分类线并满足下列条件：</p><ul><li><p><strong>分类正确，即$y_nw^Tx_n&gt;0$</strong></p></li><li><p><strong>margin最大化</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170621094248085?" alt="这里写图片描述"></p><h3 id="Standard-Large-Margin-Problem"><a href="#Standard-Large-Margin-Problem" class="headerlink" title="Standard Large-Margin Problem"></a>Standard Large-Margin Problem</h3><p>要让margin最大，即让离分类线最近的点到分类线距离最大，我们先来看一下如何计算点到分类线的距离。</p><p>首先，我们将权重$w(w_0,w_1,\cdots,w_d)$中的$w_0$拿出来，用b表示。同时省去$x_0$项。这样，hypothesis就变成了$h(x)=sign(w^Tx+b)$。</p><p><img src="http://img.blog.csdn.net/20170621100716605?" alt="这里写图片描述"></p><p>下面，利用图解的方式，详细推导如何计算点到分类平面的距离：</p><p><img src="http://img.blog.csdn.net/20170621101004571?" alt="这里写图片描述"></p><p>如上图所示，平面上有两个点：x’和x’’。因为这两个点都在分类平面上，所以它们都满足：</p><p>$$w^Tx’+b=0$$</p><p>$$w^Tx’’+b=0$$</p><p>同时可以得到：$w^Tx’=-b$，$w^Tx’’=-b$，则有：</p><p>$$w^T(x’’-x’)=w^Tx’’-w^Tx’=-b-(-b)=0$$</p><p>(x’’-x’)是平面上的任一向量，(x’’-x’)与w内积为0，表示(x’’-x’)垂直于w，那么w就是平面的法向量。</p><p>现在，若要计算平面外一点x到该平面的距离，做法是只要将向量(x-x’)投影到垂直于该平面的方向（即w方向）上就可以了。那么，令(x’’-x’)与w的夹角为$\theta$，距离就可以表示为：</p><p>$$distance(x,b,w)=|(x-x’)cos(\theta)|=|\ ||x-x’||\cdot \frac{(x-x’)w}{||x-x’||\cdot ||w||}|=\frac1{||w||}|w^Tx-w^Tx’|$$</p><p>代入$w^Tx’=-b$，可得：</p><p>$$distance(x,b,w)=\frac1{||w||}|w^Tx+b|$$</p><p>点到分类面（Separating Hyperplane）的距离已经算出来了。基于这个分类面，所有的点均满足：$y_n(w^Tx_n+b)&gt;0$，表示所有点都分类正确，则distance公式就可以变换成：</p><p>$$distance(x,b,w)=\frac1{||w||}y_n(w^Tx_n+b)$$</p><p>那么，我们的目标形式就转换为：</p><p><img src="http://img.blog.csdn.net/20170621112518701?" alt="这里写图片描述"></p><p>对上面的式子还不容易求解，我们继续对它进行简化。我们知道分类面$w^Tx+b=0$和$3w^Tx+3b=0$其实是一样的。也就是说，对w和b进行同样的缩放还会得到同一分类面。所以，为了简化计算，我们令距离分类满最近的点满足$y_n(w^Tx_n+b)=1$。那我们所要求的margin就变成了:</p><p>$$margin(b,w)=\frac1{||w||}$$</p><p>这样，目标形式就简化为：</p><p><img src="http://img.blog.csdn.net/20170621134411889?" alt="这里写图片描述"></p><p>这里可以省略条件：$y_n(w^Tx_n+b)&gt;0$，因为满足条件$y_n(w^Tx_n+b)=1$必然满足大于零的条件。我们的目标就是根据这个条件，计算$\frac1{||w||}$的最大值。</p><p>刚刚我们讲的距离分类满最近的点满足$y_n(w^Tx_n+b)=1$，也就是说对所有的点满足$y_n(w^Tx_n+b)\geq 1$。另外，因为最小化问题我们最熟悉也最好解，所以可以把目标$\frac1{||w||}$最大化转化为计算$\frac12w^Tw$的最小化问题。</p><p><img src="http://img.blog.csdn.net/20170621140211481?" alt="这里写图片描述"></p><p>如上图所示，最终的条件就是$y_n(w^Tx_n+b)\geq 1$，而我们的目标就是最小化$\frac12w^Tw$值。</p><h3 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h3><p>现在，条件和目标变成：</p><p><img src="http://img.blog.csdn.net/20170621143428452?" alt="这里写图片描述"></p><p>现在，举个例子，假如平面上有四个点，两个正类，两个负类：</p><p><img src="http://img.blog.csdn.net/20170621143607559?" alt="这里写图片描述"></p><p>不同点的坐标加上条件$y_n(w^Tx_n+b)\geq 1$，可以得到：</p><p><img src="http://img.blog.csdn.net/20170621143829925?" alt="这里写图片描述"></p><p>最终，我们得到的条件是：</p><p>$$w_1\geq +1$$</p><p>$$w_2\leq -1$$</p><p>而我们的目标是：</p><p>$$min\ \frac12w^Tw=\frac12(w_1^2+w_2^2)\geq 1$$</p><p>目标最小值为1，即$w_1=1,\ w_2=-1,\ b=-1$，那么这个例子就得到了最佳分类面的解，如图所示，且$margin(b,w)=\frac1{||w||}=\frac1{\sqrt2}$。分类面的表达式为：</p><p>$$x_1-x_2-1=0$$</p><p>最终我们得到的矩的表达式为：</p><p>$$g_{SVM}(x)=sign(x_1-x_2-1)$$</p><p>Support Vector Machine(SVM)这个名字从何而来？为什么把这种分类面解法称为支持向量机呢？这是因为分类面仅仅由分类面的两边距离它最近的几个点决定的，其它点对分类面没有影响。决定分类面的几个点称之为支持向量（Support Vector），好比这些点“支撑”着分类面。而利用Support Vector得到最佳分类面的方法，称之为支持向量机（Support Vector Machine）。</p><p>下面介绍SVM的一般求解方法。先写下我们的条件和目标：</p><p><img src="http://img.blog.csdn.net/20170621151733194?" alt="这里写图片描述"></p><p>这是一个典型的二次规划问题，即Quadratic Programming（QP）。因为SVM的目标是关于w的二次函数，条件是关于w和b的一次函数，所以，它的求解过程还是比较容易的，可以使用一些软件（例如Matlab）自带的二次规划的库函数来求解。下图给出SVM与标准二次规划问题的参数对应关系：</p><p><img src="http://img.blog.csdn.net/20170621153830381?" alt="这里写图片描述"></p><p>那么，线性SVM算法可以总结为三步：</p><ul><li><p><strong>计算对应的二次规划参数Q，p，A，c</strong></p></li><li><p><strong>根据二次规划库函数，计算b，w</strong></p></li><li><p><strong>将b和w代入$g_{SVM}$，得到最佳分类面</strong></p></li></ul><p><img src="http://img.blog.csdn.net/20170621154841557?" alt="这里写图片描述"></p><p>这种方法称为Linear Hard-Margin SVM Algorithm。如果是非线性的，例如包含x的高阶项，那么可以使用我们之前在《机器学习基石》课程中介绍的特征转换的方法，先作$z_n=\Phi(x_n)$的特征变换，从非线性的x域映射到线性的z域空间，再利用Linear Hard-Margin SVM Algorithm求解即可。</p><h3 id="Reasons-behind-Large-Margin-Hyperplane"><a href="#Reasons-behind-Large-Margin-Hyperplane" class="headerlink" title="Reasons behind Large-Margin Hyperplane"></a>Reasons behind Large-Margin Hyperplane</h3><p>从视觉和直觉的角度，我们认为Large-Margin Hyperplane的分类效果更好。SVM的这种思想其实与我们之前介绍的机器学习非常重要的正则化regularization思想很类似。regularization的目标是将$E_{in}$最小化，条件是$w^Tw\leq C$；SVM的目标是$w^Tw$最小化，条件是$y_n(w^Tx_n+b)\geq1$，即保证了$E_{in}=0$。有趣的是，regularization与SVM的目标和限制条件分别对调了。其实，考虑的内容是类似的，效果也是相近的。SVM也可以说是一种weight-decay regularization，限制条件是$E_{in}=0$。</p><p><img src="http://img.blog.csdn.net/20170621161842672?" alt="这里写图片描述"></p><p>从另一方面来看，Large-Margin会限制Dichotomies的个数。这从视觉上也很好理解，假如一条分类面越“胖”，即对应Large-Margin，那么它可能shtter的点的个数就可能越少：</p><p><img src="http://img.blog.csdn.net/20170621162739818?" alt="这里写图片描述"></p><p>之前的《机器学习基石》课程中介绍过，Dichotomies与VC Dimension是紧密联系的。也就是说如果Dichotomies越少，那么复杂度就越低，即有效的VC Dimension就越小，得到$E_{out}\approx E_{in}$，泛化能力强。</p><p>下面我们从概念的角度推导一下为什么dichotomies越少，VC Dimension就越少。首先我们考虑一下Large-Margin演算法的VC Dimension，记为$d_{vc}(A_{\rho})$。$d_{vc}(A_{\rho})$与数据有关，而我们之前介绍的$d_{vc}$与数据无关。</p><p>假如平面上有3个点分布在单位圆上，如果Margin为0，即$\rho=0$，这条细细的直线可以很容易将圆上任意三点分开（shatter），就能得到它的$d_{vc}=3$。如果$\rho&gt;\frac{\sqrt3}{2}$，这条粗粗的线无论如何都不能将圆上的任一三点全完分开（no shatter），因为圆上必然至少存在两个点的距离小于$\sqrt3$，那么其对应d的$d_{vc}&lt;3$。</p><p><img src="http://img.blog.csdn.net/20170621164552819?" alt="这里写图片描述"></p><p>那么，一般地，在d维空间，当数据点分布在半径为R的超球体内时，得到的$d_{vc}(A_{\rho})$满足下列不等式：</p><p><img src="http://img.blog.csdn.net/20170621165105577?" alt="这里写图片描述"></p><p>之前介绍的Perceptrons的VC Dimension为d+1，这里得到的结果是Large-Margin演算法的$d_{vc}(A_{\rho})\leq d+1$。所以，由于Large-Margin，得到的dichotomies个数减少，从而VC Dimension也减少了。VC Dimension减少降低了模型复杂度，提高了泛化能力。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本节课主要介绍了线性支持向量机（Linear Support Vector Machine）。我们先从视觉角度出发，希望得到一个比较“胖”的分类面，即满足所有的点距离分类面都尽可能远。然后，我们通过一步步推导和简化，最终把这个问题转换为标准的二次规划（QP）问题。二次规划问题可以使用Matlab等软件来进行求解，得到我们要求的w和b，确定分类面。这种方法背后的原理其实就是减少了dichotomies的种类，减少了有效的VC Dimension数量，从而让机器学习的模型具有更好的泛化能力。</p><p><strong><em>注明：</em></strong></p><p>文章中所有的图片均来自台湾大学林轩田《机器学习技法》课程</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170621075532782?imageView/2/w/500/q/100&quot; alt=&quot;这里写图片描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田机器学习技法" scheme="https://redstonewill.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/"/>
    
    
      <category term="机器学习" scheme="https://redstonewill.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="林轩田" scheme="https://redstonewill.github.io/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/"/>
    
      <category term="笔记" scheme="https://redstonewill.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="技法" scheme="https://redstonewill.github.io/tags/%E6%8A%80%E6%B3%95/"/>
    
  </entry>
  
</feed>
